[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "実証会計・ファイナンスの勉強ノート",
    "section": "",
    "text": "0.1 はじめに\nこのノートは、大阪大学経済学研究科のファイナンス学者の笠原晃恭先生と会計学者の村宮克彦先生が書かれた「実証会計・ファイナンス」新世社に関する学習内容をまとめたものです。 本書は、日経ストックリーグに参加する学生が、Rを駆使して分析パートを作成できるように作られており、会計学とファイナンスの基礎知識を付けた後で、Rの基本を学び、財務分析や投資理論をRで実装するための方法を学習できる、非常に有用な教科書です。 ぜひ本書を手に取って、企業のデータ分析を自分の手で実践してみてください。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>はじめに</span>"
    ]
  },
  {
    "objectID": "index.html#準備",
    "href": "index.html#準備",
    "title": "実証会計・ファイナンスの勉強ノート",
    "section": "0.2 準備",
    "text": "0.2 準備\n各自のPC(WindowsかMacを想定)の好きな場所にKasahara_Muramiyaというフォルダを作成し，そこを作業ディレクトリにしていることを想定しています。この文章の意味が分からない人は，Rの入門書を確認してください。 作業ディレクトリの中にdataというフォルダを作成し，そこにテキストで使うデータファイルを保存してある，という前提で進めます。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>はじめに</span>"
    ]
  },
  {
    "objectID": "chapter02.html",
    "href": "chapter02.html",
    "title": "\n2  ファイナンス入門\n",
    "section": "",
    "text": "2.1 割引率\nファイナンス(finance)の大事な概念に割引率(discount rate)があります。 これは、ある財の今の価値と将来の価値は異なっており、将来の価値を現在の価値(これを現在価値(present value)という)に変換するための係数です。\nたとえば，今の100万円が来年110万円になる世界において，\n100 = f(110)\nと表せる関数fが存在するとします。このとき，110万円を現在価値に変換するための係数が割引率です。 具体的に，\nf(110) = \\frac{110}{1 + r}\nと表せるとき，rが割引率です。\n\\begin{aligned}\n100 &= \\frac{110}{1 + r}\\\\\nr &= \\frac{110}{100} - 1 = 0.1\n\\end{aligned}\nこの場合，割引率rは0.1(10%)となります。 割引率10%の世界において，今の100万円は1年後の110万円と同じ価値をもつ，ということを意味しています。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ファイナンス入門</span>"
    ]
  },
  {
    "objectID": "chapter02.html#割引率",
    "href": "chapter02.html#割引率",
    "title": "\n2  ファイナンス入門\n",
    "section": "",
    "text": "2.1.1 確実なキャッシュ・フローに対する割引率\n\n\n現在価値 ：将来に発生するキャッシュフローの現時点における価値\n\n時間価値 ：将来と現在の価値の違い\n\n無リスク金利 (risk-free rate) ：安全資産へと投資したときのリターンで，投資時点でリターンの額が確定します。 無リスク金利は確率変数ではなく定数(parameter)です。\n\n上の式を年をTという記号で表して一般的に表現します。 T年後に確実に獲得できるキャッシュフローをCF_Tで表し、無リスク割引率をR_Fで表します1。 このとき現在価値 PV は以下のように計算されます。\n\nPV = \\frac{CF_T}{(1 + R_F)^T}\n\n\n\n現時点でCF_0を1年間貯金する。利息rは0.1とする。 1年後に受け取れるキャッシュフローCF_1は、貯金した元本CF_0と利息CF_0 \\times 0.1となる。つまり、CF_0 + CF_0 \\times 0.1 = (1+0.1)CF_0である。\n逆に、来年CF_1受け取るためには、今いくら貯金するかを考える。必要な貯金額をXとすると、X \\times (1 + 0.1) = CF_1となる。つまりX = CF_1/ (1.1)となる。 これが現在価値である。\n将来の確実なキャッシュ・フローCF_Tの現在価値は、割引率R_Fと将来受け取る時点であるTに依存している。CF_T = 100の場合、R_FとTの変化に応じて現在価値がどのように変化するのか確認する。\nT=1として、横軸を割引率、縦軸を現在価値としたグラフが以下のものである。 割引率が大きくなるにつれて現在価値が小さくなることが分かる。\n\n\n\n現在価値と割引率\n\nT_fixed &lt;- 1 # 1年後に固定\n\ndata.frame(\n  R_F = c(0.01, seq(0.1, 1, by = 0.01))\n  ) |&gt;\n  mutate(\n    PV = 100 / (1 + R_F)^T_fixed\n  ) |&gt;\n  ggplot() + aes(x = R_F, y = PV) +\n  geom_line(color = \"blue\") +\n  scale_x_continuous(labels = scales::percent) + # 軸を%表示に\n  labs(x = \"割引率\", y = \"現在価値\") +\n  mystyle\n\n\n\n\n\n\n\n\n次に、R_F = 0.1 に固定して、横軸を年 T 、縦軸を現在価値 PV としてグラフが以下のものです。 図を見ると，キャッシュ・フローを受け取る時点が遠くなるほど、現在価値が小さくなることがわかります。 1年後に受け取れる100万円と，10年後に受け取れる100万円では，後者の方が価値が低い，というのは直観的ですよね。\n\n\n\n現在価値と期間\n\nR_F &lt;- 0.1 # 無リスク利子率\nT &lt;- c(seq(0, 10, by = 0.1)) # 将来受け取る時点\nPV &lt;- 100 / (1 + R_F)^T # 現在価値の計算\ndf &lt;- data.frame(T, PV) # データフレーム作成\n# 作図\ndf |&gt;\n  ggplot() +\n  aes(x = T, y = PV) +\n  geom_line(color = \"red\") +\n  xlab(\"T年後\") + ylab(\"現在価値\") + mystyle\n\n\n\n\n\n\n\n\n\n2.1.2 不確実なキャッシュ・フローに対する割引率\nモデルに投資家のリスクプレミアム(risk premium; RP)を反映させることが割引率の2つ目の役割です。 通常、将来キャッシュ・フローがいくらになるのか分からないのが普通であり、CFは様々な要因で変化する確率変数(random variable)であるため、現時点における期待値(expected value)で評価されます。\nたとえば，1年後に確実に150万円もらえる投資Aと，確率50%で200万円，確率50%で100万円もらえる投資Bがあるとします。 期待値で評価すると，投資Aの期待キャッシュフローは150万円，投資Bの期待キャッシュフローは0.5 \\times 200 + 0.5 \\times 100 = 150万円となり，同じ期待キャッシュフローをもつことになります。 しかし，直観的に投資Bは100万円しか生み出さないリスクがある分，2つの投資の価値を現在の価値で比較すると，投資Aの方が価値が高いと思いませんか？\nこのリスクのある資産Bの割引率を\\tilde{R}と表すと，2つの投資の現在価値は，次のようになります。\n\n\\frac{150}{1 + R_F} \\quad &gt; \\quad \\frac{200 \\times 0.5 + 100 \\times 0.5}{1 + \\tilde{R}}\n となるなら， \nR_F &lt; \\tilde{R}\n\nとなります。このR_Fと\\tilde{R}の差がリスクプレミアム(risk premium: RP)です。リスクプレミアムは、リスクのある資産に投資することに対する追加的な見返りを意味します。\n\n\\begin{aligned}\nRP \\equiv \\tilde{R} - R_F\\\\\nR_F + RP = \\tilde{R}\n\\end{aligned}\n\n\n\nここで、期待値をとる演算子(operator)を\\mathbb{E}で表し、期待値をとる時点を添え字で表す。ここでは現時点t=0における期待値を\\mathbb{E}_0と表現している。 たとえば，現時点をt=0として，1期先に起こりうる結果Xが100か200であることが分かっていて，それぞれの発生確率が50%であったとする。この将来に起こりうる結果を現時点での情報を基に期待値をとる，ということは， \n\\mathbb{E}[X] = 0.5 \\times 100 + 0.5 \\times 200 = 150\n となる。このように起こりうる結果と発生確率を掛けて足したものを期待値という。\nリスクプレミアムは割引率の調整で定量化されます。\n\n\\begin{aligned}\nPV_0 & = \\frac{\\mathbb{E_0}[CF_1]}{1 + R_F + \\underbrace{(\\tilde{R} - R_F)}_{\\text{RP}}}\\\\\n     & =\\frac{\\mathbb{E_0}[CF_1]}{\\underbrace{1+\\tilde{R}}_{\\text{リスク調整済み割引率}}}\n\\end{aligned}\n\n割引率は時間価値やリスクプレミアムに関する定量的な情報を含むので、タイミングやリスクの異なるキャッシュフローを現在価値という同一の尺度で評価できます。\n\n2.1.3 NPV法\n先ほど学習した割引現在価値を判断の基準に，投資意思決定を行う方法をNPV法(Net Present Value Method)といいます。 いま，投資するかどうかを決めるタイミングを時点0(t=0)とします。 キャッシュフローはCF_tで表し，マイナスなら支出，プラスなら収入を意味します。 将来キャッシュフローは不確実であるため，現時点での期待値\\mathbb{E_0}[CF_t]で評価します。 ちなみにCF_0は時点0での投資なので，マイナスとなります。\n投資時点からT年間にわたって毎年\\mathbb{E}[CF_t],\\quad t = 1,\\dots ,Tの期待キャッシュフローが生み出されるなら、それらを割引率1 + \\tilde{R}で現在価値に直して足し合わせた値(つまりNPV)が、現時点で評価したプロジェクトの成果となります。\nNPVはそのプロジェクトから発生するすべてのキャッシュフローの現在価値として解釈できます。 コーポレートファイナンスでは，\n\nNPVがゼロ以上のプロジェクトは投資を実行\nNPVが負のプロジェクトは投資を見送る\n\nことを推奨しています。 NPV法を一般的に表現すると次のようになります(p.48)。 \n\\begin{aligned}\nNPV_0 &= \\frac{CF_0}{(1+\\tilde{R})^0} + \\frac{\\mathbb{E}[CF_1]}{(1+\\tilde{R})^1} + \\cdots + \\frac{\\mathbb{E}[CF_T]}{(1+\\tilde{R})^T}\\\\\n&= CF_0 + \\sum_{t=1}^T\\frac{\\mathbb{E}[CF_t]}{(1+\\tilde{R})^t}\n\\end{aligned}\n\n\n\nx^0 = 1 であることに注意してください。\n\n2.1.4 配当割引モデル\nNPV法の考え方を株式投資に適用することもできます。 株式の保有期間をT年とし、時点tにおける株価をP_tで表します。 株式から生み出される将来キャッシュ・フローは、\n\n一株当たり配当と，\n売却時点での売却損益\n\nであり、t時点の一株当たり配当をD_t，売却時点での一株当たり売却損益をP_T - P_{T-1}と表します。 将来配当や将来売却損益は確率変数であるため期待値で考え、それを割引率\\tilde{R}で割り引くことで、一株当たりの株式価値を求めます。\n\n\\begin{aligned}\nP_0^* &= \\frac{\\mathbb{E_0}[D_1]}{1 + \\tilde R} + \\frac{\\mathbb{E_0}[D_2]}{(1 + \\tilde R)^2} + \\cdots + \\frac{\\mathbb{E_0}[D_{\\infty}]}{(1 + \\tilde R)^{T}} + \\frac{\\mathbb{E_0}[P_T] - P_0}{(1+\\tilde{R})^T}\\\\\n&= \\sum^{T}_{t=1} \\frac{\\mathbb{E_0}[D_t]}{(1+\\tilde{R})^t} + \\frac{\\mathbb{E_0}[P_T] - P_0}{(1+\\tilde{R})^T}\n\\end{aligned}\n\n十分長い期間T \\rightarrow \\inftyを考えると，売却損益の現在価値はゼロに近づくため，株式の理論価値P_0^*は以下のように表せます。\n\nP_0^* = \\sum^{\\infty}_{t=1} \\frac{\\mathbb{E_0}[D_t]}{(1+\\tilde{R})^t}\n\nこれが配当割引モデル(Dividend Discount Model: DDM)です。 将来配当の予測値データがあれば，現時点における理論上の株価を計算することができます。\n\n2.1.5 ゴードン成長モデル\n配当割引モデルは理論上は正しいのですが、将来の配当を無限に予測することは現実的ではありません。 そこで、将来の配当が一定の割合で成長していくという仮定を置くことで、将来配当の予測を簡略化する方法があります。 より具体的に，期待一株当たり配当が一定の割合で成長していくと仮定した割引配当モデルをゴードン成長モデルという。\n直近の実現した一株当たり配当をD_0と置き、将来にわたってこの配当の期待値が一定割合G%で成長していくと仮定する。 つまり1時点先の配当額D_1が(1 + G)D_0となる、と仮定する。 すると、t 時点先の配当額 \\mathbb{E}[D_t] は、成長率Gを用いた複利計算により、 \nD_t = (1+G)^t D_0\n で表すことができます。 一定割合で配当額が成長する株式の理論価値P_0を配当割引モデルで計算すると， \n\\begin{aligned}\nP_0 &= \\frac{(1 + G) D_0}{(1+\\tilde{R})} +\n  \\frac{(1+G)^2 D_0}{(1+\\tilde{R})^3} +\n  \\frac{(1+G)^3 D_0}{(1+\\tilde{R})^3} + \\cdots \\\\\n    &= \\sum^{\\infty}_{t = 1}\\frac{(1 + G)^t D_0}{(1 + \\tilde{R})^t}\\\\\n    &=\\frac{(1+G)D_0}{\\tilde{R}-G}\n\\end{aligned}\n\n2本目の式から3本目の式への計算で、等比級数の和の公式を利用している。\n\n\n\n\n\n\nTip\n\n\n\n初項a，公比rの等比数列 \na, ar, ar^2, ar^3, \\dots , ar^{n-1},ar^n , \\dots\n がある。この等比数列の和をS_nで表す。 \nS_n = a + ar + ar^2 + \\cdots + ar^{n-1} + \\cdots\n 両辺にrを乗じると， \nrS_n =  ar + ar^2 + \\cdots + ar^{n-1} + ar^{n} + \\cdots\n となる。そして，S_n - rS_nを計算すると， \n\\begin{aligned}\nS_n - r S_n &= a\\\\\n(1-r)S_n &= a\\\\\nS_n &= \\frac{a}{1-r}\n\\end{aligned}\n 上のゴードン成長モデルの初項は(1+G)D_0/(1+\\tilde R)，公比は(1 +G)/(1+\\tilde R)なので， \n\\begin{aligned}\nS_n\n%P_0^* &= \\frac{(1+G)D_0}{1+ \\tilde R} + \\frac{(1+G)^2 D_0}{(1+ \\tilde R)^2} + \\frac{(1+G)^3 D_0}{(1+ \\tilde R)^3} + \\cdots \\\\\n&= \\displaystyle  \\frac{\\frac{(1+G)D_0}{(1 + \\tilde R)}}{1 - \\frac{1+G}{1+\\tilde R}}\\\\\n&= \\displaystyle  \\frac{\\frac{(1+G)}{(1 + \\tilde R)}D_0}{\\frac{(1+ \\tilde R) - (1+G)}{1+\\tilde R}}\\\\\n%&= \\displaystyle  \\frac{\\frac{(1+G)}{(1 + \\tilde R)}D_0}{\\frac{\\tilde R - G}{1+\\tilde R}}\\\\\n&= \\displaystyle  \\frac{1+G}{\\tilde R - G}D_0\\\\\n\\end{aligned}\n ただし，\\tilde{R} \\not = Gの場合のみである。\n\n\n\n2.1.6 割引率と期待リターンの関係\n割引率Rは投資家が将来キャッシュフローを購入するにあたって最低限要求する期待リターン(要求収益率)とも解釈できます。 これくらいリスクのある投資をするのだから，リスクのない資産への投資よりも高いリターンを要求する，という考えを反映しています。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ファイナンス入門</span>"
    ]
  },
  {
    "objectID": "chapter02.html#平均分散アプローチ入門",
    "href": "chapter02.html#平均分散アプローチ入門",
    "title": "\n2  ファイナンス入門\n",
    "section": "\n2.2 平均分散アプローチ入門",
    "text": "2.2 平均分散アプローチ入門\n個々の投資家にとって最適となる証券の組み合わせの比率を決めることを最適ポートフォリオ選択といいます。 ポートフォリオの価値をリターンの期待値と分散で評価する考え方を平均・分散アプローチといいます。\n\n2.2.1 ポートフォリオのリスクとリターン\n\n投資対象が銘柄Aと銘柄Bの2銘柄のみが投資対象であるケース\n各銘柄への投資割合をw_Aとw_B\n\nw_A + w_B = 1\n\n記号の定義は以下の通りです。\n\n元本 X\n\n投資銘柄Aのリターン 1 + R_A\n\n投資銘柄Bのリターン 1 + R_B\n\n\n\n\n\n\n\n\nNote\n\n\n\nリターンの定義(P_t - P_{t-1})/P_{t-1} = P_t/P_{t-1} -1はネット・リターン(net return)と呼ばれるものである。 これにたいして，元本も含めたリターン1 + R_t = P_t/P_{t-1}はグロス・リターン(gross return)という。\n\n\n元本Xのうちw_A分だけ銘柄Aに投資すると、1年後に期待値で\\mathbb{E}[X \\times w_A \\times (1+R_A)]になります。 手元現金全額を銘柄AとBに振り分けると、 \n\\begin{aligned}\n(1 + R_A) w_A X + ( 1 + R_B) w_B X\n&= w_A X + w_A R_A X + w_B X + w_B R_B X\\\\\n&= \\left [\\underbrace{(w_A+w_B)}_{\\text{定義より} = 1}+(w_AR_A+w_BR_B) \\right ]X\\\\\n&= (1 + w_A R_A + w_B R_B)X\n\\end{aligned}\n となります。 この1年後の価値と初期投資額の比としてこのポートフォリオのリターン1 + R_Pを計算します。 \n\\begin{aligned}\n1 + R_P &= \\frac{\\overbrace{(1 + w_A R_A + w_B R_B)X}^{将来時点の評価額}}{\\underbrace{X}_{初期投資}}\\\\\n        &= 1 + w_A R_A + w_B R_B\\\\\n        &= 1 + w_A R_A + w_B R_B\\\\\nR_P     &= w_A R_A + w_B R_B\n\\end{aligned}\n\nポートフォリオ構築時には、各銘柄の実現リターンはわからないので(つまり確率変数)、かわりに期待値や分散を評価します。 銘柄Aと銘柄Bのネット・リターンをそれぞれR_AとR_Bで表すと，期待値，分散，標準偏差は次のようになります。\n\n期待値 \\mathbb{E}[R_A] = \\mu _A，\\mathbb{E}[R_B] = \\mu_B\n\n分散 \\mathbb{V}[R_A] = \\sigma^2_A，\\mathbb{V}[R_B] = \\sigma^2_B\n\n共分散 \\mathbb{Cov}[R_A, R_B] = \\sigma_{AB}\n\n相関係数 \\rho = \\frac{\\sigma_{AB}}{\\sigma_A \\sigma_B}\n\n\n\n\\begin{aligned}\n% \\rho &= \\frac{\\mathbb{E}[(R_A - \\bar R_A)(R_B - \\bar R_B)]}{\\mathbb{E}[(R_A - \\bar R_A)^2]}\n\\rho &= \\frac{\\sigma _{AB}}{\\sigma _A \\times \\sigma _B} \\\\\n\\sigma_{AB} & = \\rho\\sigma_A\\sigma_B\n\\end{aligned}\n\nと表せます。\n上の式より、ポートフォリオのリターンはR_P = w_A R_A + w_B R_B なので、 ポートフォリオのリターンの期待値 \\mathbb{E}[R_P] = \\mu_P も各銘柄の期待リターンの加重平均となります。 ここで投資割合w_Aとw_Bは定数であり，R_A, R_Bは確率変数です。 \n\\begin{aligned}\n\\mathbb{E}[R_p] = \\mu_P &= \\mathbb{E}[w_A R_A + w_B R_B]\\\\\n&= w_A \\mathbb{E}[R_A] + w_B \\mathbb{E}[R_B]\\\\\n&=w_A\\mu_A+w_B\\mu_B\n\\end{aligned}\n\nつぎに，ポートフォリオのリターンR_Pの分散\\mathbb{V}[R_P] = \\sigma^2_Pは各銘柄の分散及び相関係数を用いて計算できます。\n\n\\begin{aligned}\n\\mathbb{V}[R_P] = \\sigma_P^2 &= \\mathbb{V}[w_A R_A + w_B R_B]\\\\\n&= w_A^2 \\mathbb{V}[R_A] + w_B^2 \\mathbb{V}[R_B] + 2 w_A w_B \\mathbb{Cov}[R_A,R_B]\\\\\n&= w_A^2 \\sigma_A^2 + w_B^2 \\sigma_B^2 + 2w_A w_B \\sigma _{AB}\\\\\n&= w^2_A \\sigma^2_A + w^2_B \\sigma^2_B +\n\\underbrace{2 w_A w_B \\rho \\sigma_A \\sigma_B}_{ここの\\rho の符号が重要}\n\\end{aligned}\n\n\n\n\n\n\n\nTip確率変数の分散\n\n\n\n確率変数XとYの線形結合aX + bYの分散は次のように計算できます。 \n\\begin{aligned}\n\\mathbb{V}(aX + bY) &= \\mathbb{E}\\left[ \\{ (aX + bY) - \\mathbb{E}[aX + bY] \\}^2 \\right] \\\\\n&= \\mathbb{E}\\left[ \\{ (aX + bY) - (a\\mu_X + b\\mu_Y) \\}^2 \\right] \\\\\n&= \\mathbb{E}\\left[ \\{ a(X - \\mu_X) + b(Y - \\mu_Y) \\}^2 \\right] \\\\\n&= \\mathbb{E}\\left[ a^2(X - \\mu_X)^2 + 2ab(X - \\mu_X)(Y - \\mu_Y) + b^2(Y - \\mu_Y)^2 \\right] \\\\\n&= a^2 \\mathbb{E}\\left[ (X - \\mu_X)^2 \\right] + 2ab \\mathbb{E}\\left[ (X - \\mu_X)(Y - \\mu_Y) \\right] + b^2 \\mathbb{E}\\left[ (Y - \\mu_Y)^2 \\right] \\\\\n&= a^2 \\mathbb{V}(X)  + b^2 \\mathbb{V}(Y) + 2ab \\mathrm{Cov}(X, Y)\n\\end{aligned}\n\n\n\nポートフォリオPの分散 \\mathbb{V}(R_P) は，各銘柄の分散に投資割合の二乗を乗じたものに，各銘柄のリターンの相関関係部分を加えたものとなっていることが分かります。 つまり，この2銘柄のリターンの相関係数\\rhoに応じて，ポートフォリオPの分散が大きくなるかどうかが決まる，ということです。\n\n2.2.2 分散投資のメリット\n保有比率(w_A, w_B)を変化させたときのポートフォリオの\\mu_Pと\\sigma_Pがどのように変化するかを確認しましょう。 分散は非負の値をとることに注意してください。\n\n\\begin{aligned}\n\\mathbb{V}[R_P] = \\sigma_P^2 &= w^2_A \\sigma^2_A + w^2_B \\sigma^2_B + 2\\rho{w_Aw_B\\sigma_A\\sigma_B}\\\\\n&= (w_A \\sigma_A + w_B \\sigma_B)^2 - 2w_A  w_B \\sigma _A \\sigma_B + 2\\rho{w_Aw_B\\sigma_A\\sigma_B}\\\\\n% &= (w_A \\sigma_A + w_B \\sigma_B)^2 - (2 + 2\\rho ) w_A w_B\\sigma_A\\sigma_B\\\\\n&=\\underbrace{(w_{A} \\sigma_{A} + w_{B}\\sigma_{B})^{2}}_{&gt;0} - \\underbrace{2(1-\\rho )w_{A}w_{B} \\sigma_{A}\\sigma_{B}}_{ここ重要}\n\\end{aligned}\n\n0 \\leq w_{A} \\leq 1 かつ 0 \\leq w_{B} \\leq 1 ，w_A + w_B = 1 のとき、\n\n2 ( 1- \\rho ) w_A w_B \\sigma _A \\sigma _B \\geq 0\n\nとなります。 \\rho = 1のときのみ等号で成立します。 したがって、-1 \\leq \\rho &lt; 1 のとき、( 1- \\rho ) w_A w_B \\sigma _A \\sigma _B &gt; 0 となり，次の不等式が成立します。 \n\\begin{aligned}\n\\sigma_P^2 &= (w_{A}\\sigma_{A}+w_{B}\\sigma_{B})^{2} - \\underbrace{2(1-\\rho )w_{A}w_{B} \\sigma_{A}\\sigma_{B}}_{&gt; 0}\\\\\n\\Longleftrightarrow \\sigma _P^2 &\\leq (w_A \\sigma _A + w_B \\sigma _B)^2 \\\\\n\\Longleftrightarrow \\sigma_{P} & \\leq\n\\underbrace{w_{A}\\sigma_{A}+w_{B}\\sigma_{B}}_{リスクの加重平均}\n\\end{aligned}\n となり，ポートフォリオのリスクを表す標準偏差\\sigma_Pが銘柄AとBの標準偏差の加重平均w_{A}\\sigma_{A} + w_{B} \\sigma_{B}以下になることがわかります。 これを分散投資効果という。\n\n\nCode\n分散投資効果 p.65\n\n# パラメータ設定\nparams &lt;- list(\n  mu_A = 0.1, sigma_A = 0.2,\n  mu_B = 0.2, sigma_B = 0.3,\n  rho = 0.2\n)\n\n# データの生成\ndf_portfolio &lt;- tibble(\n  wa = seq(0, 1, by = 0.01),\n  wb = 1 - wa\n  ) |&gt;\n  mutate(\n    mu_p = wa * params$mu_A + wb * params$mu_B,\n    var_p = wa^2 * params$sigma_A^2 + wb^2 * params$sigma_B^2 +\n      2 * params$rho * wa * wb * params$sigma_A * params$sigma_B,\n    sigma_p = sqrt(var_p),\n    # ラベル作成: 0.1刻みの点のみラベルを付ける\n    label = if_else(round(wa * 100) %% 10 == 0,\n                    sprintf(\"%.1f, %.1f\", wa, wb),\n                    NA_character_)\n  )\n\n# 作図\nggplot(df_portfolio, aes(x = mu_p, y = sigma_p)) +\n  geom_line() +\n  geom_point(data = df_portfolio |&gt; filter(!is.na(label)), size = 2) +\n  geom_text(aes(label = label), na.rm = TRUE, vjust = -1, size = 3) +\n  coord_flip() +\n  labs(x = \"期待リターン\", y = \"標準偏差 (リスク)\") +\n  mystyle\n\n\n\n\n\n\n\n\n\n完全な負の相関(\\rho=-1)であるの場合、\\sigma^{2}_{P}=0のポートフォリオを構築できる。 確認のため、2銘柄の価格が完全な負の相関\\rho = -1をもつとき、ポートフォリオPのリスク\\sigma_Pは \n\\begin{aligned}\n\\mathbb{V}[R_P] = \\sigma ^2_P &=(w_{A}\\sigma_{A}+w_{B}\\sigma_{B})^{2}-2(1- (-1))w_{A}w_{B} \\sigma_{A}\\sigma_{B}\\\\\n&= (w_{A}\\sigma_{A}+w_{B}\\sigma_{B})^{2} -4w_{A}w_{B} \\sigma_{A}\\sigma_{B}\\\\\n&= w_A ^2 \\sigma _A^2 + w_B^2\\sigma _B^2 + 2w_A w_B \\sigma_A \\sigma_B -4w_{A}w_{B} \\sigma_{A}\\sigma_{B}\\\\\n&= w_A ^2 \\sigma _A^2 - 2w_{A}w_{B} \\sigma_{A}\\sigma_{B} + w_B^2\\sigma _B^2 \\\\\n&= (w_{A}\\sigma_{A} - w_{B}\\sigma_{B})^{2}\\\\\n\\sigma _P &= | w_{A}\\sigma_{A} - w_{B}\\sigma_{B}|\n\\end{aligned}\n\n以下のように，w_A \\sigma _A = w_B \\sigma_Bとなるようにw_Aとw_Bを選べば、\\sigma _P = 0となるポートフォリオを作れる。\n\n\nCode\n完全な負の相関の分散投資効果 p.65\n\n# パラメータ設定\nparams &lt;- list(\n  mu_A = 0.1, sigma_A = 0.2,\n  mu_B = 0.2, sigma_B = 0.3\n)\n\n# データ生成\ndf_neg_corr &lt;- tibble(\n  wa = seq(0, 1, by = 0.01),\n  wb = 1 - wa\n) |&gt;\n  mutate(\n    mu_p = wa * params$mu_A + wb * params$mu_B,\n    # 完全な負の相関の場合、標準偏差は加重平均の差の絶対値になる\n    sigma_p = abs(wa * params$sigma_A - wb * params$sigma_B),\n    # ラベル作成: 0.1刻みの点のみラベルを付ける\n    label = if_else(round(wa * 100) %% 10 == 0,\n                    sprintf(\"%.1f, %.1f\", wa, wb),\n                    NA_character_)\n  )\n\n# 作図\nggplot(df_neg_corr, aes(x = mu_p, y = sigma_p)) +\n  geom_line() +\n  geom_point(data = df_neg_corr |&gt; filter(!is.na(label)), size = 2) +\n  geom_text(aes(label = label), na.rm = TRUE, vjust = -1, size = 3) +\n  coord_flip() + # 縦軸をリターン、横軸をリスクにするため入れ替え\n  labs(x = \"期待リターン\", y = \"標準偏差 (リスク)\") +\n  mystyle\n\n\n\n\n\n\n\n\n\nこのケースでは、\\sigma_A = 0.2、\\sigma_B = 0.3となっているため、0.2w_A = 0.3w_Bとなる保有割合を考える。 \n\\begin{aligned}\n0.2 w_A &= 0.3w_B\\\\\n0.2 w_A &= 0.3(1-w_A)\\\\\n0.2 w_A &= 0.3 - 0.3w_A\\\\\n0.5 w_A &= 0.3\\\\\nw_A &= 0.6\n\\end{aligned}\n となるため、銘柄Aに60％、銘柄Bに40%を投資することで、リスクゼロで期待リターン0.6\\times0.1 + 0.4 \\times 0.2 = 0.14を獲得することができる。\n\n2.2.3 空売りの効果\n空売り(short sale)とは、\n\n保有していない証券を誰か(普通は証券会社)から借りてきて売却し、\n一定期間後に買い戻して元の持ち主に返却する\n\n取引をいい、値下がりから利益を得る。 空売りを行う投資家をショートセラー(short seller)という。\nいままでは、0 \\leq w_A,w_B \\leq 1 という制約を置いていたが、この制約をはずして w_A + w_B = 1 のみを課す。 つまりw_A &lt; 0やw_B &lt; 0が空売りを表す。\n\n\nCode\n空売りの効果 p.66\n\n# パラメータ設定\nparams &lt;- list(\n  mu_A = 0.1, sigma_A = 0.2,\n  mu_B = 0.2, sigma_B = 0.3,\n  rho  = 0.2\n)\n\n# データ生成\ndf_short &lt;- tibble(\n  wa = seq(-1, 2, by = 0.01), # 空売りを考慮して範囲拡大\n  wb = 1 - wa\n) |&gt;\n  mutate(\n    mu_p = wa * params$mu_A + wb * params$mu_B,\n    sigma_p = sqrt(wa^2 * params$sigma_A^2 + wb^2 * params$sigma_B^2 +\n                   2 * params$rho * wa * wb * params$sigma_A * params$sigma_B),\n    wa_int = round(wa * 100), # 100倍して整数化\n\n    # 条件:\n    # 1. wa が -1 以上 2 以下 (wa_int が -100 ~ 200)\n    # 2. wa が 0.1 刻み (wa_int が 10 で割り切れる)\n    is_label_target = (wa_int &gt;= -100 & wa_int &lt;= 200) & (wa_int %% 10 == 0),\n\n    label = if_else(is_label_target,\n                    sprintf(\"%.1f, %.1f\", wa, wb),\n                    NA_character_)\n  )\n\n# 作図\nggplot(df_short, aes(x = mu_p, y = sigma_p)) +\n  geom_line() +\n  # ラベルがある点（0 &lt;= wa &lt;= 1）のみポイントとテキストを表示\n  geom_point(data = df_short |&gt; filter(!is.na(label)), size = 2) +\n  geom_text(aes(label = label), na.rm = TRUE, vjust = -1, size = 3) +\n\n  coord_flip() +\n  labs(x = \"期待リターン\", y = \"標準偏差 (リスク)\") +\n  mystyle\n\n\n\n\n\n\n\n\n\n先ほどの空売りなしのケースと比べると，曲線が大きく広がっていることがわかります。 次に，安全資産を加えた3資産の場合を考えます。\n\n2.2.4 安全資産の導入\n安全資産の購入についても考える。\n安全資産FのリターンをR_F、ポートフォリオPの保有比率をw_F，銘柄Aと銘柄Bと安全資産の投資割合をそれぞれw_A, w_B, w_Fで表します。\nまず銘柄Aと安全資産の2資産からなるポートフォリオを考えます。 各資産への投資割合をw_A + w_F = 1, \\quad  w_B = 0 とする場合を考える。 この安全資産と銘柄AからなるポートフォリオPの(ネット)リターン \\tilde R_P は， \n\\tilde R_{P} = w_{F} R_{F} + w_{A} \\tilde R_{A}\n となり，このポートフォリオの期待値は， \n\\begin{aligned}\n\\mu_{P} =\\mathbb{E}[R_P] &=\\mathbb{E}[ w_F R_{F} + w_{A} \\tilde{R_A} ]\\\\\n&=w_F R_{F}+w_{A} \\mathbb{E}[\\tilde{R_A}]\\\\\n&=w_F R_{F}+w_{A} \\mu_{A}\\\\\n&=(1-w_A) R_{F}+w_{A} \\mu_{A}\\\\\n&=R_{F} - w_{A}R_F + w_A\\mu_A\\\\\n&=R_{F} + w_A(\\underbrace{\\mu_A - R_F}_{\\tiny リスクプレミアム})\n\\end{aligned}\n\nとなります。 もちろん安全資産のリターンは定数なので，期待値をとってもそのままです。 \\mu_{A} - R_{F} はリスク資産である銘柄Aのリスクプレミアムを表しています。 通常，リスクのある資産の期待リターンは安全資産のリターンより大きいため，リスクプレミアムは正の値となります。 したがって，リスク資産への投資割合 w_A を1単位増加させれば，\\mathbb{E}[R_P] はリスクプレミアム分増加する\nつぎに，ポートフォリオのリスクを表す標準偏差 \\sigma _P とリターンの関係は次式で表せます。 まず安全資産のリスクはゼロであるため，リスク資産の銘柄Ａを保有する分だけリスクが生じる。\n\n\\begin{aligned}\n\\sigma_P^2 = \\mathbb{V}[R_P]  &= \\mathbb{V}[w_FR_F + w_A R_A]\\\\\n&= \\mathbb{V}[w_A R_A]\\\\\n&= w_A^2 \\mathbb{V}[R_A]\\\\\n&= w_A^2 \\sigma _A^2 \\\\\n\\sigma _P & = |w_A| \\sigma_A\n\\end{aligned}\n\n空売りを想定する場合w_A &lt; 0となるため，標準偏差を求める際に絶対値をとっています。 空売りはない状況（つまり，w_A&gt;0）を想定すると，\n\n\\begin{aligned}\n\\sigma _P = w_A \\sigma _A\\\\\nw_A = \\frac{\\sigma_P}{\\sigma _A}\n\\end{aligned}\n\nのように，リスク資産である銘柄Aへの投資割合w_Aが，ポートフォリオPとリスク資産Aのリスクの割合で決定されることがわかります。 これを，ポートフォリオの期待リターン\\mu_Pに代入すると、\n\n\\begin{aligned}\n\\mu_{P} &= R_F + w_A(\\mu_A - R_F)\\\\\n& = R_F + \\frac{\\sigma_P}{\\sigma _A}(\\mu_A - R_F) \\\\\n&= R_{F}+\\frac{\\mu_{A}-R_{F}}{\\sigma_{A}}\\sigma_{P}\n\\end{aligned}\n\nとなり，期待リターン\\mu_Pは，切片がR_F，傾きが(\\mu_A - R_F)/\\sigma_Aとする\\sigma_Pの線形関数となる。\n\n\nCode\n安全資産の導入 p.68\n\n# パラメータ設定\nparams &lt;- list(\n  R_F     = 0.01, # 安全資産利子率\n  mu_A    = 0.1,  # 銘柄A 期待リターン\n  sigma_A = 0.2   # 銘柄A 標準偏差\n)\n\n# データ生成\ndf_safe &lt;- tibble(\n  wa = seq(-1, 2, by = 0.01) # 銘柄Aへの投資比率\n) |&gt;\n  mutate(\n    wf = 1 - wa, # 安全資産への投資比率\n    mu_p    = params$R_F + wa * (params$mu_A - params$R_F),\n    sigma_p = abs(wa) * params$sigma_A, # 空売り時は絶対値\n\n    # ラベルの作成\n    wa_int = round(wa * 100),\n    is_label_target = (wa_int &gt;= 0 & wa_int &lt;= 100) & (wa_int %% 10 == 0),\n    label = if_else(is_label_target,\n                    sprintf(\"%g, %g\", wa, wf),\n                    NA_character_)\n  )\n\n# 作図\nggplot(df_safe, aes(x = mu_p, y = sigma_p)) +\n  geom_line() +\n  geom_point(data = df_safe |&gt; filter(!is.na(label)), size = 2) +\n  geom_text(aes(label = label), na.rm = TRUE, vjust = -1, size = 3) +\n\n  coord_flip() +\n\n  labs(x = \"期待リターン\", y = \"標準偏差 (リスク)\") +\n  mystyle\n\n\n\n\n\n\n\n\n\n\n2.2.5 3資産のポートフォリオ\nリスク資産AとB，安全資産Fの3資産に投資するポートフォリオを考える。 ここで，w_A + w_B &gt; 0を仮定し，少なくとも少しはリスク資産を保有するケースを考える。 当然だけれど，w_A = w_B =0のケースでは，安全資産のみを保有するケースとなり，リスクも無く，リターンも確定している。\n3資産A,B,Fへの投資割合をそれぞれw_A，w_B,w_Fとすると， 3資産からなるポートフォリオの期待リターンは次のように計算できる。 \n\\begin{aligned}\n\\mathbb{E}[R_{P}] &= w_FR_F + w_A \\mathbb{E} [\\tilde R_A] + w_B \\mathbb{E}[ \\tilde R_B] \\\\\n& =\nw_{F} R_{F} + (w_{A} + w_{B}) \\left(\\frac{w_{A}}{w_{A}+w_{B}} \\mathbb{E} [\\tilde R_{A}] + \\frac{w_{B}}{w_{A}+w_{B}} \\mathbb{E}[ \\tilde R_{B} ]\\right)\n\\end{aligned}\n 安全資産への投資割合w_Fとリスク資産への投資割合w_C = w_A + w_Bとまとめて，式を変形させる。 安全資産への投資以外の資金で構築したリスク資産AとBからなるポートフォリオをP_Cを考えると，P_Cの期待リターンR_Cは次のように計算できる。 \n\\begin{aligned}\nR_{C} &= \\frac{w_{A}}{w_{A}+w_{B}} \\mathbb{E}[\\tilde R_{A}] + \\frac{w_{B}}{w_{A}+w_{B}}\\mathbb{E}[ \\tilde R_{B}]\\\\\n\\end{aligned}\n\n安全資産FとポートフォリオCを保有した場合の期待リターンは次式となる。\n\n\\begin{aligned}\n\\mu_{P} & = \\mathbb{E}[w_F R_F + w_A R_A + w_B R_B]\\\\\n&= w_FR_F + w_A \\mathbb{E}[R_A] + w_B \\mathbb{E}[R_B]\\\\\n&= w_FR_F + (w_A + w_B) \\underbrace{ \\left( \\frac{w_A}{w_A + w_B} \\mathbb{E}[R_A] + \\frac{w_B}{w_A + w_B} \\mathbb{E}[R_B] \\right )}_{=w_C\\text{とおく}}\\\\\n&= w_F R_F + w_{C}\\mu_C\n\\end{aligned}\n\n安全資産と2つのリスク資産からなるポートフォリオの期待リターンは，安全資産の期待リターンとリスク資産の期待リターンの和となる。\n安全資産と2つのリスク資産に投資可能な場合，(\\mu_P, \\sigma _P)の取りうる値を図示できる。テキストの数値例を用いてRで図示してみる。\n\nリスク資産Aの期待リターン 0.1，標準偏差 0.2\nリスク資産Bの期待リターン 0.2，標準偏差 0.3\n安全資産の期待リターンを 0.01\nリスク資産AとBの間の相関係数は0.2\n安全資産，銘柄A，銘柄Bへの投資割合を0.2，0.3，0.5とするポートフォリオを考える。このポートフォリオの期待リターン\\mu_Pと標準偏差\\sigma_Pは次のようになる。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ファイナンス入門</span>"
    ]
  },
  {
    "objectID": "chapter02.html#最適ポートフォリオ問題",
    "href": "chapter02.html#最適ポートフォリオ問題",
    "title": "\n2  ファイナンス入門\n",
    "section": "\n2.3 最適ポートフォリオ問題",
    "text": "2.3 最適ポートフォリオ問題\n「どのようなポートフォリオが投資家にとって望ましいか」\n一般に、投資家はリスクが小さい一方でリターンが大きいポートフォリオを好む。 ここでは，リターンをポートフォリオの期待リターン\\mu_P，リスクをポートフォリオの標準偏差\\sigma _Pで表し，この2つの変数から構成される平面(\\mu_P, \\sigma_P)上で最適ポートフォリオ問題を分析する。\n\n2.3.1 効率的フロンティア\nリスク資産Aと資産Bにのみ投資可能であり，それぞれに異なる割合で投資したポートフォリオDとＥを比較する(以下の図）\n\n標準偏差はともに0.25 \\sigma _D = \\sigma _E = 0.25\n\nDの方がEよりも期待リターンが大きい，\\mu _D &gt; \\mu _E\n\n\nつまり，同じリスク（標準偏差）ならリターン（期待リターン）が高いポートフォリオに投資したほうがいいです。 以下のグラフでいうと、同じリスク(緑のライン上)なら、リターンの高いポートフォリオが望ましい。そのため青い線が効率的フロンティアとなり、点線は選択されないポートフォリオになります。\n\n\nCode\n効率的フロンティア\n\n# --- 1. パラメータ設定 ---\nparams &lt;- list(\n  mu_A    = 0.1, sigma_A = 0.2,  # 株式Aの標準偏差\n  mu_B    = 0.2, sigma_B = 0.3,  # 株式Bの標準偏差\n  rho     = 0.2   # 相関係数\n)\n\n# --- 2. 最小分散ポートフォリオ (MVP) の算出 ---\n# 分散・共分散\ncov_ab &lt;- params$rho * params$sigma_A * params$sigma_B\nvar_a  &lt;- params$sigma_A^2\nvar_b  &lt;- params$sigma_B^2\n\n# MVPにおける資産Aのウェイト w_mvp\n# 公式: w = (Var(B) - Cov(A,B)) / (Var(A) + Var(B) - 2Cov(A,B))\nw_mvp &lt;- (var_b - cov_ab) / (var_a + var_b - 2 * cov_ab)\n\n# MVPのリターンとリスク（しきい値として使用）\nmu_mvp    &lt;- w_mvp * params$mu_A + (1 - w_mvp) * params$mu_B\nsigma_mvp &lt;- sqrt(w_mvp^2 * var_a + (1 - w_mvp)^2 * var_b + 2 * w_mvp * (1 - w_mvp) * cov_ab)\n\n# --- 3. プロット用データの作成 ---\ndf_plot &lt;- tibble(\n  w = seq(-1, 2, by = 0.001)\n) |&gt;\n  mutate(\n    mu_p = w * params$mu_A + (1 - w) * params$mu_B,\n    sigma_p = sqrt((w * params$sigma_A)^2 +\n                  ((1 - w) * params$sigma_B)^2 +\n                  2 * w * (1 - w) * cov_ab),\n    frontier_type = if_else(mu_p &gt;= mu_mvp, \"効率(上部)\", \"非効率(下部)\")\n  )\n\n# --- 4. プロット作成 ---\nggplot(df_plot, aes(x = sigma_p, y = mu_p)) +\n  geom_path(\n    aes(color = frontier_type,\n    linetype = frontier_type)\n    ) +\n  geom_vline(xintercept = 0.25, color = \"green\", linetype = \"dashed\") +\n  # 資産A (緑)\n  annotate(\"point\", x = params$sigma_A, y = params$mu_A, color = \"orange\", size = 2) +\n  annotate(\"text\",  x = params$sigma_A, y = params$mu_A, label = \"A\", vjust = 2, fontface = \"bold\") +\n  # 資産B (オレンジ)\n  annotate(\"point\", x = params$sigma_B, y = params$mu_B, color = \"orange\", size = 2) +\n  annotate(\"text\",  x = params$sigma_B, y = params$mu_B, label = \"B\", vjust = -1.5, fontface = \"bold\") +\n  # 最小分散ポートフォリオ MVP (黒)\n  annotate(\"point\", x = sigma_mvp, y = mu_mvp, color = \"black\", size = 2) +\n\n  # C. 見た目の調整\n  scale_color_manual(values = c(\"効率(上部)\" = \"red\", \"非効率(下部)\" = \"blue\")) +\n  scale_linetype_manual(values = c(\"効率(上部)\" = \"solid\", \"非効率(下部)\" = \"dashed\")) +\n\n  labs(title = \"効率的フロンティア(2資産)\",\n       x = \"リスク\",\n       y = \"期待リターン\",\n       color = \"\",\n       linetype = \"\") +\n  mystyle +\n  xlim(0.1, 0.6) + ylim(0.0, 0.3)\n\n\n\n\n\n\n\n\n\nリスク資産AとBに加え、安全資産Fにも投資可能な場合、効率的フロンティアは直線になります。 この効率的フロンティアは資本市場線(Capital Market Line; CML)とも呼ばれます。 資本市場線の傾きは、この金融市場におけるリスクとリターンのトレードオフを表しているといえます。\n\n\nCode\n3資産の効率的フロンティア\n\n# --- 1. パラメータ設定 ---\nparams &lt;- list(\n  mu_A    = 0.1,  sigma_A = 0.2,\n  mu_B    = 0.2,  sigma_B = 0.3,\n  rho     = 0.2,  R_F     = 0.01\n)\n\n# --- 2. データの作成 ---\n# 2-1. リスク資産のみのフロンティア\ndf_frontier &lt;- tibble(\n  w = seq(-1, 2, by = 0.001)\n) |&gt;\n  mutate(\n    mu_p = w * params$mu_A + (1 - w) * params$mu_B,\n    sigma_p = sqrt((w * params$sigma_A)^2 + ((1 - w) * params$sigma_B)^2 +\n                   2 * w * (1 - w) * params$rho * params$sigma_A * params$sigma_B),\n    sharpe_ratio = (mu_p - params$R_F) / sigma_p\n  )\n\n# 2-2. 接点ポートフォリオ\ntangency_port &lt;- df_frontier |&gt; slice_max(sharpe_ratio, n = 1)\n\n# 2-3. 資本市場線 (CML)\ndf_cml &lt;- tibble(\n  sigma_p = c(0, 0.6),\n  mu_p    = c(params$R_F, params$R_F + tangency_port$sharpe_ratio * 0.6)\n)\n\n# --- 3. プロット作成 ---\nggplot() +\n  # A. 資本市場線 (CML)\n  geom_line(\n    data = df_cml,\n    aes(x = sigma_p, y = mu_p),\n    color = \"red\"\n  ) +\n\n  # B. リスク資産のみのフロンティア\n  geom_path(\n    data = df_frontier,\n    aes(x = sigma_p, y = mu_p),\n    color = \"blue\",\n    linetype = \"dashed\"\n  ) +\n\n  # C. ポイントの描画\n  # 資産A\n  annotate(\"point\", x = params$sigma_A, y = params$mu_A, color = \"green\", size = 2) +\n  annotate(\"text\",  x = params$sigma_A, y = params$mu_A, label = \"A\", vjust = 2, fontface = \"bold\") +\n\n  # 資産B\n  annotate(\"point\", x = params$sigma_B, y = params$mu_B, color = \"orange\", size = 2) +\n  annotate(\"text\",  x = params$sigma_B, y = params$mu_B, label = \"B\", vjust = 2, fontface = \"bold\") +\n\n  # 安全資産\n  annotate(\"point\", x = 0, y = params$R_F, color = \"purple\", size = 2) +\n  annotate(\"text\",  x = 0, y = params$R_F, label = \"安全資産(F)\", hjust = -0.3, fontface = \"bold\") +\n\n  # 接点ポートフォリオ\n  annotate(\"point\", x = tangency_port$sigma_p, y = tangency_port$mu_p, color = \"black\", size = 2) +\n  annotate(\"text\",  x = tangency_port$sigma_p, y = tangency_port$mu_p,\n           label = paste0(\"接点 P \\n(w=\", sprintf(\"%.2f\", tangency_port$w), \")\"),\n           hjust = -0.2, vjust = 0.8, lineheight = 0.9, size = 3) +\n\n  # D. テーマなどの設定\n  labs(title = \"安全資産を含む場合の効率的フロンティア\",\n       x = \"リスク (標準偏差)\",\n       y = \"期待リターン\") +\n\n  # 【修正】データを消さずにズームするために coord_cartesian を使用\n  coord_cartesian(xlim = c(0, 0.6), ylim = c(0, 0.3)) +\n\n  # テーマ設定\n  theme_economist_white(base_family = \"HiraKakuProN-W3\") +\n  theme(\n    text = element_text(size = 12),\n    axis.title = element_text(size = 12),\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\n\n安全資産が利用可能な場合、投資家は「安全資産」と「任意のリスク資産ポートフォリオ」を組み合わせることができます。 先ほどの式で確認した通り、安全資産とあるポートフォリオを組み合わせると、リスク・リターン平面上では直線が描かれます。 では、投資家はどのリスク資産ポートフォリオと安全資産を組み合わせるべきでしょうか？\n図の紫の点（安全資産 R_F）からスタートします。 そこから、青い点線（リスク資産のみのフロンティア）上の任意の点に向けて直線を引くことができます。 投資家は、同じリスクならより高いリターンを好むため、傾きが最も急になる直線を選ぼうとします。 その直線とは、安全資産の点から伸び、リスク資産のフロンティアに接する直線（赤い実線）となります。 この接点となるポートフォリオを接点ポートフォリオ(Tangency Portfolio)と呼びます。 この赤い直線上の組み合わせは、青い曲線上のどの点よりも（接点を除いて）左上に位置するため、より効率的です。 したがって、安全資産が存在する場合の効率的フロンティアはこの直線（資本市場線）となります。\n\n\n\n\n\n\nNote【直感的理解】なぜ曲線ではなく直線が最強なのか？\n\n\n\nこの理屈は、「ピンと定規」を使うと直感的に理解できます。\n\nリスク資産のエリア（青い曲線）  これまで見てきた双曲線（青い点線）は、株式などのリスク資産だけで作れる限界ラインでした。 投資家はこのライン上のどこかを選ぶしかありませんでした。\n安全資産（紫の点）  ここに「リスクゼロでお金が増える」安全資産（R_F）が登場します。 これはグラフの左端（リスク0）の軸上にピンを刺すようなものです。\n混ぜると「直線」になる 安全資産と、あるリスク資産を混ぜてポートフォリオを作ると、 グラフ上ではその2点を結ぶ直線が描かれます。 投資家は、安全資産のピン（R_F）を支点にして、定規をリスク資産のエリア（青い曲線）に向けて伸ばすことができます。\n\n定規を跳ね上げる（最適化） 投資家は「同じリスクなら、できるだけ高いリターン」を欲しがります。 つまり、R_Fに刺したピンを支点にして、定規の角度をできるだけ急にして、グイッと上に持ち上げたいと考えます。\n\n定規が曲線の内側を通るとき（割線）：もっと上にいけます。\n定規が曲線から離れてしまったとき：そのような商品は存在しないので買えません。\n\n\n\n定規を限界まで上に持ち上げたとき、定規は青い曲線の一番出っ張った部分に「ピタリ」と接するはずです。この「接した状態の直線」こそが、物理的に可能な範囲で最もリターン効率が良いライン（効率的フロンティア）となります。 そして、その接点にあるのが「接点ポートフォリオ」です。 これ以外の青い曲線上の点は、すべてこの直線の下側（＝効率が悪い）に来てしまうため、選ばれなくなります。\n\n\n\n\n2.3.2 投資家のリスク回避度と最適ポートフォリオ\n効率的フロンティアのうち、どの点が投資家の最適ポートフォリオになるのか，について考える。 そのためには投資家のリスク・リターンのトレードオフに関する選好(preference)の特徴，つまりリスクの回避度の情報が必要となる。 (\\mu_P,\\rho_p)平面上でそれを描く方法の一つが無差別曲線(indifference curve)である。 無差別曲線とは，投資家の効用(utility)が一定となるリスクとリターンの組み合わせを描いた曲線をいう。つまり同じ効用水準を達成できるリスクとリターンの組み合わせを表現した曲線である。\n\n2.3.2.1 効用関数の例\n以下では，財xとyを消費したときの効用Uを図示しています。 この消費者の効用関数はU(x,y) = x^{\\frac 25} \\times y^{\\frac 35}としている。\n\n\nなぜこのような設定にしているのかというと，この効用関数は限界代替率逓減(diminishing marginal rate of substitution)を満たしており，たくさん消費すると効用が増えるが，その増え方がだんだん小さくなる，という現実をよく表している性質を持っているからです。\n\nCode# 1. 効用関数のデータ作成\nx &lt;- 1:50\ny &lt;- 1:50\nu_func &lt;- function(x, y) { x^(2/5) * y^(3/5) }\nU &lt;- outer(x, y, u_func)\n\n# 2. 予算制約面のデータ作成\nbc_x_vec &lt;- seq(0, 25, length.out = 50)\nbc_z_vec &lt;- seq(0, 50, length.out = 50)\nbc_x_mat &lt;- matrix(rep(bc_x_vec, times = 50), nrow = 50, ncol = 50)\nbc_z_mat &lt;- matrix(rep(bc_z_vec, each = 50), nrow = 50, ncol = 50)\nbc_y_mat &lt;- (100 - 4 * bc_x_mat) / 6\n\n# 3. 交線のデータ作成\nline_x &lt;- seq(0, 25, length.out = 100)\nline_y &lt;- (100 - 4 * line_x) / 6\nline_z &lt;- u_func(line_x, line_y)\n\n# 4. 描画\nplot_ly() |&gt;\n  # (A) 効用関数の曲面 + 等高線\n  add_surface(\n    x = ~x, y = ~y, z = ~U,\n    opacity = 0.6,\n    colorscale = \"Viridis\",\n    name = \"効用関数\",\n    showscale = FALSE, # 【追加】カラーバー（色の凡例）を消す\n    contours = list(\n      z = list(\n        show = TRUE,\n        usecolormap = TRUE,\n        highlightcolor = \"#ff0000\",\n        project = list(z = TRUE)\n      )\n    )\n  ) |&gt;\n  # (B) 予算制約面\n  add_surface(\n    x = bc_x_mat,\n    y = bc_y_mat,\n    z = bc_z_mat,\n    opacity = 0.3,\n    colorscale = list(c(0, 1), c(\"blue\", \"blue\")),\n    showscale = FALSE, # 元からある設定（ここも消す）\n    name = \"予算制約\"\n  ) |&gt;\n  # (C) 交線\n  add_paths(\n    x = line_x, y = line_y, z = line_z,\n    line = list(width = 2, color = \"red\"),\n    name = \"予算線上の効用\"\n  ) |&gt;\n  layout(\n    title = \"効用最大化：曲面・予算制約・無差別曲線\",\n    showlegend = FALSE, # 【追加】項目名（線や面の名前）の凡例を消す\n    scene = list(\n      xaxis = list(title = \"財 x\"),\n      yaxis = list(title = \"財 y\"),\n      zaxis = list(title = \"効用 U\"),\n      camera = list(eye = list(x = -1.5, y = 1.5, z = 1.2))\n    )\n  )\n\n\n\n\n\nこの山のような部分が効用関数の曲面を表しており，xとyをたくさん消費すれば効用水準が高くなっています。 青い面は予算制約面を表しており，この面の上は予算を使い切って消費することを意味しています。 つまり青い面上の点で，もっとも満足度が高い場所が，最適消費点となります。\n分かりやすくするために，この三次元の図を上から見た図を考えます。 青いラインは予算制約で，青い線の内側が消費可能集合(affordable set)となります。 右上に行くほど効用が高くなるので，予算制約と無差別曲線の接点が最適消費点となります。\n\ncontour(x, y, U, method = \"edge\", labcex = 1, lwd = 2)\nabline(a = 100/6, b = -4/6, lwd = 2, col = \"blue\") #予算制約線\npoints(x = 10, y = 10, lwd = 3, col = \"darkblue\", pch = 16) #最適消費点\n\n\n\n\n\n\n無差別曲線と消費可能集合\n\n\n\n無リスク利子率が10%で，リスクプレミアムが5％，\\beta が1.2の場合の期待リターンは， R_F + \\beta \\times (R_M - R_F) = 0.1 + 1.2 \\times 0.05 = 0.16 となります。 このときの無差別曲線はU = 0.16 となるようなリスクとリターンの組み合わせを表します。\n\n\n\n無差別曲線の局所的な傾きは、その投資家が追加的なリスクを引き受けるうえで要求するリスクプレミアム，つまり傾き＝我慢料の相場を表しています。 したがって，リスク回避的な投資家ほど，リスクを1単位負担する際に，より大きなリスクプレミアムを要求するので、傾きは大きくなる，ということです。\n無差別曲線と効率的フロンティアが接する点が、この投資家にとっての最適ポートフォリオとなります。 投資可能なポートフォリオの範囲で、最も左上の無差別曲線を実現するのが接点となる。 どの点が最適ポートフォリオとして選ばれるかは個々の投資家の無差別曲線の形状(リスク回避度)に依存する。最適ポートフォリオにおいて、無差別曲線と効率的フロンティアの局所的な傾きは一致(接線だから当然)するため、その投資家が要求するリスクプレミアムがちょうど実現されている。\n上図の場合，この投資家の最適ポートフォリオは(w_F,w_{tan})\\approx(0.29,0.71)の比率で構成される。 接点ポートフォリオは銘柄Aに47％、銘柄Bに53％投資するポートフォリオだったので、最適保有比率は、(w_F,w_A,w_B)\\approx(0.29,0.33,0.38)と書き換えられる。\n\n2.3.3 トービンの分離定理\n安全資産が投資可能な場合の最適ポートフォリオ問題を考える。\n\n接点ポートフォリオを求め、リスク資産同士の相対的な保有比率を求める。\n投資家ごとのリスク回避度に応じて安全資産と接点ポートフォリオの最適保有比率の決定\n\n1は各投資家で共通している。 いったん接点ポートフォリオを求めてしまえば、他の投資家はその情報を用いて2を考えればよい。\n最適ポートフォリオ問題を2段階に分離できるという命題は、トービンの分離定理(又は二基金分離定理)と呼ばれている。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ファイナンス入門</span>"
    ]
  },
  {
    "objectID": "chapter02.html#capm",
    "href": "chapter02.html#capm",
    "title": "\n2  ファイナンス入門\n",
    "section": "\n2.4 CAPM",
    "text": "2.4 CAPM\n金融市場全体の均衡を考えるために、資本資産価格モデル(Capital Asset Pricing Model; CAPM)を学習します。\n\n2.4.1 仮定の確認\n\n\n選好 : ポートフォリオを期待値と標準偏差の基準で評価\n\n\n取引コスト : 取引コストは存在せず、空売りも自由\n\n流動性 : どれだけ売買しても証券の価格は不変\n\n情報集合 : みんな同じ情報を共有\n\n上記の仮定を満たす市場のことを、完全資本市場(完全市場: perfect market)と呼びます。 空想上の市場ですが、理論構築の大事な出発点です。\n\n2.4.2 CAPMの第一命題\n先の仮定の下で、安全資産が投資可能なとき、全ての投資家の最適ポートフォリオ問題に対してトービンの分離定理を応用することができます。 全ての投資家は「安全資産」と「接点ポートフォリオ」のみに投資し、危険資産に限定すれば全員が同じ構成比率のポートフォリオ（接点ポートフォリオ）を保有します。 金融市場全体の均衡を議論するうえで、市場にその資産が供給されている以上、誰かがその最適ポートフォリオの一部として保有しているはずです。 すなわち、需要と供給が一致している点がポイントです。\n以上の議論をよりフォーマルに述べるために、市場ポートフォリオを導入します。\n\n\n\n\n\n\nImportant市場ポートフォリオ\n\n\n\n市場ポートフォリオ (market portfolio) とは、市場に存在する全ての危険資産を時価総額比率で保有したポートフォリオをいう。厳密には、リスク資産には株式や債券に代表される金融資産の他、不動産や貴金属などの実物資産も含まれるが、実用上はTOPIXやS&P500といった株価指数と同一視されることが多い。\n\n\n\n\n\n\n\n\nImportantCAPMの第一命題\n\n\n\n市場ポートフォリオは接点ポートフォリオと一致し、効率的フロンティア（資本市場線）上に位置する。\n\n\n投資家は市場ポートフォリオに投資するとき、\\sigma_M のリスクを背負う見返りとして、R_F に加えて \\mu_M-R_F だけ追加的な報酬を期待します。 この追加的な報酬を市場リスクプレミアム (market risk premium) といいます。したがってこの命題の下では、資本市場線を市場リスクプレミアム (\\mu_M-R_F) を利用して、以下のように表せます。\n\n\\mu_P = R_F + \\frac{\\mu_M - R_F}{\\sigma_M} \\sigma_P\n\n\n前の章で用いたパラメータをそのまま考えます。 接点ポートフォリオの保有比率は概ね47%を銘柄Aに、53%を銘柄Bに投資する結果となりました。CAPMの第一命題によると、均衡した市場における銘柄AとBの時価総額比率は約0.47対0.53になっていなければなりません。 この命題に従えば、投資家は各銘柄の期待リターンや分散から接点ポートフォリオを計算する必要はなく、単に時価総額加重で市場ポートフォリオを保有すればよいことになります。\n\n\nパッシブ運用： 幅広い銘柄に分散投資し、市場平均と同じようなパフォーマンスを目指す運用手法。\n\nアクティブ運用： 市場平均を上回るパフォーマンスを目指し、投資銘柄を絞ったり、投資比率を工夫したりする運用方法。\n\n任意のポートフォリオの収益性を測る指標として、シャープ・レシオが提唱されています。シャープ・レシオは追加的なリスク・テイクによってどれだけリスクプレミアムを改善できるのかを表す指標です。CAPMの第一命題によると、市場ポートフォリオはシャープ・レシオを最大化するという意味で最も効率的なポートフォリオであり、資本市場線の傾き \\frac{\\mu_M - R_F}{\\sigma_M} は市場ポートフォリオのシャープ・レシオと一致します。\n\n\\text{Sharpe Ratio} = \\frac{\\mu_P-R_F}{\\sigma_P}\n\n\n2.4.3 CAPMの第二命題\n第二命題は個々の資産のリスクとリターンのトレードオフを数式で表現したものです。 ある証券に投資するときのリスクと、その証券に投資するときの期待リターンとの関係を知ることができるようになります。\n各投資家が証券 i を追加的に保有する際、重要となるのは市場ポートフォリオとの相関です。分散が大きい資産であっても、市場ポートフォリオと負に相関していれば、その資産を追加的に保有することでポートフォリオ全体のリスクは低減されます。CAPMの第二命題は、この相関を以下のマーケット・ベータとして定量化します。 （※ R_i は証券 i のリターン、R_M は市場ポートフォリオのリターン）\nこの \\beta_i は市場ポートフォリオのリスクを1としてベンチマーク化し、その証券のリスクがベンチマークの1を上回るか下回るかを測るものです。\\beta_i が大きいほど証券 i は投資家にとってリスク（システマティック・リスク）が大きいことを意味します。CAPMの世界では、証券 i のリスクはその証券のリターンの標準偏差ではなく、この \\beta_i によって測られます。\n\n\\beta_i = \\frac{\\mathbb{Cov}[R_i, R_M]}{\\mathbb{Var}[R_M]}\n\n金融市場全体が均衡しているには、リスクの高い証券はその分だけ期待リターンも高くなければなりません。 もし \\beta_i が低いにもかかわらず期待リターンが高い証券があるなら、投資家は市場ポートフォリオから離れてその証券をさらに買い増しするインセンティブを持ちます。 その結果、市場価格が上がり、期待リターンが下がるため、最終的に \\beta_i に応じた期待リターンが均衡で実現されます。\nこれまでは市場リスクプレミアムを \\mu_M - R_F と表記していましたが、以後ではより一般的な \\mathbb{E}[R_M] - R_F と表記します。\n\n\n\n\n\n\nImportantCAPMの第二命題\n\n\n\n各証券のリスクプレミアムは、その証券のマーケット・ベータに比例する。 この式は、証券 i のリスクプレミアム \\mathbb{E}[R_i]-R_F を、\\beta_i と市場リスクプレミアム \\mathbb{E}[R_M]-R_F に分解している。\n\n\n\n\\begin{aligned}\n\\mathbb{E}[R_i]-R_F = \\beta_i (\\mathbb{E}[R_M] - R_F)\\\\\n\\text{ただし、 } \\beta_i = \\frac{\\mathbb{Cov}[R_i,R_M]}{\\mathbb{Var}[R_M]}\n\\end{aligned}\n\n通常、市場リスクプレミアムは正の値をとるので、CAPMの第二命題によると、個々の証券のリスクプレミアムは \\beta_i に関して線形に増加します。 \\beta_i はあくまで市場ポートフォリオとの相関でリスクを定量化しているのがポイントです。 いくら個々の証券の分散（リスク）が大きくても、それが市場ポートフォリオと相関しない固有リスクであれば、リスクプレミアムには反映されません。 期待値をとる前の R_i を分解して確認します。\n\nR_i = R_F + \\beta_i (R_M - R_F) + \\varepsilon_i\n\nここで \\varepsilon_i は期待値ゼロで R_M と相関しない誤差項です。\n\n\\mathbb{E}[\\varepsilon_i] = 0, \\qquad \\mathbb{Cov}[\\varepsilon_i, R_M] = 0\n\n分散を計算すると以下のようになります。\n\n\\begin{aligned}\n\\mathbb{Var}[R_i] &= \\mathbb{Var}[\\beta_i R_M + \\varepsilon_i]\\\\\n& = \\beta_i^2 \\mathbb{Var}[R_M] + \\mathbb{Var}[\\varepsilon_i] + \\underbrace{2\\mathbb{Cov}[\\beta_i R_M, \\varepsilon_i]}_{\\tiny =0}\\\\\n& = \\underbrace{\\beta_i^2 \\mathbb{Var}[R_M]}_{\\tiny 市場ポートフォリオとの相関による寄与分} + \\underbrace{\\mathbb{Var}[\\varepsilon_i]}_{\\tiny 誤差項による寄与分}\n\\end{aligned}\n\nR_i の分散は、市場ポートフォリオとの相関による寄与分（システマティック・リスク）と誤差項による寄与分（固有リスク）に分解できます。 誤差項の分散が大きければその分だけ R_i の分散も大きくなりますが、証券 i のリスクプレミアムは \\beta_i(\\mathbb{E}[R_M]-R_F) のままで変化はありません。つまり、分散投資によって消去可能な固有リスクに対しては、市場は報酬（プレミアム）を与えないのです。\n\n2.4.4 証券市場線\n下左の図が示すように、安全資産と複数の危険資産が投資可能な場合、投資家の最適ポートフォリオは資本市場線上の1点(オレンジの点)となります。 一方、CAPMの第二命題が示唆するように、各証券のリスク（ベータ）とリターンとの関係は、右上がりの直線となります（図2.14 右図）。 縦軸に各証券の期待リターン、横軸に各証券のリスクを表すマーケット・ベータをとると、CAPMが完全に成立する世界では全ての資産が一直線上に並びます。この直線を証券市場線 (Securities Market Line; SML) と呼びます。\n定義通り \\beta を計算すると銘柄Aは約 0.63、銘柄Bは約 1.33 となります。 両者の期待リターンおよび \\beta を図示すると証券市場線に乗っており、この仮想的な市場ではCAPMが成立していることがわかります。\n\n\nCode\n証券市場線のプロット\n\n# -------------------------------------------------------\n# 1. パラメータ設定 (本文の記述と整合するように調整した数値)\n# -------------------------------------------------------\n# ※ ユーザーの手元に前の章のデータがある場合はそれを読み込んでください。\n# ここでは本文中の「A:47%, B:53%」「Beta A:0.63, Beta B:1.33」\n# と概ね一致するパラメータを設定します。\n\nmu_A &lt;- 0.05      # 銘柄Aの期待リターン\nsig_A &lt;- 0.10     # 銘柄Aの標準偏差\nmu_B &lt;- 0.12      # 銘柄Bの期待リターン\nsig_B &lt;- 0.20     # 銘柄Bの標準偏差\nrho &lt;- 0.2        # 相関係数\nRf &lt;- 0.01        # 安全利子率\n\n# 共分散\ncov_AB &lt;- rho * sig_A * sig_B\n\n# -------------------------------------------------------\n# 2. 接点ポートフォリオ(市場ポートフォリオ)の計算\n# -------------------------------------------------------\n# 過剰リターンベクトル\nR_excess &lt;- c(mu_A - Rf, mu_B - Rf)\n# 分散共分散行列\nSigma &lt;- matrix(c(sig_A^2, cov_AB, cov_AB, sig_B^2), nrow = 2)\n\n# 接点ポートフォリオのウェイト計算 (解析解)\nSigma_inv &lt;- solve(Sigma)\nw_tangency_unscaled &lt;- Sigma_inv %*% R_excess\nw_M &lt;- w_tangency_unscaled / sum(w_tangency_unscaled) # ウェイトの和を1にする\n\n# 市場ポートフォリオの期待リターンとリスク\nmu_M &lt;- as.numeric(t(w_M) %*% c(mu_A, mu_B))\nsig_M &lt;- as.numeric(sqrt(t(w_M) %*% Sigma %*% w_M))\n\n# Betaの計算: Cov(Ri, RM) / Var(RM)\n# Cov(Ra, Rm) = w_A*Var(A) + w_B*Cov(A,B)\ncov_AM &lt;- w_M[1] * sig_A^2 + w_M[2] * cov_AB\ncov_BM &lt;- w_M[1] * cov_AB + w_M[2] * sig_B^2\n\nbeta_A &lt;- cov_AM / sig_M^2\nbeta_B &lt;- cov_BM / sig_M^2\n\n# データフレーム化 (プロット用)\nassets &lt;- tibble(\n  Asset = c(\"銘柄A\", \"銘柄B\", \"市場PF\"),\n  Mu = c(mu_A, mu_B, mu_M),\n  Sigma = c(sig_A, sig_B, sig_M),\n  Beta = c(beta_A, beta_B, 1) # 市場PFのベータは定義上1\n)\n\n# -------------------------------------------------------\n# 3. 効率的フロンティアのデータ生成 (左図用)\n# -------------------------------------------------------\nw_seq &lt;- seq(-0.5, 1.5, length.out = 300)\nfrontier_data &lt;- tibble(\n  w_A = w_seq,\n  w_B = 1 - w_seq\n) %&gt;%\n  mutate(\n    Mu = w_A * mu_A + w_B * mu_B,\n    Sigma = sqrt(w_A^2 * sig_A^2 + w_B^2 * sig_B^2 + 2 * w_A * w_B * cov_AB)\n  )\n\n# -------------------------------------------------------\n# 4. 作図 (ggplot2)\n# -------------------------------------------------------\n\n# --- 左図: 資本市場線 (CML) ---\np_cml &lt;- ggplot() +\n  # 効率的フロンティア（双曲線）\n  geom_path(data = frontier_data, aes(x = Sigma, y = Mu),\n            color = \"gray70\", size = 1) +\n  # 資本市場線 (CML): 切片Rf, 接点を通る直線\n  geom_abline(intercept = Rf, slope = (mu_M - Rf) / sig_M,\n              color = \"darkblue\", linetype = \"solid\", size = 0.8) +\n  # 各資産のポイント\n  geom_point(data = assets, aes(x = Sigma, y = Mu, color = Asset), size = 3) +\n  # Rfの点\n  geom_point(aes(x = 0, y = Rf), color = \"black\", size = 2) +\n  annotate(\"text\", x = 0.01, y = Rf, label = \"Rf\", vjust = -1) +\n  # ラベル類\n  labs(title = \"資本市場線 (CML)\",\n       x = \"リスク (標準偏差)\", y = \"期待リターン\") +\n  theme_minimal() +\n  scale_x_continuous(limits = c(0, max(frontier_data$Sigma)*1.1)) +\n  scale_y_continuous(limits = c(0, max(frontier_data$Mu)*1.1), labels = scales::percent) +\n  theme(legend.position = \"none\") # 凡例は右図と共通または省略\n\n# --- 右図: 証券市場線 (SML) ---\np_sml &lt;- ggplot() +\n  # 証券市場線 (SML): 切片Rf, 傾き(Rm-Rf)\n  geom_abline(intercept = Rf, slope = (mu_M - Rf),\n              color = \"darkred\", linetype = \"solid\", size = 0.8) +\n  # 各資産のポイント\n  geom_point(data = assets, aes(x = Beta, y = Mu, color = Asset), size = 3) +\n  # 補助線 (市場PFのベータ=1を示す線)\n  geom_segment(aes(x = 1, xend = 1, y = 0, yend = mu_M),\n               linetype = \"dashed\", color = \"gray\") +\n  # Rfの点\n  geom_point(aes(x = 0, y = Rf), color = \"black\", size = 2) +\n  annotate(\"text\", x = 0.1, y = Rf, label = \"Rf\", vjust = -1) +\n  # ラベル類\n  labs(title = \"証券市場線 (SML)\",\n       x = \"ベータ (β)\", y = \"期待リターン\") +\n  theme_minimal() +\n  scale_x_continuous(limits = c(0, 1.5)) +\n  scale_y_continuous(limits = c(0, max(frontier_data$Mu)*1.1), labels = scales::percent) +\n  theme(legend.position = \"bottom\")\n\n# --- 図の結合 ---\np_combined &lt;- p_cml + p_sml\np_combined",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ファイナンス入門</span>"
    ]
  },
  {
    "objectID": "chapter02.html#n資産が投資可能な場合への拡張",
    "href": "chapter02.html#n資産が投資可能な場合への拡張",
    "title": "\n2  ファイナンス入門\n",
    "section": "\n2.5 N資産が投資可能な場合への拡張",
    "text": "2.5 N資産が投資可能な場合への拡張\nここまではリスク資産が銘柄AとBの二つしかない場合を分析してきましたが，平均分散アプローチやCAPMは危険資産の数が任意のN個であっても成立します。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ファイナンス入門</span>"
    ]
  },
  {
    "objectID": "chapter02.html#footnotes",
    "href": "chapter02.html#footnotes",
    "title": "\n2  ファイナンス入門\n",
    "section": "",
    "text": "無リスク割引率は無リスク金利と同義で，全くリスクのない確実に手に入れられる利息のようなものです。↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ファイナンス入門</span>"
    ]
  },
  {
    "objectID": "chapter03.html",
    "href": "chapter03.html",
    "title": "\n3  R言語入門\n",
    "section": "",
    "text": "3.1 Rの基本的な機能\nプログラミング言語にはいろんな種類があるけれど、今回学習するR言語は、インタプリタ型とよばれるもので、コンパイルという作業の必要が無く、書いたらすぐ実行できる仕様となっています。たとえば、教科書にあるように\nを実行すれば、結果がすぐ表示されます。 RstudioとかVisual Studio CodeとかAntigravityを使って、上のようなRソースコードを一気に書いてまとめて実行するためのスクリプト・ファイルを作成します。\nソースコードを書くにあたり注意する点が4つあります。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R言語入門</span>"
    ]
  },
  {
    "objectID": "chapter03.html#rの基本的な機能",
    "href": "chapter03.html#rの基本的な機能",
    "title": "\n3  R言語入門\n",
    "section": "",
    "text": "3.1.1 スカラー変数の定義\nこの学習を通じて変数(variable)とは、数値や文字といったデータを格納するための箱を表し、中に何が入っているのかにより、スカラー変数、ベクトル、行列、データフレームなどに分類されます。まずは、スカラー変数の定義を学びます。\nスカラー(scalar)とは、大きさだけで決まる量のことで、つまり、1つの数値を指します。 R言語ではスカラー変数を定義するには、&lt;-を使います。たとえば、x &lt;- 100と書けば、xというスカラー変数に100という数値を格納できます。このとき、&lt;-は代入演算子と呼ばれ、右辺の値を左辺の変数に代入するという意味です。また、xという変数を左辺値(left-hand side)、100という数値を右辺値(right-hand side)と呼びます。\n\nx &lt;- 100 # 代入演算子&lt;- の前後に半角スペースを入れるのがお作法\n\nこの中身を表示されるには、print()関数を使います。\n\nprint(x) # xの中身を表示\n\n[1] 100\n\n\nあるいは\n\nx\n\n[1] 100\n\n\nでも表示されます。\n\nRでは#の後ろの文章はコメントとして扱われ、実行されません。コメントはプログラムの内容を説明するためにたくさん書いて残しておきましょう。\n\n3.1.2 ベクトル変数の定義\nベクトル(vector)とは、大きさと向きで決まる量のことで、つまり、複数の数値を指します。R言語ではベクトル変数を定義するには、c()を使います。たとえば、x &lt;- c(1, 2, 3)と書けば、xというベクトル変数に1, 2, 3という数値を格納できます。このとき、c()はベクトルを作る関数と呼ばれ、1, 2, 3という数値を引数として与えています。\n\nx &lt;- c(1, 5, 9) # xに1と5と9を要素とするベクトルを代入\nprint(x)\n\n[1] 1 5 9\n\n\n等差数列を作る関数にseq()関数があります。seq()は3つの引数をとり、\n\n\nfrom : 始点\n\nto : 終点\n\nby : 差分\n\nを指定します。たとえば、2000年から2020年を表す年度の変数をyearとして定義するには、\n\nyear &lt;- seq(from = 2000, to = 2020, by = 1)\nprint(year)\n\n [1] 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014\n[16] 2015 2016 2017 2018 2019 2020\n\n\nと書けば、2000から2020までの公差1の等差数列を作ります。 seq()変数の引数には、fromとtoとbyの3つの引数を指定することができますが、fromとtoのみを指定することもできます。このとき、byの値は1となります。次のように書いても、上と同じ結果を得ることができます。\n\nseq(2000,2020)\n\n [1] 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014\n[16] 2015 2016 2017 2018 2019 2020\n\n\nベクトルの要素数を知るには、length()関数を使います。\n\nlength(year) # yearの要素数を表示\n\n[1] 21\n\n\nベクトル変数yearの中には21個の要素があることがわかります。\n\n3.1.2.1 ベクトルの要素の取り出し\n複数の要素をもつベクトルから、一部の要素を取り出すには、[]を使います。たとえば、xの2番目の要素を取り出すには、x[2]と書きます。このとき、[]は添字演算子と呼ばれ、2という添字を引数として与えています。添字は1から始まります。\n上のyearから2000を取り出すには、year[1]、2020を取り出すにはyear[20]と書きます。 次のような書き方で、好きな要素を指定して取り出すことができます。\n\nyear[1] # 1番目のデータを取り出す\n\n[1] 2000\n\nyear[20] # 20番目のデータを取り出す\n\n[1] 2019\n\nyear[2:5] # 2番目から5番目のデータを取り出す\n\n[1] 2001 2002 2003 2004\n\nyear[c(5,10)] # 1番目と20番目のデータを取り出す\n\n[1] 2004 2009\n\nyear[6:length(year)] # 6番目から最後のデータを取り出す\n\n [1] 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019\n[16] 2020\n\n\n\n3.1.2.2 現在価値の計算\n今の時点をt=0として、T年後に確実に得られるキャッシュ・フローCF_Tの現在価値PV_0は、\n\nPV_0 = \\frac{CF_T}{(1+r)^T}\n\nと書けます。たとえば1年後に確実に受け取れる100万円の現在価値PV_0を計算してみます。 いま、無リスク利子率rは10%とします。\n\n100 / (1 + 0.1)^1\n\n[1] 90.90909\n\n\n次に、この無リスク利子率rが変化した場合の現在価値の計算を考えます。まず、無リスク利子率のベクトルを定義します。\n\n# 下の２つは同じ結果\nR &lt;- seq(from = 0.1, to = 0.2, by = 0.01)　# 省略せずに書いた場合\nR &lt;- seq(0.1, 0.2, 0.01) # 略した場合\n\n次に、無リスク利子率が変化した場合の現在価値を計算します。\n\nPV &lt;- 100 / (1 + R)^1\nprint(PV)\n\n [1] 90.90909 90.09009 89.28571 88.49558 87.71930 86.95652 86.20690 85.47009\n [9] 84.74576 84.03361 83.33333\n\n\n無リスク利子率が0.1から0.2まで0.01ずつ変化した場合の現在価値が計算されました。この結果をグラフにしてみます。\n\n3.1.3 基本パッケージplotによる作図\nとりあえずサクッと作図してデータをチェックしたいとき、もとからR言語に組み込まれている基本関数plot()が便利です。先ほど作成したベクトル変数PVをグラフにしてみます。\n\nplot(PV)\n\n\n\n\n\n\n\nいま、PVは11個の要素をもつベクトル変数なので、データを左から順番に並べた散布図(scatter diagram)が作成されています。これだと何のグラフか分かりづらいので、いろいろとオプションを指定してみます。\n\nplot(\n    x = R, # x軸のデータ\n    y = PV, # y軸のデータ\n    xlab = \"無リスク利子率\",\n    ylab = \"現在価値\",\n    main = \"無リスク利子率と現在価値の関係\",\n    type = \"l\" # 線グラフ\n)\n\n\n\n\n\n\n\nMacだと文字化けしてしまいました。そこで文字コードを指定します。Windowsだとこの作業は不要です。\n\npar(family = \"HiraKakuProN-W3\") # Macの場合のみ\nplot(\n    x = R, # x軸のデータ\n    y = PV, # y軸のデータ\n    xlab = \"無リスク利子率\", # x軸のラベル\n    ylab = \"現在価値\", # y軸のラベル\n    main = \"無リスク利子率と現在価値の関係\", # グラフのタイトル\n    type = \"l\" # 折れ線グラフ\n)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R言語入門</span>"
    ]
  },
  {
    "objectID": "chapter03.html#for文の使い方",
    "href": "chapter03.html#for文の使い方",
    "title": "\n3  R言語入門\n",
    "section": "\n3.2 for文の使い方",
    "text": "3.2 for文の使い方\nプログラミングの基本要素である\n\n繰り返し\n分岐\n関数\n\nの最初の要素である「繰り返し」を行うための文法がfor文です。for文は、ある処理を繰り返し行うための文法です。たとえば、1から10までの整数を順番に表示するには、次のように書きます。\n\nfor (i in 1:10) { # iは1から10まで\n    print(i) # iを表示\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n\n\nこの文の構造は、基本的には\n\nfor (好きな変数 in 繰り返す範囲) {\n    繰り返したい処理\n}\n\nとなっています。\nたとえば、教科書のように、\n\n初期投資100万円\n1年後に50万円のキャッシュ・フロー\n2年後に50万円のキャッシュ・フロー\n3年後に50万円のキャッシュ・フロー\n\nという投資プロジェクトの現在価値を計算する場合、愚直に書くと次のようになります。\n\nNPV1 &lt;- -100 +\n    50 / (1 + 0.1)^1 +\n    50 / (1 + 0.1)^2 +\n    50 / (1 + 0.1)^3\nprint(NPV1)\n\n[1] 24.3426\n\n\nこの上のコードの2行目から4行目はほぼ同じ内容なので、数字が変化しているところに注目し、for文を使って書き換えてみます。ここでは^1のところが1ずつ大きくなってます。この部分をiという変数に置き換えてみます。 ついでに、後で変化させることがあるかもしれない部分をすべて変数として定義しておきます。\n\nR &lt;- 0.1 # 無リスク利子率\nNPV &lt;- -100 # 初期投資\nCF &lt;- 50 # キャッシュ・フロー\n\nfor (i in 1:3) { # iは1から3まで\n    NPV &lt;- NPV + CF / (1 + R)^i # 現在価値の計算\n}\nprint(NPV)\n\n[1] 24.3426\n\n\n愚直に計算した場合の同じ結果となりました。 これを10年間の現在価値を計算する場合だとすると、\n\nR &lt;- 0.1 # 無リスク利子率\nNPV &lt;- -100 # 初期投資\nNPV1 &lt;- NPV +\n    50 / (1 + R)^1 +\n    50 / (1 + R)^2 +\n    50 / (1 + R)^3 +\n    50 / (1 + R)^4 +\n    50 / (1 + R)^5 +\n    50 / (1 + R)^6 +\n    50 / (1 + R)^7 +\n    50 / (1 + R)^8 +\n    50 / (1 + R)^9 +\n    50 / (1 + R)^10\nprint(NPV1)\n\n[1] 207.2284\n\n\nと面倒くさいことこの上ないですが、for文を使えば、\n\nR &lt;- 0.1 # 無リスク利子率\nNPV &lt;- -100 # 初期投資\nfor (i in 1:10) { # iは1から10まで\n    NPV &lt;- NPV + 50 / (1 + R)^i\n}\nprint(NPV)\n\n[1] 207.2284\n\n\nと短く書くことができます。 使いこなせるように練習しておきましょう。 次のように、print()関数の位置を変えた場合、どうなるか考えてみてください。\n\nR &lt;- 0.1 # 無リスク利子率\nNPV &lt;- -100 # 初期投資\nfor (i in 1:3) { # iは1から10まで\n    print(NPV)\n    NPV &lt;- NPV + 50 / (1 + R)^i\n}\n\n[1] -100\n[1] -54.54545\n[1] -13.22314\n\nprint(NPV)\n\n[1] 24.3426\n\n\nこの場合、最初にNPVの中を表示し、次に1期目の現在価値を計算し、またその結果を表示し、2期目の現在価値を計算し・・・という順番で繰り返しが行われるので、計算の途中経過が表示されることになります。\n\n3.2.1 if文\n次に、プログラミングの基本要素である\n\n繰り返し\n分岐\n関数\n\nのうち分岐を行うための文法がif文です。if文は、ある条件を満たす場合にのみ処理を行うための文法です。たとえば、ある変数xが0より大きい場合にのみ、その変数を表示するには、次のように書きます。\n\nx &lt;- -1\nif (x &gt; 0) { # xが0より大きい場合\n    print(x) # xを表示\n}\n\nこの文の構造は、基本的には\n\nif (条件) {\n    条件を満たす場合に実行する処理\n}\n\nのようになっています。 このif文を使って、NPVが0より大きい場合にのみ、「プロジェクトを実行！」と表示されるようにしてみます。\n\nR &lt;- 0.1 # 無リスク利子率\nNPV &lt;- -100 # 初期投資\nfor (i in 1:10) { # iは1から10まで\n    NPV &lt;- NPV + 50 / (1 + R)^i\n}\nif (NPV &gt; 0) { # NPVが0より大きい場合\n    print(\"プロジェクトを実行！\") # 文字列を表示\n}\n\n[1] \"プロジェクトを実行！\"\n\n\nここではNPVの値が207.2284となりプラスになっているので、「プロジェクトを実行！」と表示されます。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R言語入門</span>"
    ]
  },
  {
    "objectID": "chapter03.html#npvと割引率の関係の可視化",
    "href": "chapter03.html#npvと割引率の関係の可視化",
    "title": "\n3  R言語入門\n",
    "section": "\n3.3 NPVと割引率の関係の可視化",
    "text": "3.3 NPVと割引率の関係の可視化\n無リスク利子率が0.1から0.2まで0.01ずつ変化した場合の現在価値NPVの値を計算してみます。\n\nR &lt;- seq(0.1, 0.2, 0.01) # 無リスク利子率\nN &lt;- length(R) # 無リスク利子率の要素数 11個\nNPV &lt;- rep(NA, N) # ベクトル変数にN個のNAを代入\n\nfor (i in 1:N) { # iは1からNまで\n    NPV[i] &lt;- -100 # 初期投資\n    for (j in 1:3) { # jは1から3まで\n        NPV[i] &lt;- NPV[i] + 50 / (1 + R[i])^j # 現在価値\n    }\n}\nprint(NPV) # 11個の現在価値を表示\n\n [1] 24.342600 22.185736 20.091563 18.057630 16.081601 14.161256 12.294477\n [8] 10.479248  8.713646  6.995838  5.324074\n\n\n少し複雑な構造しているので、順番に説明します。\n\n1行目は、無リスク利子率のベクトル変数Rを定義しています。ここでは、0.1から0.2まで0.01刻みのデータを作成しています。\n2行目は、ベクトル変数Rの要素数をNとして定義しています。ここでは、Nは11となります。\n3行目は、ベクトル変数NPVにN個のNAを代入しています。NAはNot Availableの略で、欠損値を表します。NAを代入することで、空っぽの箱が11個入ったベクトル変数NPVを用意します。\n4行目から9行目は、for文を使って、NPVの中身を計算しています。 forが2回出てきているので、二重に繰り返しの処理を行っています。これをネストと呼びます。 1つのめforはiが1からN(ここでは11)まで変化し、2つめのforはjが1から3まで変化します。1つめのfor文のiが1のとき、次のfor文のjが1から3までの処理を繰り返し、次に1つめのfor文のiが2のとき、次のfor文のjが1から3までの処理を繰り返し・・・という順番で処理が行われます。\n10行目は、NPVの中身を表示しています。\n\n\nTABキーを使って、インデントを行い、ソースコードのまとまりをわかりやすくしています。インデントは、プログラムの構造をわかりやすくするために行います。インデントを行うときは、半角スペース2つか4つを使います。どちらを使っても構いませんが、どちらかに統一することが大切です。\nこの結果をグラフにしてみます。\n\nplot(\n    x = R, # x軸のデータ\n    y = NPV, # y軸のデータ\n    xlab = \"無リスク利子率\", # x軸のラベル\n    ylab = \"現在価値\", # y軸のラベル\n    main = \"図：無リスク利子率と現在価値\", # グラフのタイトル\n    type = \"l\" # 線グラフ\n)\n\n\n\n\n\n\n\n\n3.3.0.1 ベクトル化\n上のコードは、for文を使って、NPVの中身を計算しています。しかし、R言語では、for文を使わずに、ベクトルを使って、同じことを行うことができます。このように、for文を使わずに、ベクトルを使って処理を行うことをベクトル化と呼びます。ベクトル化を行うと、処理が高速化されることがあります。\n\nR &lt;- 0.1 # 無リスク利子率 10%\nCF &lt;- c(-100, 50, 50, 50) # キャッシュ・フローのベクトル\nyear &lt;- 0:3 # 年度のベクトル\nPV_CF &lt;- CF / (1 + R)^year # 各期の現在価値を計算\nNPV &lt;- sum(PV_CF) # 現在価値の合計\nprint(NPV)\n\n[1] 24.3426",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R言語入門</span>"
    ]
  },
  {
    "objectID": "chapter03.html#独自関数の定義の仕方",
    "href": "chapter03.html#独自関数の定義の仕方",
    "title": "\n3  R言語入門\n",
    "section": "\n3.4 独自関数の定義の仕方",
    "text": "3.4 独自関数の定義の仕方\nプログラミングの基本要素である\n\n繰り返し\n分岐\n関数\n\nの作り方について説明します。 Rでは自分で関数を定義することができます。関数を定義することで、同じ処理を何度も書く必要がなくなり、プログラムの見通しがよくなります。 例えば、足し算をする関数my_add()を定義してみます。\n\nmy_add &lt;- function(x, y){\n    x + y\n}\n\nこの関数の構造は、\n\n好きな関数名 &lt;- function(引数1, 引数2){\n    処理内容\n}\n\nとなっています。つまり、この独自関数my_add()は、xとyという2つの引数(ひきすう)を足し合わせる関数です。数学的に書くなら、\n\nf(x, y) = x + y\n\nとなります。これはfという関数は2つの引数を足す関数であるという意味になっています。 作成した独自関数my_add()を使ってみます。\n\nmy_add(1, 2)\n\n[1] 3\n\n\n3が出力されました。\nこのように、独自関数を作成する場合には、\n\nどのような引数を与えるのか？\nそれに対してどのような処理を行うのか？\n最終的にどの値を返す(出力させる)のか？\n\nを考えておく必要があります。\nでは今までの流れで、現在価値を計算する関数を作成してみます。変化させたい値は、キャッシュフローCFと無リスク利子率Rなので、その2つを引数とする独自関数を作成します。 少し注意する必要がある点として、以下の計算例ではCFの1番目の要素は初期投資額となることに注意しましょう。\n\ncalc_PV &lt;- function(CF, R) {\n    PV &lt;- CF[1] # 初期投資額なのでマイナスの値\n    for (i in 2:length(CF)) { # iは2からCFの要素数まで\n        PV &lt;- PV + CF[i] / (1 + R)^(i - 1) # 現在価値\n    }\n    return(PV) # 現在価値を返す\n}\n\nこの関数calc_PV()を使って、現在価値を計算してみます。\n\ncalc_PV(c(-100, 50, 50, 50), 0.1)\n\n[1] 24.3426\n\n\nちゃんと計算されました。この関数を使って、無リスク利子率が0.1から0.2まで0.01ずつ変化した場合の現在価値を計算してみます。\n\nCF &lt;- c(-100, 50, 50, 50) # キャッシュ・フローのベクトル\nR &lt;- seq(0.1, 0.2, 0.01) # 無リスク利子率のベクトル\ncalc_PV(CF,R)\n\n [1] 24.342600 22.185736 20.091563 18.057630 16.081601 14.161256 12.294477\n [8] 10.479248  8.713646  6.995838  5.324074\n\n\n計算されました。 関数の引数にデフォルトで値を設定することで、入力を楽にすることができます。例えば、無リスク利子率のデフォルト値を0.1に設定してみます。\n\ncalc_PV &lt;- function(CF, R = 0.1) {\n    PV &lt;- CF[1] # 初期投資額なのでマイナスの値\n    for (i in 2:length(CF)) { # iは2からCFの要素数まで\n        PV &lt;- PV + CF[i] / (1 + R)^(i - 1) # 現在価値\n    }\n    return(PV) # 現在価値を返す\n}\n\nすると、無リスク利子率を指定しなくても、デフォルト値が使われるようになります。\n\nCF &lt;- c(-100, 50, 50, 50) # キャッシュ・フローのベクトル\ncalc_PV(CF)\n\n[1] 24.3426\n\n\nただ計算を間違えるもとにもなるので、なるべく省略せずに、しっかり書くことが大事です。\n\n3.4.0.1 もっと凝った独自関数\n繰り返し、分岐、関数というプログラミングの基本要素を勉強したので、もう少し複雑なプログラムを作成してみます。\nまずは、引数に正の数字以外のもの、あるいは文字列を入力した場合にエラーを表示する関数を作成します。\n\ncalc_PV_new &lt;- function(CF, R) {\n    if (R &lt;= 0) {\n        stop(\"無リスク利子率は正の値を入力してください。\") # エラー処理\n    }\n    if ( !is.numeric(CF) ) {\n        stop(\"キャッシュ・フローは数値を入力してください。\")\n    }\n    if ( !is.numeric(R) ) {\n        stop(\"無リスク利子率は数値を入力してください。\")\n    }\n\n    PV &lt;- CF[1]\n    for (i in 2:length(CF)) {\n        PV &lt;- PV + CF[i] / (1 + R)^(i - 1)\n    }\n    return(PV)\n}\n\nできました。ついでに、NPVの計算結果とともに、NPVが0より大きい場合にのみ、「プロジェクトを実行！」と表示する機能も実装してみます。\n\ncalc_PV_new &lt;- function(CF, R = 0.1) {\n    if (R &lt;= 0) {\n        stop(\"無リスク利子率は正の値を入力してください。\") # エラー処理\n    }\n    if ( !is.numeric(CF) ) {\n        stop(\"キャッシュ・フローは数値を入力してください。\")\n    }\n    if ( !is.numeric(R) ) {\n        stop(\"無リスク利子率は数値を入力してください。\")\n    }\n\n    PV &lt;- CF[1]\n    for (i in 2:length(CF)) {\n        PV &lt;- PV + CF[i] / (1 + R)^(i - 1)\n    }\n\n    if (PV &gt;= 0) { # NPVが0より大きい場合\n    paste0(\"NPVが\", round(PV, digits = 2), \"なので、プロジェクトを実行！\") # 文字列を表示\n    } else {\n    paste0(\"NPVが\", round(PV, digits = 2), \"なのでプロジェクト中止！\") # 文字列を表示\n    }\n}\n\nいろいろ駆使してより短く簡単に書くなら、\n\ncalc_PV &lt;- function(CF, R = 0.1) {\n  if (!is.numeric(CF) || !is.numeric(R) || R &lt;= 0) {\n    stop(\"キャッシュ・フローと無リスク利子率は数値を入力し、無リスク利子率は正の値を入力してください。\")\n  }\n  PV &lt;- sum(sapply(1:length(CF), function(i) CF[i] / (1 + R)^(i - 1)))\n\n  if (PV &gt;= 0) {\n    paste0(\"NPVが\", round(PV, digits = 2), \"なので、プロジェクトを実行！\")\n  } else {\n    paste0(\"NPVが\", round(PV, digits = 2), \"なのでプロジェクト中止！\")\n  }\n}\n\n\nCF &lt;- c(-100, 50, 50, 50)\ncalc_PV(CF)\n\n[1] \"NPVが24.34なので、プロジェクトを実行！\"\n\n\nうまくいきました。 ちょっとキャッシュフローのベクトルを変化させて、初期投資を-200にすると、\n\nCF &lt;- c(-200, 50, 50, 50)\ncalc_PV(CF)\n\n[1] \"NPVが-75.66なのでプロジェクト中止！\"\n\n\nちゃんと中止のメッセージが出ました。\nこのように、分岐、繰り返し、関数を駆使して、様々なプログラムを作成することができます。プログラミングの基本要素を使いこなせるように、練習を重ねてください。まずは教科書に書いてあるソースコードを自分のPC上で実行してみてください。その際は、コピペせずに自分で入力するようにしてください。\n\n3.4.0.2 付録：ベクトル化で早くなるのか？\nどれほど高速化されるのかを確認するため、100万年分の現在価値を計算してみます。 最初に松浦のR環境を確認してみます。 コンピューターはMac miniで、CPUはM4 Pro、メモリは24GB、MacOS Tahoe 26.3です。 Rやパッケージのバージョンは以下の通りです。\n\nsessionInfo() \n\nR version 4.5.0 (2025-04-11)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS 26.3\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n\nlocale:\n[1] C.UTF-8/C.UTF-8/C.UTF-8/C/C.UTF-8/C.UTF-8\n\ntime zone: Asia/Tokyo\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] Rcpp_1.1.0           microbenchmark_1.5.0 ggthemes_5.1.0      \n [4] lubridate_1.9.4      forcats_1.0.1        stringr_1.6.0       \n [7] dplyr_1.1.4          purrr_1.2.0          readr_2.1.5         \n[10] tidyr_1.3.1          tibble_3.3.0         ggplot2_4.0.0       \n[13] tidyverse_2.0.0     \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6       jsonlite_2.0.0     compiler_4.5.0     tidyselect_1.2.1  \n [5] systemfonts_1.3.1  scales_1.4.0       textshaping_1.0.3  yaml_2.3.10       \n [9] fastmap_1.2.0      R6_2.6.1           generics_0.1.4     knitr_1.50        \n[13] htmlwidgets_1.6.4  pillar_1.11.1      RColorBrewer_1.1-3 tzdb_0.5.0        \n[17] rlang_1.1.6        stringi_1.8.7      xfun_0.53          S7_0.2.0          \n[21] timechange_0.3.0   cli_3.6.5          withr_3.0.2        magrittr_2.0.4    \n[25] digest_0.6.37      grid_4.5.0         hms_1.1.3          lifecycle_1.0.4   \n[29] vctrs_0.6.5        evaluate_1.0.5     glue_1.8.0         farver_2.1.2      \n[33] ragg_1.5.0         pacman_0.5.1       rmarkdown_2.29     tools_4.5.0       \n[37] pkgconfig_2.0.3    htmltools_0.5.8.1 \n\nR.version\n\n               _                           \nplatform       aarch64-apple-darwin20      \narch           aarch64                     \nos             darwin20                    \nsystem         aarch64, darwin20           \nstatus                                     \nmajor          4                           \nminor          5.0                         \nyear           2025                        \nmonth          04                          \nday            11                          \nsvn rev        88135                       \nlanguage       R                           \nversion.string R version 4.5.0 (2025-04-11)\nnickname       How About a Twenty-Six      \n\n\n今回比較した4つの手法について、それぞれの特徴と、どのような場面で使うべきかをまとめました。 適切な手法を選択する際の参考にしてください。\n\nforループ：1つずつ順番に計算する、最も基本的で直感的な方法です。 プログラムの構造が分かりやすく、複雑な条件分岐を書きやすいです。 しかし、Rは繰り返し処理のたびに「解釈」を行うため、回数が増えると極端に時間がかかります。データ数が少ない場合や、計算ロジックが非常に複雑でベクトル化が難しい場合に使います。\nベクトル化 : Rの得意技で、データを「まとめて」一気に計算する方法です。 forループに比べて劇的に高速で、コードも短くシンプルになります。 しかし、計算のために巨大な一時データをメモリ上に作成するため、メモリ消費量が大きいです。データが巨大すぎるとメモリ不足で停止することがありますが、Rでは通常はこの方法が推奨されます。\n分割計算 / チャンク化 : データを一定のサイズ（例：100万件ずつ）に区切って、少しずつベクトル化計算を行う方法です。ベクトル化の速さを活かしつつ、メモリ消費量を低く抑えることができますが、コードが少し複雑になります。また、区切る処理が入る分、純粋なベクトル化よりわずかに遅くなります。億単位のデータなど、一気に計算するとメモリ不足になるような大規模データを扱う場合に有効です。\nRcpp (C++連携) : Rの中から、より高速なプログラミング言語である「C++」を呼び出して計算する方法です。圧倒的に最速です。また、メモリ管理も効率的なので、大規模データでも軽快に動作します。C++の知識が必要で、コードを書く難易度が高いですが、生成AIを活用すれば初心者でも比較的簡単に導入できます。非常に大規模なシミュレーションや、計算速度が最重要となる場合に適しています。\n\n以下では、それぞれの手法で現在価値を計算する関数を定義します。\n\n\n\nfor文とベクトル化の比較\n\n# for文版\ncalc_PV_for &lt;- function(CF, R = 0.1) {\n  PV &lt;- CF[1]\n  n &lt;- length(CF)\n  if (n &lt; 2) return(PV) # 要素数が1以下の場合は即リターン\n  \n  for (i in 2:n) {\n    PV &lt;- PV + CF[i] / (1 + R)^(i - 1)\n  }\n  return(PV)\n}\n\n# ベクトル版\ncalc_PV_vec &lt;- function(CF, R = 0.1){\n  year &lt;- 0:(length(CF) - 1)\n\n  PV_CF &lt;- CF / (1 + R)^year\n  NPV &lt;- sum(PV_CF)\n  return(NPV)\n}\n\n# ベクトル版一気に計算版\ncalc_PV_chunk &lt;- function(CF, R = 0.1, chunk_size = 1e6) { # デフォルトで100万件ずつ処理\n  n &lt;- length(CF)\n  total_npv &lt;- 0\n  \n  # チャンクの開始位置を作成 (例: 1, 1000001, 2000001...)\n  starts &lt;- seq(1, n, by = chunk_size)\n  \n  for (start in starts) {\n    # 終了位置を計算（データの最後を超えないようにminを使う）\n    end &lt;- min(start + chunk_size - 1, n)\n    \n    # 1. 必要な部分だけデータを切り出す（ここでメモリ消費を抑える）\n    cf_part &lt;- CF[start:end]\n    \n    # 2. 時間tのベクトルを作成（全体の位置に合わせて調整）\n    # CF[1]がt=0に対応するため、インデックスから1を引く\n    t_part &lt;- (start:end) - 1\n    \n    # 3. 部分的な現在価値を計算して合計に加算\n    # ベクトル化の恩恵を受けつつ、メモリ消費はchunk_size分だけで済む\n    total_npv &lt;- total_npv + sum(cf_part / (1 + R)^t_part)\n  }\n  \n  return(total_npv)\n}\n\n# Rcppを使ってC++で高速化版\n# C++のコードをRの中でコンパイルして関数化\ncppFunction('\ndouble calc_PV_cpp(NumericVector CF, double R) {\n  double npv = 0;\n  double discount_factor = 1.0;\n  double r_plus_1 = 1.0 + R;\n  int n = CF.size();\n  \n  for(int i = 0; i &lt; n; ++i) {\n    // 毎回 pow(1+R, i) を計算すると遅いので、\n    // 割引率を掛け合わせて更新していく（これが最速）\n    npv += CF[i] / discount_factor;\n    discount_factor *= r_plus_1;\n  }\n  return npv;\n}\n')\n\n# 使い方\n# calc_PV_cpp(CF, 0.1)\n\n\n比較してみます。 ランダムな将来キャッシュフローを1万年分用意します。\n\nset.seed(121)\nn_years &lt;- 10^6 # 100万年分\n# 初期投資-100とランダムなキャッシュフロー\nCF &lt;- c(-100, runif(n_years - 1, min = 0, max = 100)) \n\nでは、それぞれの方法で計算した速度を比較してみましょう。 正確に比較するため、microbenchmarkパッケージを使って、それぞれ10回ずつ計測し、その分布を確認します。\n\n# 全ての手法をまとめて計測\nres &lt;- microbenchmark(\n    \"For Loop\"   = calc_PV_for(CF),\n    \"Vectorized\" = calc_PV_vec(CF),\n    \"Chunked\"    = calc_PV_chunk(CF),\n    \"Rcpp (C++)\" = calc_PV_cpp(CF, 0.1),\n    times = 10, # 10回繰り返して計測\n    unit = \"ms\" # 単位をミリ秒に統一\n)\n\n# 結果の数値表示\nprint(res)\n\nUnit: milliseconds\n       expr       min        lq      mean    median        uq       max neval\n   For Loop 40.699183 40.760519 41.262695 41.017056 41.193848 43.888204    10\n Vectorized  9.194127  9.373707 10.130202  9.574504 11.133509 11.516203    10\n    Chunked 14.059064 14.538846 23.785957 15.320080 18.645939 57.010008    10\n Rcpp (C++)  1.128853  1.149353  1.207602  1.159542  1.163867  1.670504    10\n\n# 結果の可視化（箱ひげ図）\nggplot(res, aes(x = expr, y = time / 1e6, fill = expr)) + # timeを1e6(100万)で割ってミリ秒に変換\n  geom_boxplot() + # 箱ひげ図を指定\n  scale_y_continuous(labels = scales::comma) + # 軸の数値をカンマ区切りに（見やすくするため）\n  labs(title = \"計算手法による実行速度の比較 (100万件)\", \n       y = \"実行時間 (ミリ秒)\",\n       x = \"\") + # x軸ラベル（手法名）は自明なので空欄に\n  theme_minimal() + # ベーステーマ（mystyleがあればそちらに置き換えてください）\n  mystyle +\n  theme(legend.position = \"none\") # 色分けの凡例は不要なら消す\n\n\n\n\n\n\n\n実行結果の解釈:\n\n\nforループ: 最も遅くなります。Rでのループ処理はオーバーヘッドが大きいためです。\nベクトル化: for文に比べて劇的に高速化します。通常はこの方法が推奨されます。\nChunked: ベクトル化より少し遅くなりますが、メモリ消費を抑えられるメリットがあります。\n\nRcpp: 圧倒的に高速です。C++のレベルで最適化されるため、大規模なシミュレーションや反復計算では威力を発揮します。\n\nこれがベクトル化による実行速度の効率化です。とはいえ、演算に時間がかかるような大規模データや複雑なシミュレーションをするようになるまで、ベクトル化の恩恵はそれほど大きくないですし、巨大な中間ベクトルをメモリ上に生成するため、計算速度は速くなるがメモリ消費量は増えるます。 ということなので今は気にせずに、読みやすく、確実に動くプログラムを書くことを心がけましょう。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R言語入門</span>"
    ]
  },
  {
    "objectID": "chapter03.html#演習",
    "href": "chapter03.html#演習",
    "title": "\n3  R言語入門\n",
    "section": "\n3.5 演習",
    "text": "3.5 演習\n各自でやってみてください。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R言語入門</span>"
    ]
  },
  {
    "objectID": "chapter03.html#データフレーム入門",
    "href": "chapter03.html#データフレーム入門",
    "title": "\n3  R言語入門\n",
    "section": "\n3.6 データフレーム入門",
    "text": "3.6 データフレーム入門\n\n3.6.1 CSVファイルの読み込み\nRでCSVファイルを読み込むには、readrパッケージのread_csv()関数を使うのがよいでしょう。 たとえば、data.csvというファイルを読み込むには、次のように書きます。\n\ndf &lt;- readr::read_csv(\"data/ch03_daily_stock_return.csv\")\n\nこのdfというオブジェクトの型を見てみると，\n\nclass(df)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\nspec_tbl_df，tbl_df，tbl，data.frameという4つの型が表示されます。 data.frameという属性が含まれており，dfがデータフレームであることを示しています。\n\n\nspec_tbl_dfは，readrパッケージが読み込んだデータフレームに付与する属性で，データの仕様情報を保持しています。 tbl_dfは，tibbleパッケージが提供するデータフレームの拡張型で，表示や操作がしやすくなっています。 tblは，dplyrパッケージが提供するデータフレームの拡張型で，データ操作が効率的に行えるようになっています。 基本的には，data.frameとして扱うことができます。\nあとは，\n\n\nnrow()関数で行数を確認\n\nstr()関数で構造を確認\n\nmean()関数で平均を計算\n\nsd()関数で標準偏差を計算\n\ncor()関数で相関係数を計算\n\nなどを使って，データの中身を確認してみましょう。\n\n\nwhich.min()関数やwhich.max()関数で最小値・最大値のインデックスを取得\n\n例えば，最も日次リターンが高い日付を調べるには，次のようにします。\n\nbest_day_ID &lt;- which.max(df$firm1)\nbest_day_ID\n\n[1] 13\n\n\n13行目が最も日次リターンが高い日付なので，dfからその行を取り出してみます。\n\ndf$date[best_day_ID]\n\n[1] \"2020-04-17\"",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R言語入門</span>"
    ]
  },
  {
    "objectID": "chapter03.html#ファクター型と日付型",
    "href": "chapter03.html#ファクター型と日付型",
    "title": "\n3  R言語入門\n",
    "section": "\n3.7 ファクター型と日付型",
    "text": "3.7 ファクター型と日付型\n\n3.7.1 ファクター型入門\nファクター型あるいは因子型(factor)は，カテゴリカル変数を表現するためのデータ型で，分かりづらいものの，非常に便利かつ重要なデータの型なので，しっかり理解しておきましょう。\n数値型や文字列型を因子型に変換する方法には，\n\n基本関数 factor()\n\n\nforcatsパッケージのas_factor()関数\n\nforcatsパッケージのfct_relevel()関数\n\n先ほど読み込んだデータのindustry変数は，文字列型ですが，これを因子型に変換してみます。\n\nfirm_ID &lt;- c(1,2,3)\nname &lt;- c(\"Firm A\", \"Firm B\", \"Firm C\")\nindustry &lt;- c(\"Machinery\", \"Chemicals\", \"Machinery\")\n\nfirm_data &lt;- data.frame(\n  firm_ID = firm_ID,\n  name = name,\n  industry = industry\n)\n\nこのindustry変数はカテゴリー変数ですが，文字列型になっているので，因子型に変換してみます。\n\nfirm_data &lt;- firm_data |&gt;\n    mutate(\n        industry = forcats::fct_inorder(industry)\n        )\nclass(firm_data$industry)\n\n[1] \"factor\"\n\n\nforcatsパッケージには非常に便利な関数がたくさんあるので，ぜひドキュメントを参照してみてください。代表的なものに\n\n\nas_factor() : 他の型から因子型に変換\n\nfct_inorder() : 出現順にレベルを設定\n\nfct_order() : 頻度順にレベルを設定\n\nfct_relevel() : レベルの順序を変更\n\nfct_recode() : レベルの名前を変更\n\nfct_collapse() : レベルをまとめる\n\nfct_lump() : 頻度の低いレベルをまとめる\n\nがあります。\n\n3.7.2 日付型入門\n日付データとは、年月日や時間を表すデータです。 たとえば、“2026-02-03”や”2025-01-01 00:00:01”のような形式で表されます。 日付データは、文字列として記録されていることが多いので、日付型に変換する必要があります。 日付データの操作にはtidyverseのlubridateパッケージを使うと便利です。 lubridateパッケージには、日付データを簡単に操作するための関数がたくさんあります。\n\n\nymd() : 年月日形式の文字列を日付型に変換\n\nmdy() : 月日年形式の文字列を日付型に変換\n\nhms() : 時分秒形式の文字列を時刻型に変換\n\nymd_hms() : 年月日時分秒形式の文字列を日付型に変換\n\ntoday() : 今日の日付を取得\n\nnow() : 現在の日付と時刻を取得\n\nたとえば，次のように日付っぽい値になっている文字列型なら、lubridateパッケージが判別して日付型に変換してくれます。 今回は、2022-01-15のように年月日の形式なのでymd()関数を使います。\n\ndate &lt;- c(\"2022-01-15\", \"2023/01/15\")\nclass(date)\n\n[1] \"character\"\n\n\n\n文字列型の日付データをDate型に変換したい場合は，次のようにします。\n\ndate &lt;- lubridate::ymd(date) # 年月日\ndate\n\n[1] \"2022-01-15\" \"2023-01-15\"\n\nclass(date)\n\n[1] \"Date\"",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R言語入門</span>"
    ]
  },
  {
    "objectID": "chapter03.html#外部パッケージ",
    "href": "chapter03.html#外部パッケージ",
    "title": "\n3  R言語入門\n",
    "section": "\n3.8 外部パッケージ",
    "text": "3.8 外部パッケージ\npacmanパッケージのp_load()関数を使うと，CRANに登録されているパッケージのうち，必要なパッケージを一括でインストール・読み込みできます。 未インストールのパッケージなら自動でインストールして読み込み、インストール済みのパッケージならそのまま読み込みます。 たとえば，tidyverseパッケージとskimrパッケージをインストール・読み込みするには，次のようにします。\n\npacman::p_load(tidyverse, skimr)\n\nまれに，開発中のパッケージをGitHubからインストールしたい場合があります。その場合は，pacmanパッケージのp_load_gh()関数を使います。たとえば，username/repoというGitHubリポジトリからパッケージをインストール・読み込みするには，次のようにします。\n\npacman::p_load_gh(\"username/repo\")\n\nこれで，GitHubからパッケージがインストールされ，読み込まれます。 GitHubリポジトリにあるパッケージはCRANに登録されていないため、自己責任で使用してください。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R言語入門</span>"
    ]
  },
  {
    "objectID": "chapter04.html",
    "href": "chapter04.html",
    "title": "\n4  財務データの取得と可視化\n",
    "section": "",
    "text": "4.1 ディスクロージャー制度の概要とデータの入手先\nここでは，ROE(Return on Equity)を計算してみます。 ROEの定義は，\nROE_t = \\frac{X_t}{BE_{t-1}}\nとなります。 分子のX_tはt期の当期純利益，分母のBE_{t-1}はt期首の株主資本です。 練習用データであるfinancial_date.csvには，当期純利益はXという列名で収録されていますが、株主資本の列はありません。 よってデータから株主資本は次のように計算します。\nBE_t = \\underbrace{(OA_t - OL_t)}_{NOA_t} - \\underbrace{(FO_t - FA_t)}_{NFO_t}\nこの計算を行い，新しい変数BEをデータフレームに加えるには，dplyr::mutate()を使います。\n分母の株主資本は期首，つまり前期末の数値を用いる必要があります。 1期前の値を参照するには，lab()関数を用います。 ただ，クロスセクションのデータで普通にlag()関数を用いると，次のように別の企業のデータを参照してしまいます。\n結果のfirm_IDが2の企業の2015年のROEを計算するには，1期前の企業1の2014年の株主資本を参照する必要があるけれど，2014年のデータは存在しないため、企業2の2015年度のROEは欠損値NAになっている必要があるのに、lag()関数が1つ前の企業1の2020年の株主資本を参照してしまっています。 ROEを企業ごとに計算するために，mutate()関数の引数として、.by = firm_IDを指定します。\n2015年のROEが欠損値になっており、正しい計算ができています。 クロスセクション分析におけるlag()関数の問題点を分かりやすくするために、上のようにlagged_BE変数とROE変数を別々に作成しましたが、通常は次のように書きます。\nこれでROEの計算ができので、次にROEのヒストグラムを作ってみます。\nROEの分布が分かりました。赤字企業が分かりやすいように、ROEがゼロのところに縦線を引いてみます。 縦線を引くにはgeom_vline()を使い、横線を引くにはgeom_hline()を使います。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>財務データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter04.html#ディスクロージャー制度の概要とデータの入手先",
    "href": "chapter04.html#ディスクロージャー制度の概要とデータの入手先",
    "title": "\n4  財務データの取得と可視化\n",
    "section": "",
    "text": "4.1.1 法定開示と適時開示\n\n\n\n年次開示\n四半期開示\n重要事実\n\n\n\n法定開示\n有価証券報告書\n四半期報告書\n臨時報告書\n\n\n適時開示\n決算短信\n四半期決算短信\n適時開示\n\n\n\n4.1.2 財務データの入手先\n\n\nEDINET：全上場企業の法定開示資料データベース，XBRL形式も提供\n\nTDnet：上場企業の決算短信データベース, XBRL形式も提供\n\nXBRL(eXtensible Business Reporting Language)形式で財務諸表などの主要情報を公開しています。 XBRL形式を学習しておくと，EDINETやTDnetから直接データを取得してRで分析することもできるので便利ですが，なかなか面倒なことが多いので，大学生なら大学が契約してくれているデータベースを活用しましょう。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>財務データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter04.html#rを利用した財務データの分析",
    "href": "chapter04.html#rを利用した財務データの分析",
    "title": "\n4  財務データの取得と可視化\n",
    "section": "\n4.2 Rを利用した財務データの分析",
    "text": "4.2 Rを利用した財務データの分析\n\n4.2.1 tidyverseパッケージの概要\ntidyverseとは，R神Wickham氏が基本コンセプトを設定し，整然データ(tidy data)に対して一貫した記法でデータを扱えるパッケージ群です。 インストールと読み込みは以下の通りです。\n\n#install.packages(\"pacman\") # まだなら1回だけ実行\npacman::p_load(tidyverse)\n\ntidyverseパッケージを読み込むことで，次の代表的なパッケージが読み出されます。\n\n\ndplyr データハンドリング　めっちゃ使う\n\ntidyr tidyデータにもっていく　使う\n\nreadr データを読み込む めっちゃ使う\n\nforcats ファクター型変数の操作　めっちゃ使う\n\nggplot2 データの可視化　めっちゃ使う\n\npurrr 関数型プログラミングで使う　慣れてくると使う\n\ntibble data.frameではなくtibbleにする　あまり使わない\n\nstringr 文字列の加工・操作　ちょいちょい使う\n\n4.2.2 財務データの読み込み\n準備として，サポートサイトにある練習用のデータセットch04_financial_data.csvをダウンロードして，作業ディレクトリに置いておきましょう。\n\n\n作業ディレクトリの場所を確認するにはgetwd()を使います。 作業ディレクトリを変更するときは，setwd()で作業ディレクトリを絶対パスで指定するとよいでしょう。\nreadrパッケージのread_csv()関数を使って，CSVファイルを読み込みます。 read_csv()関数は，\n\nデータの読み込みが高速かつ型の推論が柔軟\n基本のdata.frameではなく，その拡張版であるtibbleで返す\n列名を勝手に変換しない。\n文字列を勝手にファクター型にしない(read.csv()だと勝手にファクターになる)。\n\nという利点があります。\n\n\n\nデータの読み込み\n\nfinancial_data &lt;- read_csv(\"data/ch04_financial_data.csv\")\nnrow(financial_data) # 行数\n\n\n[1] 7920\n\nncol(financial_data) # 列数\n\n[1] 11\n\nhead(financial_data, 5) # 最初の5行\n\n# A tibble: 5 × 11\n   year firm_ID industry_ID sales    OX   NFE     X     OA    FA    OL     FO\n  &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1  2015       1           1 5261.  437.  NA    287. 13006. 3543. 4373.  2481.\n2  2016       1           1 5949.  564.  50.7  513. 13866. 4642. 4534.  3960.\n3  2017       1           1 6505.  691.  29.5  662. 13953. 7744. 5111.  6159.\n4  2018       1           1 6846.  751.  86.5  665. 18818. 7285. 5137. 10124.\n5  2019       1           1 7572.  959. 298.   660. 18190  9735. 5488. 11362.\n\n\nこのfinancial_dataには、11個の変数に観測値が7920個あることがわかります。\n\n\nyear : 年度\n\nfirm_ID : 企業ID\n\nindustry_ID : 産業ID\n\nsales : 売上高\n\nOX : 事業利益(operating income)\n\nNFE : 純金融費用(net financial expenses)\n\nX : 当期純利益(net income)\n\nOA : 事業資産(operating assets)\n\nOL : 事業負債(operating liabilities)\n\nFE : 金融資産(financial assets)\n\nFO : 金融負債(financial obligations)\n\nこのデータフレームの構造をdplyrパッケージのglimpse()を使って確認します。\n\nglimpse(financial_data)\n\nRows: 7,920\nColumns: 11\n$ year        &lt;dbl&gt; 2015, 2016, 2017, 2018, 2019, 2020, 2015, 2016, 2017, 2018…\n$ firm_ID     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4…\n$ industry_ID &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ sales       &lt;dbl&gt; 5261.40, 5948.96, 6505.06, 6846.38, 7572.24, 7537.63, 3505…\n$ OX          &lt;dbl&gt; 437.49, 564.14, 691.18, 751.29, 958.53, 778.37, 45.82, 51.…\n$ NFE         &lt;dbl&gt; NA, 50.667498, 29.543157, 86.486500, 298.049774, -65.45877…\n$ X           &lt;dbl&gt; 286.64, 513.48, 661.64, 664.80, 660.48, 843.83, 40.07, 49.…\n$ OA          &lt;dbl&gt; 13005.55, 13865.58, 13952.58, 18818.48, 18190.00, 20462.86…\n$ FA          &lt;dbl&gt; 3543.43, 4642.16, 7743.99, 7284.72, 9735.13, 10274.25, 225…\n$ OL          &lt;dbl&gt; 4372.96, 4534.22, 5111.22, 5137.28, 5487.96, 5371.38, 1840…\n$ FO          &lt;dbl&gt; 2480.72, 3959.70, 6159.02, 10123.91, 11362.22, 13772.15, 2…\n\n\n変数はすべて数値型doubleになっていますが、firm_IDとindustry_IDはカテゴリーを表す変数ですので、数値型ではなくファクター型に変換します。ついでにyearは年度という時間を尺度なので、数値型ではなくfactor型に変換します。 ここで重要なのは、yearはただのファクター型ではなく、順序のあるファクター型とすることです。 ここではforcatsパッケージのas_factor()を使います。\n\n# firm_IDとindustry_IDをfactor型に変換\nfinancial_data &lt;- financial_data |&gt;\n  mutate(\n        year = as_factor(year),\n        firm_ID = as_factor(firm_ID),\n        industry_ID = as_factor(industry_ID)\n  )",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>財務データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter04.html#探索的データ分析",
    "href": "chapter04.html#探索的データ分析",
    "title": "\n4  財務データの取得と可視化\n",
    "section": "\n4.3 探索的データ分析",
    "text": "4.3 探索的データ分析\n\n4.3.1 データセットの概要確認\nデータセットを操作するまえに，データの概要を大まかにつかむ必要があり，この作業を探索的データ分析(exploratory data analysis)といいます。 仮説などを持たず，とりあえず特徴や構造を理解するための方法です。 データセットの概要を確認するために，skimrパッケージのskim()関数を用います。\n\n引数の型に応じて自動的に最適な結果を返す機能を多態性 (polymorphism)といい，多態性をもつ関数を総称関数(generic function)という。\n\n\nskimr::skim(financial_data)\n\n\nData summary\n\n\nName\nfinancial_data\n\n\nNumber of rows\n7920\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n8\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\nyear\n0\n1\nFALSE\n6\n202: 1363, 201: 1356, 201: 1323, 201: 1319\n\n\nfirm_ID\n0\n1\nFALSE\n1515\n1: 6, 2: 6, 3: 6, 4: 6\n\n\nindustry_ID\n0\n1\nFALSE\n10\n3: 1760, 10: 1702, 7: 1334, 1: 1143\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\nsales\n0\n1\n166007.00\n381980.29\n205.34\n16103.33\n40430.74\n118313.82\n3496433.0\n▇▁▁▁▁\n\n\nOX\n0\n1\n7968.91\n25951.56\n-353606.72\n399.28\n1602.88\n5260.46\n398034.5\n▁▁▇▁▁\n\n\nNFE\n1\n1\n64.02\n5941.34\n-285383.87\n-66.43\n-1.19\n41.36\n331035.2\n▁▁▇▁▁\n\n\nX\n0\n1\n7904.88\n26910.18\n-357624.83\n383.27\n1586.10\n5204.60\n572588.7\n▁▇▁▁▁\n\n\nOA\n0\n1\n152272.76\n453879.24\n216.51\n12559.91\n30799.24\n93469.20\n7987936.2\n▇▁▁▁▁\n\n\nFA\n0\n1\n80185.35\n422852.06\n288.43\n6835.07\n19095.33\n52117.92\n29250611.1\n▇▁▁▁▁\n\n\nOL\n0\n1\n50260.88\n148602.43\n35.04\n3964.84\n10868.31\n33110.89\n2817974.8\n▇▁▁▁▁\n\n\nFO\n0\n1\n70680.61\n290625.71\n43.64\n3757.44\n11125.20\n35446.03\n7026923.6\n▇▁▁▁▁\n\n\n\n\n\nさらに，データセットのある変数に含まれる固有な要素を抽出するには，unique()関数を用います。\n\nunique(financial_data$year) # financial_dataのyear変数に含まれる固有要素\n\n[1] 2015 2016 2017 2018 2019 2020\nLevels: 2015 2016 2017 2018 2019 2020\n\n# 2015, 2016, 2017, 2018, 2019, 2020\n\n固有要素の数を確認するには，unique()関数で取り出した要素の数をlength()関数で返します。 企業-年の企業数と年度数を確認するには次のようにします。\n\n\n\n企業数と産業数の確認\n\nsort(unique(financial_data$year))\n\n\n[1] 2015 2016 2017 2018 2019 2020\nLevels: 2015 2016 2017 2018 2019 2020\n\nfinancial_data$firm_ID |&gt; n_distinct()\n\n[1] 1515\n\nfinancial_data$industry_ID |&gt; n_distinct()\n\n[1] 10\n\n\nよってこのデータには10の産業、1515の企業があることが分かります。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>財務データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter04.html#欠損データの処理",
    "href": "chapter04.html#欠損データの処理",
    "title": "\n4  財務データの取得と可視化\n",
    "section": "\n4.4 4.3.2 欠損データの処理",
    "text": "4.4 4.3.2 欠損データの処理\nほとんどのデータセットには，欠損値(NA)が含まれているため，この欠損値の処理は非常に重要になります。 欠損値の有無を確認するためには，complete.cases()関数を用いるのが便利です。 欠損値が含まれているとFALSEを返し，欠損値がないとTRUEを返します。\n\nhead(complete.cases(financial_data)) # 最初の６行の結果を表示\n\n[1] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\nsum()関数で，TRUEの個数を数え上げることもできます。\n\nsum(complete.cases(financial_data)) # TRUE/FALSEを1/0に置き換えて合計\n\n[1] 7919\n\n\n欠損値の出現に何らかの傾向がある場合，欠損値の削除が生存者バイアス(survivorship bias)をもたらす可能性があります。 たとえば，過去20年間にわたって連結財務諸表データに欠損値が含まれていない上場企業ばかりを分析すると，途中で倒産したり上場したりした企業は削除され，20年間経営し続けている優良企業しかデータに残らない生存者バイアスが発生します。\nこのようなバイアスを考慮しなくても良いなら，欠損値をもつ個体(unit)のデータ(行)を削除するのが単純な処理となります。 このとき，tidyrパッケージに含まれるdrop_na()関数を用いると簡単に欠損値を含む行を削除できます。 基本関数のna.omit()でもよいですが，tidyr::drop_na()の方がオプションが豊富なのでおすすめです。\n\nnrow(financial_data) # 欠損行を削除する前の行数\n\n[1] 7920\n\nnrow(drop_na(financial_data)) # 欠損行を削除した場合の行数\n\n[1] 7919\n\nfinancial_data &lt;- drop_na(financial_data) # 欠損行を削除した上でデータを上書き\n# この作業には注意が必要である。オリジナルデータはそのまま残しておいたほうが良い\n\n欠損値を含む行を削除するのではなく，欠損値に適切な推定値を代入することでサンプルサイズを減らさない方法も開発されていますが，欠損値の出現を説明する確率モデルを仮定し，その推定値を求める必要があります。\n\n\n\n\n\n\nNote\n\n\n\n詳しくは髙橋・渡辺 (2019) 欠損データ処理：Rによる単一代入法と多重代入法 を参照してください。\nさらに欠損値についての議論では，星野・岡田 (2016)「欠測データの統計科学―医学と社会科学への応用」岩波書店がめちゃめちゃ有用です。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>財務データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter04.html#データの抽出とヒストグラムによる可視化",
    "href": "chapter04.html#データの抽出とヒストグラムによる可視化",
    "title": "\n4  財務データの取得と可視化\n",
    "section": "\n4.5 データの抽出とヒストグラムによる可視化",
    "text": "4.5 データの抽出とヒストグラムによる可視化\n\n4.5.1 条件にあうデータの抽出方法\n教科書では複数の方法が紹介されているが，このメモではtidyverseパッケージを用いた方法だけ取り上げます。具体的には，データベース操作のパッケージであるdplyrの中のfilter()関数について説明します。 さらにmagrittrを用いたパイプ演算子|&gt;を用いたデータの受け渡しの記法を活用して，可読性の高いソースコードを書くことも紹介します。 ここではdplyrパッケージのfilter()関数であることを明示的に示すため、dplyr::filter()と書いていますが、dplyrパッケージを読み込んでいる場合はfilter()と書いても同じです。\n\nfinancial_data_2015 &lt;- financial_data |&gt;\n    dplyr::filter(year == 2015) # year変数が2015のデータを抽出\n\nfilter()で条件を満たすデータのみを取り出し，それをfinancial_data_2015に代入している。\nパイプ演算子|&gt;は左のオブジェクトを右の関数の第1引数に代入する，という処理を行います。 つまり，x |&gt; filter(year == 2015)は，filter(x, year == 2015)と同じ意味になります。 パイプ演算子を使うことで，データが次の処理に受け渡されていくプロセスが読みやすくなります。たとえば、\n\n欠損値を除去して，\n2015年のデータを抽出し，\nROEを計算して，\n産業ごとに平均値を出す\n\nというよく使いそうな処理を行いたい場合，tidyverseなら次のように書きます。\n\nfinancial_data |&gt;\n    drop_na() |&gt; # 欠損値を除去し，\n    filter(year == 2015) |&gt; # 2015年のデータを抽出し，\n    mutate(\n        ROE = earnings / equity\n        ) |&gt; # ROEを計算し，\n    summarise(\n        mean_ROE = mean(ROE), # mean()で平均値を計算\n        by = industry_ID # 産業ごとに\n    )\n\n基本関数の場合は、\n\nfinancial_data &lt;- na.omit(financial_data)\nfinancial_data_2015 &lt;- financial_data[financial_data$year == 2015, ]\nfinancial_data_2015$ROE &lt;- financial_data_2015$earnings / financial_data_2015$equity\nmean_ROE_by_industry &lt;- aggregate(financial_data_2015$ROE,\n        by = list(financial_data_2015$industry),\n        FUN = mean)\n\nとなりますので、上の方が読みやすいことがわかります。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>財務データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter04.html#ヒストグラムによる売上高の可視化",
    "href": "chapter04.html#ヒストグラムによる売上高の可視化",
    "title": "\n4  財務データの取得と可視化\n",
    "section": "\n4.6 4.4.2 ヒストグラムによる売上高の可視化",
    "text": "4.6 4.4.2 ヒストグラムによる売上高の可視化\n\n4.6.1 ヒストグラム\nヒストグラム(histogram)は，データの分布を可視化するためのグラフです。 ヒストグラムは，連続データを区間に分けて，区間ごとのデータの個数を棒グラフで表現したものです。したがってヒストグラムの棒の高さは、その区間に含まれるデータの個数を表します。\nたとえば、例として生徒100人の身長データがあるとします。 この身長データをRで生成するには，rnorm()関数を使います。\n\n# 平均170cm，標準偏差5cmの正規分布から100個のデータを生成\nheight &lt;- rnorm(100, mean = 170, sd = 5)\nprint(height)\n\n  [1] 178.4065 169.3747 172.8323 165.1019 163.0505 170.8189 171.1842 171.4337\n  [9] 173.3815 167.0513 174.2004 170.3484 166.4049 173.9655 167.7656 172.0565\n [17] 179.1289 164.9742 181.2361 170.6859 181.2653 175.2366 176.4297 168.7542\n [25] 167.4855 178.9095 173.9411 159.3116 164.0196 169.0665 164.1006 166.7217\n [33] 174.3263 157.5980 174.4226 176.9461 165.3805 172.3348 176.9741 164.6956\n [41] 174.4786 175.1558 175.8099 169.9111 171.6083 173.7775 161.7053 180.2021\n [49] 164.6172 176.2878 164.8292 174.9085 167.8020 165.0033 171.0823 171.8507\n [57] 168.7531 179.6715 172.4624 172.6359 170.4693 167.7794 159.7243 172.6310\n [65] 166.6284 172.2334 170.2458 165.9444 171.2900 169.8674 170.5213 166.6858\n [73] 168.1182 168.4997 163.2053 168.0974 172.6321 164.6079 171.4338 173.9216\n [81] 175.5060 168.8628 176.2906 171.2065 170.7491 174.0878 166.6361 170.2087\n [89] 179.6689 174.1938 179.8220 159.8830 182.7523 171.7818 178.3772 163.6710\n [97] 171.0713 179.3818 171.9733 166.6188\n\n\n100個のデータを眺めていても、なかなか特徴をつかめませんよね。そこでこの身長という連続データを5センチごとの区間に分けます。たとえば、165cm以上、170cm未満の区間には何人の生徒がいるのか、170cm以上、175cm未満の区間には何人の生徒がいるのか、というように区間ごとのデータの個数を数えます。 このとき、区間の幅を5cmにするか、10cmにするか、20cmにするか、ということは、データの特徴をつかむ上で重要なことです。区間の幅を大きくすると、データの特徴がざっくりとしかつかめません。一方、区間の幅を小さくすると、データの特徴が細かくつかめますが、データの個数が少ない区間が多くなり、データの特徴をつかむのに時間がかかります。 やってみましょう。\n\nhist(height, breaks=seq(150,190,by=5)) # 区間の幅を5cmにする\n\n\n\n\n\n\nhist(height, breaks=seq(150,190,by=10)) # 区間の幅を10cmにする\n\n\n\n\n\n\nhist(height, breaks=seq(150,190,by=1)) # 区間の幅を1cmにする\n\n\n\n\n\n\n\nどのヒストグラムがデータの特徴を最も良く表しているのか、を考えて区間幅を設定しましょう。\n\n4.6.2 ggplotでヒストグラム\nヒストグラムを書くためには，基本関数のhist()が最も簡単ですが，より高性能なggplot2を用いたヒストグラムの書き方を説明します。 ここでは、上で作成した2015年のデータfinancial_data_2015を使って、売上高のヒストグラムを書きます。\nggplot2の書き方は少し特殊ですが、慣れてくると非常に便利です。 ggplot2ではレイヤー(階層)を上から重ねていくようにグラフを作っていきます。 まずggplot()関数でグラフの土台を作ります。ggplot()に入れるデータの型はdata.frameでなければならないので注意しましょう。\n\ng &lt;- ggplot(data = financial_data_2015)\nprint(g)\n\n\n\n\n\n\n\n真っ白で何も出力されていませんが、financial_data_2015というデータフレームを指定して、グラフの土台を作りました。\n次に軸の設定をします。ヒストグラムは1変数のグラフなのでx軸のみを設定します。aes()関数で変数を指定します。\n\ng &lt;- g + aes(x = sales)\nprint(g)\n\n\n\n\n\n\n\n横軸が表示されました。 この上に、ヒストグラムを書くためにgeom_histogram()関数を追加します。 ggplot2パッケージでは、geom_***の形でグラフを指定します。例えば、\n\n\ngeom_bar 棒グラフ\n\ngeom_point 散布図\n\ngeom_line 折れ線グラフ\n\ngeom_boxplot 箱ひげ図\n\ngeom_histogram ヒストグラム\n\nあたりがよく使われるグラフです。\n\ng &lt;- g + geom_histogram() # グラフはヒストグラム\nprint(g)\n\n\n\n\n\n\n\nここでコンソールに，\n\nstat_bin() using bins = 30. Pick better value with binwidth.\n\nというメッセージが出ますが、これは「何も指定されなかったので，ヒストグラムのビンの数を30にして作図したけど，オプションのstat_bin()で適切な区間幅をbinwidthで設定してね」ということです。無視しても大丈夫です。\nx軸が指数表記となっていて見づらいので，scales()関数を使って表記を変更します。\n\ng &lt;- g + scale_x_continuous(label = scales::label_comma()) # 3桁ごとにコンマで区切った数値で表示\nprint(g)\n\n\n\n\n\n\n\n横軸の数値が変化したことが分かります。\nまた、小数ながら非常に大きな売上高をもつ企業があるため，ヒストグラムの形が左側に集まるように歪んでいます。 そこで売上高を自然対数に変換して，分布の歪みを修整したヒストグラムを書いてみます。 データを変更するので、最初から全部書きます。\n\ng &lt;- ggplot(financial_data_2015) +\n  aes(x = log(sales)) + # log()で自然対数変換\n  geom_histogram()\nprint(g)\n\n\n\n\n\n\n\nうまくいきました。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>財務データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter04.html#データの集計と折れ線グラフによる可視化",
    "href": "chapter04.html#データの集計と折れ線グラフによる可視化",
    "title": "\n4  財務データの取得と可視化\n",
    "section": "\n4.7 データの集計と折れ線グラフによる可視化",
    "text": "4.7 データの集計と折れ線グラフによる可視化\n\n4.7.1 dplyrを用いた集計\nもっとデータを加工して、データの特徴をつかむグラフを作成してみます。 データを加工するために、非常に便利なパッケージであるtidyverseのdplyrを用いたデータ加工を説明します。dplyrでよく使う関数に、\n\nsummarise()\nmutate()\nfilter()\n\nがあります。これらの関数を組み合わせることで、データの加工が非常に簡単にできます。 特定の変数ごとにデータをグループ化するには，mutate()関数やsummarise()関数の中で、.by = c(vars)という引数を用います。\n\n\n以前は、dplyrパッケージのgroup_by()関数を用いてグループ化を行っていましたが、複数の変数でグループ化を行ったとき、ungroup()関数でグループ化を解除する必要があり、また全てのグループ化を解除するにも手間でした。 dplyrの新しいバージョンでは、group_byを用いずに、summarise()やmutate()関数の中で.by引数を用いることで、グループ化と集計を一度に行うことができ、また処理後はグループ化が完全に解除されるので、コードがシンプルになります。\nたとえば、financial_dataに含まれる売上高を年度ごとに集計してみましょう。\n\nN_firms_by_year &lt;- financial_data |&gt;\n    summarize( # 以下の統計量を計算\n        N_firms = n(), # データ個数 n()\n        mean_sales = mean(sales), # 売上高の年度平均 mean()\n        .by = year # year変数ごとにグループ化\n    )\n\nこれでN_firms_by_yearというオブジェクトに、financial_dataを年度ごとにグループ化して、年度ごとの企業数N_firmsと平均売上高mean_saleを計算したデータが入っています。 2015年から2020年の6年間のデータがあるので、6行のデータが入っているはずです。 中身を確認しておきましょう。\n\nglimpse(N_firms_by_year)\n\nRows: 6\nColumns: 3\n$ year       &lt;fct&gt; 2016, 2017, 2018, 2019, 2020, 2015\n$ N_firms    &lt;int&gt; 1293, 1319, 1323, 1356, 1363, 1265\n$ mean_sales &lt;dbl&gt; 173359.5, 170010.9, 157995.4, 160928.2, 161043.7, 173614.9\n\n\n以下の変数について6個のデータが入っていることがわかります。\n\n\nyear : 年度 (ord)\n\nN_firms : 企業数 (int)\n\nmean_sales : 平均売上高 (dbl)\n\n\n\n\n\n\n\nNote\n\n\n\n関数型プログラミング(functional programming)は，現代的なプログラミング・パラダイムの1種であり，定義された関数を用いて各データに対して行いたい処理を切り分ける。Rではapply系関数として，様々な関数が用意されている。tidyverse群では，purrrがある。ちょっと難しいですがpurrr超便利\n\n\n\n4.7.2 折れ線グラフによる上場企業数の可視化\nデータの成形が終わったので，折れ線グラフを作っていきます。 ここではx軸(横軸)を年度year，y軸(縦軸)を上場企業数N_firmsとする折れ線グラフを作ってみます。 折れ線グラフを作るにはgeom_line()関数を使います。\n\ng &lt;- ggplot(N_firms_by_year) +\n    aes(x = year, y = N_firms, group=1) +\n    geom_line()\ng &lt;- g + labs(x = \"Year\", y = \"Number of Firms\") # 軸ラベル\nprint(g)\n\n\n\n\n\n\n\nここで突然現れたgroup = 1というaes()のオプションですが、これはすべてのデータが同じグループに属していることを指定しています。 x軸にファクター型を指定する場合、group = 1を指定しないと、x軸の値ごとに別のグループとして認識されてしまい、折れ線グラフがうまく描けません。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>財務データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter04.html#変数の作成とヒストグラムによる可視化",
    "href": "chapter04.html#変数の作成とヒストグラムによる可視化",
    "title": "\n4  財務データの取得と可視化\n",
    "section": "\n4.8 変数の作成とヒストグラムによる可視化",
    "text": "4.8 変数の作成とヒストグラムによる可視化\ntidyverseのdplyrパッケージのmutate()関数を用いれば，パイプ演算子|&gt;を用いて可読性の高いシンプルな書き方で、新しい変数を作成することができます。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>財務データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter04.html#キーボードショートカット",
    "href": "chapter04.html#キーボードショートカット",
    "title": "\n4  財務データの取得と可視化\n",
    "section": "\n4.9 キーボードショートカット",
    "text": "4.9 キーボードショートカット\nMacならcommand + shift + mでパイプ演算子が入力できます。 Windowsならctrl + shift + mです。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>財務データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter04.html#グループごとの集計とランク付け",
    "href": "chapter04.html#グループごとの集計とランク付け",
    "title": "\n4  財務データの取得と可視化\n",
    "section": "\n4.10 グループごとの集計とランク付け",
    "text": "4.10 グループごとの集計とランク付け\n\n4.10.1 産業ごとのROE平均値と棒グラフによる可視化\nグループごとに平均値を出すといった処理は，dplyr::summarise()の引数で.by=varを指定すれば簡単です。 ここでは、産業ごとにROEの平均値と標準偏差を求めてみます。 ROEには欠損値が含まれているため、mean()関数を使うとNAが返ってきます。NAを無視して平均値を計算するには、mean()関数のオプションna.rm = TRUEを指定します。\n\ndf_ind &lt;- financial_data |&gt;\n    summarize(\n        mean_ROE = mean(ROE, na.rm = TRUE), # 産業平均\n        sd_ROE = sd(ROE, na.rm = TRUE),　# 産業標準偏差\n        .by = industry_ID # 産業ごとにグループ化\n    )\nglimpse(df_ind)\n\nRows: 10\nColumns: 3\n$ industry_ID &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n$ mean_ROE    &lt;dbl&gt; 0.07731106, 0.10761577, 0.07548896, 0.07371925, 0.08570296…\n$ sd_ROE      &lt;dbl&gt; 0.09264764, 0.09530125, 0.05569899, 0.04676826, 0.04859797…\n\n\n10の産業ごとに統計量を計算したので、10行のデータが返ってきました。 このデータを用いて産業ごとのROE平均の棒グラフを作成してみます。\n\n# 作図\nggplot(df_ind) + # データフレームを指定\n    aes(x = industry_ID, y = mean_ROE) + # 変数を2つ指定\n    geom_col() + # 棒グラフ geom_bar()もあるけどこっち\n    labs(x = \"industry ID\", y = \"Industry Average ROE\") + # ラベル設定\n    scale_y_continuous(expand = c(0,0)) # グラフの原点0,0に設定\n\n\n\n\n\n\n\n教科書では，パイプ処理で直接ggplot()にデータフレームを渡していますが，個人的に可読性が低くなりオススメできないので，上の例ではデータ操作と作図を分けて書きました。\n次に、2020年度の産業別ROEランキングを作ってみます。 ROEを大きい順にならべて、一番大きい企業に1、2番目の企業に2、という風にランキングを表す変数を作成するには、rank(desc())を使います。desc()は降順に並べ替える関数です。\n下のソースコードでは、前半のまとまりで、以下の処理を行ったデータを新しいデータフレームROE_rank_dataに代入しています。\n\n\nfinancial_dataの中から2020年度のデータを抽出し、\n必要な変数としてfirm_ID、industry_ID、ROEの3つを選択し、\n\nindustry_IDごとにグループ化して、\n\nmutate()関数でROE_rank変数を作成し,\n\nungroup()関数でグループ化を解除しています。\n\n後半のまとまりでは、上で作成したROE_rank_dataに対して、\n\n産業ごとのROEランキング第1位の企業を抽出し、\nROEが大きい順に並べ替えて、\nそれをknitr::kable()関数で表として出力\n\nという処理をしています。\n\n# 2020年度の産業内のROEランキングの変数を作成\nROE_rank_data &lt;- financial_data |&gt;\n    filter(year == 2020) |&gt;\n    select(firm_ID, industry_ID, ROE) |&gt;\n    mutate(  # summarize を mutate に変更\n        ROE_rank = rank(desc(ROE)),\n        .by = industry_ID\n    )\n\nROE_rank_data |&gt;\n    filter(ROE_rank == 1) |&gt; # 各産業のランク1のものを抽出\n    arrange(desc(ROE)) |&gt;  # ROEが大きい順\n    knitr::kable(booktabs = TRUE, # ここから下は表の装飾\n        caption = \"2020年度産業別ROEランキング第1位企業\",\n        position = \"h!\" # 表示場所はここに\n        )\n\n\n2020年度産業別ROEランキング第1位企業\n\nfirm_ID\nindustry_ID\nROE\nROE_rank\n\n\n\n929\n7\n0.5641813\n1\n\n\n475\n3\n0.4975356\n1\n\n\n8\n1\n0.3882552\n1\n\n\n242\n2\n0.3749986\n1\n\n\n661\n5\n0.2673141\n1\n\n\n1042\n8\n0.2559963\n1\n\n\n1380\n10\n0.2497929\n1\n\n\n1167\n9\n0.2346232\n1\n\n\n619\n4\n0.1491307\n1\n\n\n719\n6\n0.1422026\n1",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>財務データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter04.html#上級デュポンモデルによるroeの分析とその可視化",
    "href": "chapter04.html#上級デュポンモデルによるroeの分析とその可視化",
    "title": "\n4  財務データの取得と可視化\n",
    "section": "\n4.11 上級デュポン・モデルによるROEの分析とその可視化",
    "text": "4.11 上級デュポン・モデルによるROEの分析とその可視化\n上級デュポン・モデルとは，次式で表されるROEの分解式です。\n\n\\begin{aligned}\nROE_t := \\frac{X_t}{BE_{t-1}} &= \\underbrace{\\frac{OX_t}{NOA_{t-1}}}_{RNOA_t} + \\underbrace{\\frac{NFO_{t-1}}{BE_{t-1}}}_{FLEV_{t-1}} \\times \\left[ \\frac{OX_t}{NOA_{t-1}} - \\frac{NFE_t}{NFO_{t-1}} \\right]\n\\end{aligned}\n\n各変数の意味は以下の通りです。 - X : 当期純利益(net income) - BE : 株主資本(book of equity) - OX : 事業利益(operating income) - NOA : 純事業資産(net operating assets) - NFO : 純金融負債(net financial obligations) - NFE : 純金融費用(net financial expenses)\nRNOA_tは，ATO_tとPM_tとに分割できます。\n\n\\underbrace{\\frac{OX_t}{NOA_{t-1}}}_{RNOA_t} = \\underbrace{\\frac{sales_t}{NOA_{t-1}}}_{ATO_t} \\times \\underbrace{\\frac{OX_t}{sales_t}}_{PM_t}\n\nいくつかの変数は，元のデータには含まれていないので，与えられたデータから計算する必要があります。 dplyr::mutate()関数を用いて新しい変数を作成し，データフレームに追加します。\n\nfinancial_data &lt;- financial_data |&gt;\n    mutate(\n        NOA = OA - OL, # 純事業資産 = 事業資産 - 事業負債\n        RNOA = OX / lag(NOA), # 会計上の事業リターン\n        PM = OX / sales, # 利ざや profit margin\n        ATO = sales / lag(NOA), # 純事業資産回転率\n        NFO = FO - FA, # 純金融負債 = 金融負債 - 金融資産\n        lagged_FLEV = lag(NFO) / lagged_BE, #期首財務レバレッジ\n        NBC = NFE / lag(NFO), # 債権者のリターン net borrowing cost\n        ROE_DuPont = RNOA + lagged_FLEV * (RNOA - NBC), # 上級デュポン・モデルによるROE\n        .by = firm_ID # 企業ごとにグループ化\n    )\n\nROEの分解式が合っているかどうかを確認するため，all.equal()関数を使って，第1引数と第2引数が等しいかどうかを判定してみます。 普通に計算したROEと上級デュポン・モデルの分解したものから計算したROE_DuPointとの比較しています。\n\nall.equal(financial_data$ROE, financial_data$ROE_DuPont)\n\n[1] \"Mean relative difference: 4.396878e-06\"\n\n\nとなり，差の平均は4.396878 \\times 10^{-6}となり，ほぼ0となっていることから，上級デュポン・モデルの分解式が正しいことが確認できます。 完全にゼロにならない理由は計算の過程で生じる丸め誤差によるものです。\n\n4.11.1 箱ひげ図による産業別比較\n産業別で利ざやPMがどのように分布しているのかを調べるために，箱ひげ図(box plot)を作ってみます。 箱ひげ図は，データの分布を可視化するためのグラフで，第1四分位点，中央値，第3四分位点，(異常値をのぞく)最大値，(異常値をのぞく)最小値を表現できる，非常に情報量の多いグラフです。\nggplot2パッケージのgeom_boxplot()関数を用いることで，データフレームから箱ひげ図を作図できます。\n先に作成したデータフレームfinancial_dataを用いて，PMの箱ひげ図を作成してみましょう。 あまり多くの箱ひげ図を作っても見づらくなるので，最終年度のデータ で，産業IDが2〜6までの企業に限定します。\n\ndf_2020 &lt;- financial_data |&gt;\n    filter(\n        year == 2020, # 最終年度\n        industry_ID %in% 2:6 # 産業コードが2から6\n    )\ng &lt;- ggplot(df_2020) +\n  aes(x = industry_ID, y = PM, fill = industry_ID) + geom_boxplot() # 箱ひげ図\ng &lt;- g + labs(x = \"Industry ID\")\nprint(g)\n\n\n\n\n\n\n\n箱ひげ図から，産業ごとに利ざやの分布が異なることがわかります。とりわけ産業3は利ざやの散らばりが大きく，産業4は非常に散らばりが小さいことが分かります。\n\n4.11.2 散布図による産業別比較\n次に産業ごとに ATO(純事業資産回転率)と PM(売上高事業利益率)がどう分布しているか散布図を書いてみます。 ここでは異常値の影響を受けにくい統計量である中央値(median)を計算し，散布図を作成してみます。\n\ndf_ind_median &lt;- financial_data |&gt;\n    summarise(\n        median_ATO = median(ATO, na.rm = TRUE), # ATOの中央値\n        median_PM = median(PM, na.rm = TRUE), # PMの中央値\n        .by = industry_ID # 産業ごとにグループ化\n    )\n\ng &lt;- ggplot(df_ind_median) +\n    aes(x = median_ATO, y = median_PM, label = industry_ID) + # 散布図\n    geom_point() + # 散布図\n    geom_text(vjust=-1) # ラベル\nprint(g)\n\n\n\n\n\n\n\nこの産業ごとに計算された中央値のデータを用いて，線形回帰直線を引いて，ATOとPMの関係を見てみます。\n\ng &lt;- g + geom_smooth(method = \"lm\", se = FALSE) # 線形回帰直線を追加\nprint(g)\n\n\n\n\n\n\n\nいい感じですが，会計学入門(1.3.4節)で学習したATO \\times RM = RNOAという関係のとおり，データからもATOとPMとの間にトレードオフの関係があることが予想されています。 もし理論どおりの関係であればデータはATO = RNOA / PMといった反比例の関係になるはずです。これを示すため，RNOAを一定としたときのATOとPMの関係，つまりを図に書き込んでみます。 関数をグラフとして図に追加するためにstat_function()関数を用います。\n\nstat_function()関数の引数は，fun = function(x) xの関数系, linetype = “スタイル”とします。 ここでは，function(x)でxの関数であることを指定し，median_RNOA / xとしてます。\n\n\nmedian_RNOA &lt;- median(financial_data$RNOA, na.rm = TRUE) # 全データから計算したRNOAの中央値\n\ng &lt;- g + stat_function(\n    fun = function(x) median_RNOA / x,\n    linetype = \"longdash\",\n    color = \"red\") # 反比例の関数を追加\nprint(g)\n\n\n\n\n\n\n\nかなりあてはまりが良さそうな線が引けました。 このように，データを可視化することで，理論とデータの整合性を確認することができます。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>財務データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter05.html",
    "href": "chapter05.html",
    "title": "\n5  株式データの取得と可視化\n",
    "section": "",
    "text": "5.0.1 株価データのダウンロードと読み込み\n前章では財務データを題材に、クロスセクションデータを扱うために必要なデータの取得と操作と可視化について学習しました。 特に重要な操作として，mutate()やsummarise()関数で、.by = varを指定することでグループごとの変数の値を計算する方法を学びました。 本章では株式データを題材に，株式データの理解に必要な株式の基礎知識とともに，リターンの定義や計算について学び，最後には統計的推論と線形回帰分析についても学習します。\nいままでと同じように、readrパッケージのread_csv()関数でCSVファイルを読み込みます。 ここでは、ch05_stock_data.csvを使います。\n株式データの読み込み\n\nstock_data &lt;- read_csv(\"data/ch05_stock_data.csv\")\nprint(stock_data)\n\n\n# A tibble: 95,040 × 9\n    year month month_ID firm_ID stock_price   DPS shares_outstanding\n   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;              &lt;dbl&gt;\n 1  2015     1        1       1         954     0            2422000\n 2  2015     2        2       1         960     0            2422000\n 3  2015     3        3       1        1113     0            2422000\n 4  2015     4        4       1        1081     0            2422000\n 5  2015     5        5       1        1317     0            2422000\n 6  2015     6        6       1        1366    29            2422000\n 7  2015     7        7       1        1353     0            2422000\n 8  2015     8        8       1        1209     0            2422000\n 9  2015     9        9       1        1291     0            2422000\n10  2015    10       10       1        1407     0            2422000\n# ℹ 95,030 more rows\n# ℹ 2 more variables: adjustment_coefficient &lt;dbl&gt;, R_F &lt;dbl&gt;\n9変数，95,040行という大規模なデータが読み込まれました。 紙面の都合上、長い変数名を短く省略します。変数名を変えるには、dplyr::rename()を使います。\n変数名の変更\n\nstock_data &lt;- stock_data |&gt;\n  rename(\n    n_shares = shares_outstanding,\n    adj_coef = adjustment_coefficient\n  )\n読み込まれたデータstock_dataの中には以下の変数が含まれています。\nyear〜firm_IDまでは，時系列や企業の特定に必要なキーとなり， stock_priceからR_Fが分析する対象となる株価や配当，発行済株式数，調整係数，無リスク金利となります。 7列目のn_sharesは発行済株式数です。 発行済株式数は随時，新株発行や自社株買い，株式分割で変動するため，株式数の変化を調整するためのデータとしてadj_coefがあります。 旧株式1に対して新株式2となる株式分割が行われた場合，この調整係数は2となります。\nこのような大規模データを前にした場合，とりあえずデータの構造を把握することから始めます。 ここでは基本関数よりも多機能なtidyverseのdplyrパッケージに含まれるglimpse関数を使って，データの構造を確認してみます。\nglimpse(stock_data)\n\nRows: 95,040\nColumns: 9\n$ year        &lt;dbl&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015…\n$ month       &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7…\n$ month_ID    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ firm_ID     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ stock_price &lt;dbl&gt; 954, 960, 1113, 1081, 1317, 1366, 1353, 1209, 1291, 1407, …\n$ DPS         &lt;dbl&gt; 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 40, 0…\n$ n_shares    &lt;dbl&gt; 2422000, 2422000, 2422000, 2422000, 2422000, 2422000, 2422…\n$ adj_coef    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ R_F         &lt;dbl&gt; 6.506826e-04, 5.834099e-04, 6.114423e-04, 6.848180e-04, 7.…\nデータの型がdblという初めて出てきた型になってますが，これはdoubleの略で，数値型の一種です。doubleは64ビットの浮動小数点数を表し，小数点以下15桁までの精度を持ちます。\nたとえば，firm_IDが74，month_IDが29から32（つまり2017年5月から8月）のデータを抽出してみます。\nデータの抽出\n\nstock_data |&gt;\n  # 条件を満たすデータをfilter()で抽出\n  filter(firm_ID == 74 , month_ID %in% 29:32) |&gt;\n  # 特定の変数を抽出\n  select(\n    year, firm_ID, month_ID,\n    stock_price, n_shares, adj_coef\n  )\n\n\n# A tibble: 4 × 6\n   year firm_ID month_ID stock_price n_shares adj_coef\n  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1  2017      74       29        2816  4960000        1\n2  2017      74       30        1402  9920000        2\n3  2017      74       31        1420  9920000        1\n4  2017      74       32        1502  9920000        1\n出力された結果の2行のadj_coefが2となっており、同時にn_sharesが倍になっていることから、この会社は1株を2株に株式分割していることがわかります。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>株式データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter05.html#時価総額とリターンの計算",
    "href": "chapter05.html#時価総額とリターンの計算",
    "title": "\n5  株式データの取得と可視化\n",
    "section": "\n5.1 時価総額とリターンの計算",
    "text": "5.1 時価総額とリターンの計算\n時価総額(market capitalization)を計算するためには、株式数に株価を掛けて計算します。 新しい変数を作成するときはdplyrパッケージのmutate()関数を使います。 mutate()で時価総額を表す新しい変数MEを作成します。\n\n\n\n時価総額の計算\n\nstock_data &lt;- stock_data |&gt;\n  mutate(\n    ME = stock_price * n_shares # 時価総額\n    )\n\n\n次に時価総額のヒストグラムを作成してみます。 前節で学習した内容に加えて、いろいろ見た目の指定を増やしてみます。 scale()関数を使って軸の範囲や表記方法を細かく指定します。\n\n\n\n時価総額のヒストグラム\n\n# 日本語を含むグラフを作成するときは，dev = \"quartz_pdf\"を指定\ng &lt;- ggplot(stock_data) + aes(x = ME) +\n  geom_histogram() + # ヒストグラムを描く\n  scale_x_continuous( # 軸の範囲と表記方法の指定\n    limits = c(0, quantile(stock_data$ME, 0.95)),\n    labels = label_comma(scale = 1e-6)\n  ) + xlab(\"時価総額\") + ylab(\"度数\") +  mystyle\nprint(g) # グラフを出力\n\n\n\n\n\n\n\n\n\n5.1.1 トータル・リターンと超過リターンの計算\nある株式のt期のトータル・リターンR_tは、次式で定義されます。\n\nR_t = \\frac{(\\text{株価}_t + \\text{1株当り配当}_t) \\times \\text{調整係数}_t - \\text{株価}_{t-1}}{\\text{株価}_{t-1}}\n\nたいていの場合，1株当り配当\\text{1株当り配当}_tはゼロで，調整係数は1となるため，次式のように簡略化できます。\n\nR_t = \\frac{\\text{株価}_t - \\text{株価}_{t-1}}{\\text{株価}_{t-1}}\n\n銘柄ごとにリターンを計算するので，mutate()と.by = firm_IDを使って計算します。 ここでは，firm_IDごとにトータルリターンRと，トータルリターンから無リスク利子率を除いた超過リターンReを計算しています。\n\nstock_data &lt;- stock_data |&gt;\n  mutate( # 新しい変数を作成\n    R = ((stock_price + DPS) * adj_coef - lag(stock_price)) / lag(stock_price),\n    Re = R - R_F, # 月次超過リターン\n    .by = firm_ID # firm_IDごとにグループ\n  )\n\nここまでの処理でstock_dataに時価総額ME，トータルリターンR，超過リターンReが追加されました。 以下では，このデータを使って探索的データ分析を行います。\n\n5.1.2 株式データの探索的データ分析\n探索的データ分析という名の，とりあえず何も考えずに目の前のデータから何が分かるのかを調べ倒してみる，という分析を行います。\nとりあえず，summary()で基本統計量を確認します。\n\nsummary(stock_data)\n\n      year          month          month_ID        firm_ID      \n Min.   :2015   Min.   : 1.00   Min.   : 1.00   Min.   :   1.0  \n 1st Qu.:2016   1st Qu.: 3.75   1st Qu.:19.00   1st Qu.: 384.0  \n Median :2018   Median : 6.50   Median :37.00   Median : 760.0  \n Mean   :2018   Mean   : 6.50   Mean   :37.01   Mean   : 761.2  \n 3rd Qu.:2019   3rd Qu.: 9.25   3rd Qu.:55.00   3rd Qu.:1147.0  \n Max.   :2020   Max.   :12.00   Max.   :72.00   Max.   :1515.0  \n                                                                \n  stock_price          DPS              n_shares            adj_coef     \n Min.   :   112   Min.   :   0.000   Min.   :3.700e+04   Min.   :0.1000  \n 1st Qu.:  1417   1st Qu.:   0.000   1st Qu.:3.151e+06   1st Qu.:1.0000  \n Median :  2445   Median :   0.000   Median :1.014e+07   Median :1.0000  \n Mean   :  4685   Mean   :   6.802   Mean   :6.973e+07   Mean   :0.9999  \n 3rd Qu.:  4558   3rd Qu.:   0.000   3rd Qu.:3.564e+07   3rd Qu.:1.0000  \n Max.   :622796   Max.   :1913.000   Max.   :2.111e+10   Max.   :2.0000  \n                                                                         \n      R_F                   ME                  R                  Re          \n Min.   :-2.329e-04   Min.   :1.459e+08   Min.   :-0.38028   Min.   :-0.38020  \n 1st Qu.: 8.233e-06   1st Qu.:9.648e+09   1st Qu.:-0.04057   1st Qu.:-0.04076  \n Median : 8.203e-05   Median :2.563e+10   Median : 0.01033   Median : 0.01013  \n Mean   : 2.041e-04   Mean   :1.365e+11   Mean   : 0.01586   Mean   : 0.01565  \n 3rd Qu.: 4.626e-04   3rd Qu.:7.987e+10   3rd Qu.: 0.06481   3rd Qu.: 0.06460  \n Max.   : 7.368e-04   Max.   :3.293e+13   Max.   : 0.51498   Max.   : 0.51448  \n                                          NA's   :1515       NA's   :1515      \n\n\nさらに，分散と標準偏差も計算します。データには欠損値が含まれているため，na.rm = TRUEオプションをつけています。 教科書とは違いますが，dplyr::summarize()関数を使って一気に複数の統計量を計算します。 ここでは，stock_data &lt;- stock_dataとしていないため，stock_dataには新しい変数は追加されず，結果を表示するだけです。\n\nstock_data |&gt;\n  summarise(\n    var_R = var(R, na.rm = TRUE), # 総リターンの分散\n    sd_R  = sd(R, na.rm = TRUE), # 総リターンの標準偏差\n    var_Re = var(Re, na.rm = TRUE), # 超過リターンの分散\n    sd_Re = sd(Re, na.rm = TRUE) # 超過リターンの標準偏差\n  )\n\n# A tibble: 1 × 4\n    var_R   sd_R  var_Re  sd_Re\n    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 0.00830 0.0911 0.00830 0.0911\n\n\nデータの分布の形を表す統計量である，3次のモーメントである歪度(skewness)と4次のモーメントである尖度(kurtosis)も計算してみます。 たとえば確率変数xの歪度は \n\\text{歪度} = \\frac 1n \\sum _{i = 1}^n \\left( \\frac{x_i - \\bar x}{\\hat \\sigma_x} \\right) ^3\n で表され，正の値をとるとき分布が右に歪んでいる(裾が右に長い)ことを示している。 尖度は， \n\\text{尖度} = \\frac 1n \\sum _{i = 1}^n \\left( \\frac{x_i - \\bar x}{\\hat \\sigma_x} \\right) ^4\n で定義され，尖度が3のとき，正規分布と同じ尖度を持つことを示し，3より小さいとき，正規分布よりとがった分布をしていることを示します。\n歪度と尖度を計算するには，e1071パッケージのskewness()関数を使います。\n\nstock_data |&gt;\n  summarise(\n    skewness_R = skewness(R, na.rm = TRUE), # 総リターンの歪度\n    kurtosis_R = kurtosis(R, na.rm = TRUE), # 総リターンの尖度\n    skewness_Re = skewness(Re, na.rm = TRUE), # 超過リターンの歪度\n    kurtosis_Re = kurtosis(Re, na.rm = TRUE) # 超過リターンの尖度\n  )\n\n# A tibble: 1 × 4\n  skewness_R kurtosis_R skewness_Re kurtosis_Re\n       &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1      0.507       1.27       0.507        1.27\n\n\nトータルリターンの歪度が0.507 &gt;0なので，右に裾の広い分布となっており，尖度が1.27 &lt; 3なので正規分布よりもとがった形となっていることがわかります。\n図でも確認するために，トータルリターンRのヒストグラムを書いてみます。\n\nggplot(stock_data) +\n  aes(x = R) + geom_histogram() + # トータルリターンのヒストグラム\n  xlab(\"月次株式リターン\") + ylab(\"度数\") + mystyle# 軸ラベル\n\n\n\n\n\n\n\nトータルリターンのヒストグラムに正規分布のグラフを重ねてみると，次のようになります。\n\n# トータルリターン\nR &lt;- stock_data$R\n# 平均と標準偏差を計算\nm &lt;- mean(stock_data$R, na.rm = TRUE)\ns &lt;- sd(stock_data$R, na.rm = TRUE)\n\nggplot(stock_data) +\n  aes(x = R) +\n  # y軸を密度(density)に設定\n  geom_histogram(aes(y = after_stat(density)), bins = 100, alpha = 0.3, fill = \"gray50\") +\n  geom_density(color = \"blue\", linewidth = 1) +  # 密度曲線を追加\n  # 正規分布の曲線を追加\n  stat_function(\n    fun = dnorm, args = list(mean = m, sd = s),\n    color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  xlab(\"月次株式リターン\") + ylab(\"密度\") + mystyle\n\n\n\n\n\n\n\n歪度と尖度の結果と整合的に、実際のトータル・リターンのデータの確率密度(青い線)と正規分布(赤い点線)を比べてみると、実際のデータは右に裾が長く，尖度も正規分布よりもとがった形となっていることが分かります。\nより厳密にデータが正規分布にしたがっているかを確認するために，Q-Qプロットを描いてみます。\n\n\n\nQ-Qプロット\n\nggplot(stock_data) +\n  aes(sample = R) +\n  stat_qq() +\n  stat_qq_line(color = \"red\") +\n  labs(x = \"理論上の分位点\", y = \"サンプルの分位点\") +\n  mystyle",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>株式データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter05.html#リターンの累積",
    "href": "chapter05.html#リターンの累積",
    "title": "\n5  株式データの取得と可視化\n",
    "section": "\n5.2 リターンの累積",
    "text": "5.2 リターンの累積\n\n5.2.1 バイ・アンド・ホールド・リターンの考え方\nバイ・アンド・ホールド・リターン(buy-and-hold-return)は，ある時点で株式を購入し，そのまま保有し続けたときのリターンのことを指します。 たとえば，12月末に株式を購入し，3月末に売却したときの、バイ・アンド・ホールド・リターンの累積は，次式で計算できます。ただし配当は無視します。 \n\\begin{aligned}\n\\left ( \\frac{W_{\\text{3月}}}{W_{\\text{12月}}} \\right) =\n\\underbrace{\\left ( \\frac{W_{\\text{1月}}}{W_{\\text{12月}}} \\right)}_{1 + R_{\\text{1月}}} \\times\n\\underbrace{\\left ( \\frac{W_{\\text{2月}}}{W_{\\text{1月}}} \\right)}_{1 + R_{\\text{2月}}} \\times\n\\underbrace{\\left ( \\frac{W_{\\text{3月}}}{W_{\\text{2月}}} \\right)}_{1 + R_{\\text{3月}}} \\times\n\\end{aligned}\n\n一般的に、月次でt時点からT時点までの年次リターンは、\n\n\\left ( \\frac{W_{\\text{翌年12月末}}}{W_{\\text{12月末}}} \\right) = \\prod_{t = \\text{1月}}^{\\text{12月}} (1 + R_t)\n\nと計算できます。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>株式データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter05.html#年次リターンの計算",
    "href": "chapter05.html#年次リターンの計算",
    "title": "\n5  株式データの取得と可視化\n",
    "section": "\n5.3 年次リターンの計算",
    "text": "5.3 年次リターンの計算\nでは、stock_dataをもとに年次リターンを計算してみましょう。\n\nannual_stock_data &lt;- stock_data |&gt;\n  summarise(\n    annual_R = prod(1 + R) - 1, # B&H年次リターン\n    annual_R_F = prod(1 + R_F) - 1, # 年次超過リターン\n    .by = c(firm_ID, year) # 企業と年度でグループ化\n  ) |&gt;\n  mutate(\n    annual_Re = annual_R - annual_R_F # 年次超過リターン\n    )\nhead(annual_stock_data)\n\n# A tibble: 6 × 5\n  firm_ID  year annual_R annual_R_F annual_Re\n    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n1       1  2015   NA      0.00743      NA    \n2       1  2016    0.997  0.000565      0.997\n3       1  2017    0.688  0.0000488     0.688\n4       1  2018   -0.214  0.00579      -0.219\n5       1  2019    0.647 -0.000770      0.648\n6       1  2020   -0.284  0.000380     -0.285",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>株式データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter05.html#株式データと財務データを組み合わせた分析",
    "href": "chapter05.html#株式データと財務データを組み合わせた分析",
    "title": "\n5  株式データの取得と可視化\n",
    "section": "\n5.4 株式データと財務データを組み合わせた分析",
    "text": "5.4 株式データと財務データを組み合わせた分析\nここでは，株式データと財務データを組み合わせて分析を行います。\n\n5.4.1 データの結合\n複数のデータフレームを結合する際に重要なところは、\n\nデータの頻度の違い\nタイミングの一致\n\nとなる。 今まで使ってきた財務データは年次データであるのに対して，株式データは月次データであるため，データの頻度が異なります。 確認してみましょう。\n\nfinancial_data &lt;- readr::read_csv(\"data/ch04_output.csv\")\nnrow(financial_data) # 年次財務データの行数\n\n[1] 7919\n\nnrow(annual_stock_data) # 年次リターン・データの行数\n\n[1] 7920\n\nnrow(stock_data) # 月次リターン・データの行数\n\n[1] 95040\n\n\n月次リターンの行数が上の年次データとは大きく異なっていることが分かります。\n\n\n\n\n\n\n先読みバイアス(look-ahead bias)とは、ある時点での情報を使って、その時点よりも未来の情報を使っていることを指します。12月末決算の会社のディスクロジャージャーは、最速で決算日後45日以内に出される決算短信か、3ヶ月以内に出される有価証券報告書があります。 このため、年次データを使って同時期の年次リターンを計算すると、年次データの発表後に出される有価証券報告書の情報を使っていることになります。これを先読みバイアスといいます。\n\n\n\n\nannual_data &lt;- annual_stock_data |&gt;\n  full_join(\n    financial_data,\n    by = c(\"firm_ID\", \"year\")\n  ) # firm_IDとyearのペアをキーとして設定\n\n\nannual_data &lt;- annual_stock_data |&gt;\n  full_join(financial_data) # キーを省略した場合，列名が同じ変数がキーになる\n\n\nmonthly_data &lt;- stock_data |&gt;\n  full_join(financial_data, by = c(\"firm_ID\", \"year\")) # firm_IDとyearのペアをキーとして設定",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>株式データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter05.html#バブルチャート",
    "href": "chapter05.html#バブルチャート",
    "title": "\n5  株式データの取得と可視化\n",
    "section": "\n5.5 バブルチャート",
    "text": "5.5 バブルチャート\n\nannual_data &lt;- stock_data |&gt;\n  filter(month == 12) |&gt; # 12月のみ\n  select(year, firm_ID, ME) |&gt; # 変数を選択\n  full_join(annual_data, ., by = c(\"year\", \"firm_ID\")) |&gt; # 年次データと結合\n  mutate(ME = ME / 1e6)\n\n\nyear2015 &lt;- annual_data |&gt;\n   filter(\n      year == 2015, # 2015年のみ\n      firm_ID %in% 2:20, # firm_IDが2から20のデータを抽出\n      X &gt; 0 # 対数を取るため当期純利益が正のデータのみ抽出\n      )\n\nggplot(year2015) +\n  aes(x = log(sales), y = log(X), size = ME, alpha = 0.4) +\n  geom_point() + # バブルチャートを描くにはsize引数を指定\n  scale_size(range = c(1, 20), name = \"Market Equity\") + # rangeでバブルの最小最大面積を指定\n  scale_x_continuous(limits = c(8, 14)) + # 両軸の範囲を指定\n  scale_y_continuous(limits = c(2, 11)) + mystyle",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>株式データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter05.html#統計的推論入門",
    "href": "chapter05.html#統計的推論入門",
    "title": "\n5  株式データの取得と可視化\n",
    "section": "\n5.6 統計的推論入門",
    "text": "5.6 統計的推論入門\n\n5.6.1 リターン・データに関する仮定\n統計的推論の内容に入る前に、firm_IDが1の企業の超過リターンReのデータを眺めてみます。\n\nstock_data_1_month &lt;- stock_data |&gt;\n  filter(firm_ID == 1) |&gt;\n  select(month_ID, Re, R)\nggplot(stock_data_1_month) +\n  aes(x = month_ID, y = Re) + # 軸の設定\n  geom_line() + mystyle # 折れ線グラフ\n\n\n\n\n\n\n\nこのようなデータは時系列データと呼ばれ、ある個体(ここではfirm_IDが1の企業)の一定期間にわたって観測したデータのことを指します。\n\n\n\n\n\n\nImportant仮定\n\n\n\n月次超過リターンの時系列データは、何らかの確率分布(モデル)から独立に生成されている。\n\n\n\n株価そのものでは無く変化率であるリターンをモデル化する理由\n\n株価それ自体は株式分割などの要因でも変化するし、会社の成長に応じて上昇するため、その成長率をモデル化する方が、投資のリスクに対するリターンをより明確に評価することができるからである。\n\n月次リターンではなく月次超過リターンをモデルかする理由\n\n投資リスクを取って得られる追加的なリターンであるリスクプレミアムを明確に評価するために、無リスク金利を差し引いた超過リターンをモデル化します。\n\n月次超過リターンが独立であるとする理由\n\n半強度の効率的市場であれば、過去の情報はすでに株価に織り込まれているので、過去の超過リターンは将来の超過リターンと無関係である、とし、超過リターンに系列相関はない、と仮定します。 しかし、アノマリーの存在などにより、現実には系列相関があると考えられますが、モデルが複雑になるので、ここでは独立の仮定をおいて、モデルを単純化します。\n\n月次超過リターンが正規分布に従うとする理由\n\n正規分布を仮定するといろいろ計算が楽になる、という理由とともに、 株価の動きは多くの独立した事象の結果であると考えられ、中心極限定理により、超過リターンは正規分布に従うと考えられます。\nこれらの仮定を受け入れると、超過リターンの確率分布は次式で表されます。\n\nRe_t \\sim N(\\mu, \\sigma^2)\n\nこれにより、母集団分布に対して統計的推論が可能になります。 firm 1の超過リターンのヒストグラムを書いてみます。\n\nggplot(stock_data_1_month) + aes(x = Re) + # データと変数\n  geom_histogram()\n\n\n\n\n\n\n\nサンプルサイズが小さいため凸凹しているけれど、もっとサンプルを増やせば、正規分布に近い形をとるはずです。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>株式データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter05.html#推定量と推定値の違い",
    "href": "chapter05.html#推定量と推定値の違い",
    "title": "\n5  株式データの取得と可視化\n",
    "section": "\n5.7 推定量と推定値の違い",
    "text": "5.7 推定量と推定値の違い\n推定量(estimator)とは、母集団分布の母数(パラメータ)を推定するために使われる統計量のことです。 推定値(estimates)とは、推定量に実際のデータを代入して計算した値のことです。 たとえば母集団分布が正規分布N(\\mu, \\sigma^2)に従うと仮定すると、母数は\\muと\\sigma^2の2つです。この母数を推定するために使われる統計量が、それぞれ標本平均\\bar xと標本分散s^2です。 このときの推定値とは、実際に観察された標本から計算された標本平均\\bar xと標本分散s^2のことを指します。\n次の問題を考えます。\n\n\n\n\n\n\nImportant問題\n\n\n\nfirm_IDが1の銘柄の月次リターンR_{i,t}^eは、期待値の意味で、ゼロより大きいのだろうか？\n\n\nここで「期待値の意味で」というのは平均的に、と言い換えても問題ないです。 企業1の月次超過リターンの平均は0より大きい、ということは、企業1の月次リターンは平均的に無リスク利子率よりも大きいかどうか、を比べるということです。\nこの問題を解くために、まずは母集団分布の母数である期待値\\muを推定する必要があります。 期待値\\muを推定するために使われる推定量は標本平均\\bar xなので、ここで標本平均を計算します。\n\nstock_data_1_month |&gt;\n  summarise(\n    mean_Re = mean(Re, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 1\n  mean_Re\n    &lt;dbl&gt;\n1  0.0291\n\n\n企業1の平均月次超過リターンmean_Reが0.0291となりました。 これだけみるとゼロより大きい値ですが、これは母集団から抽出された1つのサンプルの平均ですので、他のサンプルの平均がゼロを超えるかどうかは分かりません。\n\n5.7.1 大数の法則\n母集団から無限個の標本(sample)を抽出して、それぞれの標本平均(sample mean)を計算すると、その標本平均の平均は母集団の期待値\\muに一致することが知られています。これを対数の法則(law of large number)といいます。\n数式よりも前にシミュレーションで確認してみましょう。 まずは、母集団分布を平均が10、標準偏差が2の正規分布N(10, 4)として、母集団から100のデータを抽出して標本を1つ作ります。そしてその標本の平均を計算します。\n\nset.seed(123) # 乱数の種を固定\nsize &lt;- 100 # 標本サイズ\n# 母集団のパラメータの設定\nmu &lt;- 10 # 平均\nsigma &lt;- 4 # 標準偏差\npopulation &lt;- rnorm(size, mu, sigma) # 母集団からサンプルを抽出\nmean(population) # 標本平均\n\n[1] 10.36162\n\n\n平均は10.3616236となりました。 母集団の平均10とは異なる数値になっています。 もう一度別の標本でやってみると、\n\npopulation &lt;- rnorm(size, mu, sigma) # 母集団からサンプルを抽出\nmean(population) # 標本平均\n\n[1] 9.569813\n\n\nまた違う平均が計算されました。 この作業を何度も何度も繰り返し、標本平均をたくさん計算します。 ここでは、100個のデータをもつ標本を100個作って、それぞれの標本平均を計算します。\n\nn_sample &lt;- 100 # サンプル数\nsample_mean &lt;- rep(NA, n_sample) # 標本平均を格納するベクトル\nsample_sd &lt;- rep(NA, n_sample) # 標本分散を格納するベクトル\nfor(i in 1:n_sample){\n  population &lt;- rnorm(size, mu, sigma) # 母集団からサンプルを抽出\n  sample_mean[i] &lt;- mean(population) # 標本平均を計算\n  sample_sd[i] &lt;- sd(population)\n}\n\nサンプルの平均が100個計算できたので、ヒストグラムを書いてみます。\n\nggplot() + aes(x = sample_mean) + geom_histogram() + mystyle\n\n\n\n\n\n\n\nあまり正規分布のようには見えません。 ではサンプルの平均の平均を計算してみます。\n\nmean(sample_mean) # 標本平均の平均\n\n[1] 9.99003\n\n\n母集団の平均10に近い値になっていることが分かります。もっとサンプルの数を増やしてみます。 データの数が100のサンプルを1,000,000個(100万個)抽出して、それぞれのサンプルの平均値を計算します。\n\nn_sample &lt;- 10^6\n# 標本平均のシミュレーション\nsample_mean &lt;- replicate(n_sample, mean(rnorm(size, mu, sigma)))\n# 標本標準偏差のシミュレーション（必要な場合）\nsample_sd &lt;- replicate(n_sample, sd(rnorm(size, mu, sigma)))\n# 作図\nggplot() + aes(x = sample_mean) + geom_histogram() + mystyle\n\n\n\n\n\n\n\nほぼ正規分布のような形をしていることが分かります。ではサンプルの平均の平均を計算してみます。\n\nmean(sample_mean) # 標本平均の平均\n\n[1] 10.00063\n\nmean(sample_sd) # 標本分散の平均\n\n[1] 3.989758\n\n\nこのように標本の数を無限に大きくしたとき、サンプルの平均の平均は母集団の平均10に一致するし，標本標準偏差は母集団の標準偏差4に一致する，というのが大数の法則です。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>株式データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter05.html#t値の計算",
    "href": "chapter05.html#t値の計算",
    "title": "\n5  株式データの取得と可視化\n",
    "section": "\n5.8 t値の計算",
    "text": "5.8 t値の計算\n先ほど計算したfirm_IDが1の企業の超過リターンの平均値はNAでした。 これがゼロより大きいかどうかはすぐ分かりますが，この値はたまたま今手元にある1つのサンプルから計算された平均値なので，他の標本ではどうなるか分かりません。 このように推定量にばらつきがある場合には，その推定量の分布を考える必要があります。 ここでは，その分布をt分布(t distribution)と仮定して，t値(t-value)を計算してみます。 t値は次のように定義されます。\n\nt = \\frac{\\bar{X} - \\mu_0}{\\sqrt{s^2 / n} } \\stackrel{d}{\\approx} N(0,1)\n\nここで，\\bar Xは標本平均，\\mu_0は帰無仮説(null hypothesis)の値で，ここでは\\mu_0 = 0とします。s^2は標本分散，nは標本サイズです。 分子に注目すると，標本平均と帰無仮説の値の差となっており，もし標本平均が0に近いなら，t値は0に近い値になります。\n\nRe_firm_ID_1 &lt;- stock_data |&gt;\n  filter(firm_ID == 1) |&gt; # firm_IDが1の企業のデータを抽出\n  select(Re) |&gt; #超過リターンのみ選択\n  drop_na() |&gt; # 欠損値を除去\n  unlist() # データフレームをベクトルに変換\n\nmu0 &lt;- 0 # 帰無仮説の値\nn &lt;- length(Re_firm_ID_1) # 標本サイズ\n\nt_value &lt;- (mean(Re_firm_ID_1) - mu0) / sqrt(var(Re_firm_ID_1) / n) # $t$値の計算\nprint(t_value)\n\n[1] 2.121296\n\n\n\n5.8.1 統計的検定の考え方\nあなたがサイコロを投げるゲームをしていて、あるプレイヤーが非常に幸運だと主張しています。彼は6回サイコロを投げて、5回も「6」が出たとします。これはただの偶然なのか、それとも何か他の要因（例えば、サイコロがいかさまであるとか）が関与しているのでしょうか？\nこの問いに答えるために、我々は統計的検定(statistical test)を用いることができます。 まず帰無仮説(null hypothesis)を設定します。 この例では、帰無仮説は「サイコロは公正であり、すべての出目が等確率（1/6）で出る」とすることが適切です。\n次に、この帰無仮説が真(true)である場合に、我々が観察した結果（5回の「6」）がどれほどあり得ないかを計算します。これがp値(p value)です。この場合、6回投げて5回「6」が出る確率を計算します。\nこれを計算すると、p値は非常に小さいことが分かり（つまり、この結果は帰無仮説の下ではほぼあり得ない），帰無仮説が棄却されます。 帰無仮説が棄却されるとは，帰無仮説が正しいと仮定したときに，観測されたデータが得られる確率が小さいことを意味します。 したがって、我々はこの結果が偶然生じたとは考えにくく、その代わりにサイコロがいかさまである、または何か他の非ランダムな要因が作用している可能性を強く疑うことになります。これがp値を用いて統計的検定の考え方です。\np値が0.05より小さい場合，帰無仮説は棄却され，対立仮説が採択される，というケースが多いです。 この場合，有意水準5%で帰無仮説は棄却されます。 有意水準は，帰無仮説が正しいと仮定したときに，観測されたデータが得られる確率が小さいと判断する基準値です。 有意水準は，5%や1%がよく使われます。\nRでは，t.test()関数を使って，t値とp値を計算することができます。 ここでは，t.test()関数を使って，firm_IDが1の企業の超過リターンがゼロなのかどうなのか，を検定するために，t値とp値を計算してみましょう。\n\nt.test(Re_firm_ID_1)\n\n\n    One Sample t-test\n\ndata:  Re_firm_ID_1\nt = 2.1213, df = 70, p-value = 0.03744\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 0.001737894 0.056383256\nsample estimates:\n mean of x \n0.02906058",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>株式データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter05.html#線形回帰入門",
    "href": "chapter05.html#線形回帰入門",
    "title": "\n5  株式データの取得と可視化\n",
    "section": "\n5.9 線形回帰入門",
    "text": "5.9 線形回帰入門\n年次財務データannual_dataを使って線形回帰(linear regression)について学習します。 線形(linear)とは，Xと\\betaの積が線形であることを意味します。回帰(regression)とは，Xと\\betaの積がYを説明することを意味します。 回帰は，2変数間の間で、一方の変数が他方の変数に対して影響を与えるという関係を想定できる場合に用いられます。 しかし因果関係を直接調べているのではないことに注意しましょう。\n影響を与える変数を説明変数(explanatory variable)や独立変数(independent variable)といい、 影響を与えられる変数を目的変数(response variable)や従属変数(dependent variable)といいます。 分野などでどっちを使うのかは異なりますが、ここでは説明変数と目的変数を使います。\n線形関係を仮定した関係を式にすると，次のようになります。 \nY = \\alpha + \\beta X\n ここで， \\alphaは定数項(constant term)と呼ばれ，切片(intercept)とも呼ばれます。 \\betaは回帰係数(regression coefficient)と呼ばれ，傾き(slope)とも呼ばれます。\n実際のデータが上のモデルを満たす、つまりすべてのデータが直線上に並んでいるわけではないのです。 実際のデータとモデルとの間にはずれがあることを考慮して、上のモデルを次のように書き換えます。\n\nY = \\alpha + \\beta X + u\n ここでuは誤差項(error term)とか観察不可能項(unobservable term)と呼ばれます。\n線形回帰の目的は，XとYの関係を表す\\alphaと\\betaを推定することです。 推定するために，観測できるデータを使います。 観測できるデータはXとYのペアで(X_i, Y_i)と表記します。 このペアを観測値(observed value)と呼びます。 この観測値は，XとYの関係を表す\\alphaと\\betaを推定するために使われます。 推定するために使われる\\alphaと\\betaを推定値(estimated value)と呼びます。 推定値は，\\hat{\\alpha}と\\hat{\\beta}と表記して，観察値と区別します。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>株式データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter05.html#ols推定",
    "href": "chapter05.html#ols推定",
    "title": "\n5  株式データの取得と可視化\n",
    "section": "\n5.10 OLS推定",
    "text": "5.10 OLS推定\n推定方法として最も有名なものが最小二乗法(ordinary least squares; OLS)です。 最小二乗法では，観測値と推定値の差の二乗の和が最小になるように\\alphaと\\betaを推定します。 このとき，観測値と推定値の差を残差(residual)と呼びます。 最小二乗法では，残差の二乗の和である残差平方和(sum of squared residuals; SSR)が最小になるように\\alphaと\\betaを推定します。\n\n\\min _{\\alpha, \\beta} \\sum _{i=1}^n (Y_i - \\alpha - \\beta X_i)^2\n\n\n# 線形回帰分析のための事前準備\n# ch05_24ですでにME（時価総額）が結合されていることが前提\n\nannual_data &lt;- annual_data |&gt;\n  arrange(firm_ID, year) |&gt; # 時系列順に並べ替え（lag計算に必須）\n  mutate(\n    lag_ME = lag(ME),\n    lagged_BEME = lagged_BE / lag_ME, # ここでBEMEを計算\n    .by = firm_ID\n  )\n\n\nlm_sample_data &lt;- annual_data |&gt;\n  filter(year == 2016, firm_ID &lt;= 10) |&gt;\n  # lagged_BEMEは計算済みなので、selectで選ぶだけにする\n  select(firm_ID, year, Re = annual_Re, lagged_BEME) |&gt;\n  drop_na() # 欠損値を除去\n\nggplot(lm_sample_data) +\n  geom_point(aes(x = lagged_BEME, y = Re)) + # 散布図\n  xlab(\"簿価時価比率\") + ylab(\"超過リターン\") + mystyle\n\n\n\n\n\n\n\n\n# ch05_32: 簿価時価比率と株式リターンの散布図に回帰直線を追加\n\nggplot(lm_sample_data) +\n  geom_point(aes(x = lagged_BEME, y = Re)) +\n  geom_smooth(aes(x = lagged_BEME, y = Re), method = \"lm\", se = FALSE, color = \"black\") + # 回帰直線を追加するにはgeom_smooth()関数を用いる\n  labs(x = \"BE/ME at the End of Year t\", y = \"Excess Return for Year t + 1\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n# ch05_33: lm()関数を用いた線形回帰\n\nlm_results &lt;- lm(Re ~ lagged_BEME, data = lm_sample_data) # 従属変数 ~ 独立変数\nnames(lm_results)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\n\n\nprint(lm_results$coefficients)\n\n(Intercept) lagged_BEME \n 0.05513385  0.07552921 \n\n\n\n# ch05_35: broomパッケージのtidy()関数で係数の推定値に関する結果を確認\ntidy(lm_results)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)   0.0551    0.156      0.354   0.736\n2 lagged_BEME   0.0755    0.0844     0.895   0.405\n\n\n\nglance(lm_results)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.118       -0.0294 0.223     0.800   0.405     1   1.81  2.37  2.61\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>株式データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter05.html#対数回帰モデル",
    "href": "chapter05.html#対数回帰モデル",
    "title": "\n5  株式データの取得と可視化\n",
    "section": "\n5.11 対数回帰モデル",
    "text": "5.11 対数回帰モデル\n独立変数Xが変化したときの従属変数Yへの影響は一定(つまり傾きが一定)と仮定してきましたが、 実際には傾きが一定でない場合もあります。 回帰式が非線形であることが想定される場合、対処法として\n\n多項式回帰(polynomial regression) ：独立変数にX^2とかX^3を加える\n\n対数回帰(logarithmic regression) ：独立変数や従属変数の対数をとる\n\nたとえば、独立変数を対数変換した場合は、次のようなモデルになる。\n\nY_i = \\beta_0 + \\beta_1 \\log (X_i) + \\varepsilon_i\n\n\n\n\n線形・対数モデルによる推定\n\ntidy(lm(Re ~ log(lagged_BEME), data = lm_sample_data)) # 右辺のみlog()関数で自然対数を取る\n\n\n# A tibble: 2 × 5\n  term             estimate std.error statistic p.value\n  &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)        0.167     0.0868     1.93    0.102\n2 log(lagged_BEME)   0.0355    0.109      0.326   0.756\n\n\n作成したデータフレームをcsvファイルとして保存するには，write_csv()関数を用います。 前処理が終わった後や新しい変数を作った後に、データを保存しておくと便利です。 6章以降では、以下のデータを継続して使うので、csvファイルとして保存しておきます。\n\n\n\nデータの保存\n\nwrite_csv(monthly_data, \"data/ch05_output1.csv\")\nwrite_csv(annual_data, \"data/ch05_output2.csv\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>株式データの取得と可視化</span>"
    ]
  },
  {
    "objectID": "chapter06.html",
    "href": "chapter06.html",
    "title": "\n6  ファクターモデルの導入\n",
    "section": "",
    "text": "6.1 ファクター構築の準備",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ファクターモデルの導入</span>"
    ]
  },
  {
    "objectID": "chapter06.html#ファクター構築の準備",
    "href": "chapter06.html#ファクター構築の準備",
    "title": "\n6  ファクターモデルの導入\n",
    "section": "",
    "text": "CAPMの実証的検証に必要な市場ポートフォリオの構築\nある特徴に基づいて各銘柄をランキングにし，ランキングに応じたポートフォリオの構築",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ファクターモデルの導入</span>"
    ]
  },
  {
    "objectID": "chapter06.html#市場ポートフォリオの構築",
    "href": "chapter06.html#市場ポートフォリオの構築",
    "title": "\n6  ファクターモデルの導入\n",
    "section": "\n6.2 市場ポートフォリオの構築",
    "text": "6.2 市場ポートフォリオの構築\n市場ポートフォリオ(market portfolio)とは，市場に存在する全ての危険資産を時価総額比率で保有したポートフォリオをいいます。\n\n\n厳密には，リスク資産には株式や債券に代表される金融資産の他、不動産や貴金属などの実物資産も含まれますが、実用上はTOPIXやS&P500といった株価指数と同一視されることが多いです。\n入手可能な全銘柄の前年末時価総額\\sum ME_{j,t-1}と個別銘柄の時価総額 ME_{i,t-1} の比率をウェイト w_{i,t}^M として市場ポートフォリオを構築します。\n\nw_{i,t}^M = \\frac{ME_{i,t-1}^{12\\text{月}}}{\\sum_{j = 1}^N ME_{j,t-1}^{12\\text{月}}}\n\n株価は日々変動するため、時価総額も変動します。 そのため、毎年1月に時価の変動で崩れた比率をリセットするために、市場ポートフォリオの中身を入れ替えるリバランスを行います。\nでは練習用データで市場ポートフォリオを構築してみましょう。\n\nmonthly_data &lt;- read_csv(\"data/ch05_output1.csv\")\nannual_data &lt;- read_csv(\"data/ch05_output2.csv\")\n\nmonthly_dataは月次の株式データが収録されており、 annual_dataは年次の財務データが収録されています。 データの構造を確認しておきます。\n\nglimpse(monthly_data)\n\nRows: 95,040\nColumns: 24\n$ year        &lt;dbl&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015…\n$ month       &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7…\n$ month_ID    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ firm_ID     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ stock_price &lt;dbl&gt; 954, 960, 1113, 1081, 1317, 1366, 1353, 1209, 1291, 1407, …\n$ DPS         &lt;dbl&gt; 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 40, 0…\n$ n_shares    &lt;dbl&gt; 2422000, 2422000, 2422000, 2422000, 2422000, 2422000, 2422…\n$ adj_coef    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ R_F         &lt;dbl&gt; 6.506826e-04, 5.834099e-04, 6.114423e-04, 6.848180e-04, 7.…\n$ ME          &lt;dbl&gt; 2310588000, 2325120000, 2695686000, 2618182000, 3189774000…\n$ R           &lt;dbl&gt; NA, 0.006289308, 0.159375000, -0.028751123, 0.218316374, 0…\n$ Re          &lt;dbl&gt; NA, 0.005705898, 0.158763558, -0.029435941, 0.217579602, 0…\n$ industry_ID &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, 1, 1, 1…\n$ sales       &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 5948.96, 5…\n$ OX          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 564.14, 56…\n$ NFE         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 50.66750, …\n$ X           &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 513.48, 51…\n$ OA          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 13865.58, …\n$ FA          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4642.16, 4…\n$ OL          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4534.22, 4…\n$ FO          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3959.70, 3…\n$ BE          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10013.82, …\n$ lagged_BE   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ROE         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\nglimpse(annual_data)\n\nRows: 7,920\nColumns: 20\n$ year        &lt;dbl&gt; 2015, 2016, 2017, 2018, 2019, 2020, 2015, 2016, 2017, 2018…\n$ firm_ID     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4…\n$ ME          &lt;dbl&gt; 3577.294, 6883.324, 11376.990, 8694.752, 13957.518, 9708.9…\n$ annual_R    &lt;dbl&gt; NA, 0.99727265, 0.68786382, -0.21361287, 0.64683576, -0.28…\n$ annual_R_F  &lt;dbl&gt; 7.432089e-03, 5.649890e-04, 4.884804e-05, 5.786109e-03, -7…\n$ annual_Re   &lt;dbl&gt; NA, 0.99670766, 0.68781497, -0.21939898, 0.64760569, -0.28…\n$ industry_ID &lt;dbl&gt; NA, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ sales       &lt;dbl&gt; NA, 5948.96, 6505.06, 6846.38, 7572.24, 7537.63, 3505.75, …\n$ OX          &lt;dbl&gt; NA, 564.14, 691.18, 751.29, 958.53, 778.37, 45.82, 51.25, …\n$ NFE         &lt;dbl&gt; NA, 50.667498, 29.543157, 86.486500, 298.049774, -65.45877…\n$ X           &lt;dbl&gt; NA, 513.48, 661.64, 664.80, 660.48, 843.83, 40.07, 49.37, …\n$ OA          &lt;dbl&gt; NA, 13865.58, 13952.58, 18818.48, 18190.00, 20462.86, 2977…\n$ FA          &lt;dbl&gt; NA, 4642.16, 7743.99, 7284.72, 9735.13, 10274.25, 2258.33,…\n$ OL          &lt;dbl&gt; NA, 4534.22, 5111.22, 5137.28, 5487.96, 5371.38, 1840.35, …\n$ FO          &lt;dbl&gt; NA, 3959.70, 6159.02, 10123.91, 11362.22, 13772.15, 2340.8…\n$ BE          &lt;dbl&gt; NA, 10013.82, 10426.33, 10842.01, 11074.95, 11593.58, 1054…\n$ lagged_BE   &lt;dbl&gt; NA, NA, 10013.82, 10426.33, 10842.01, 11074.95, NA, 1054.9…\n$ ROE         &lt;dbl&gt; NA, NA, 0.06607269, 0.06376165, 0.06091859, 0.07619267, NA…\n$ lag_ME      &lt;dbl&gt; NA, 3577.294, 6883.324, 11376.990, 8694.752, 13957.518, NA…\n$ lagged_BEME &lt;dbl&gt; NA, NA, 1.4547942, 0.9164401, 1.2469602, 0.7934756, NA, 0.…\n\n\nこの銘柄ごとの保有比率を計算するために，前年度末の時価総額を計算し，lagged_MEに代入します。 annual_dataは2015年から2020年のデータが入っています。 lag()で前期末の時価総額をlagged_MEに代入しようとしても2015年の前年のデータは存在しないので，欠損値になることに注意しましょう。\n\nannual_data &lt;- annual_data |&gt;\n    arrange(firm_ID, year) |&gt; # firm_IDとyearで並び換え\n    mutate(\n      .by = firm_ID, # 企業ごと\n      lagged_ME = lag(ME) # 前期末時価総額\n      )\n\nこの処理の結果がおおよそこんな感じになっているはずです。\n\n\nfirm_ID\nyear\nME\nlagged_ME\n\n\n\n1\n2015\n3577.294\nNA\n\n\n1\n2016\n6883.324\n3577.294\n\n\n1\n2017\n11376.990\n6883.324\n\n\n\nこのlagged_MEを使って保有比率を計算します。 年度ごとに時価総額を合計し、ある企業の前期末時価総額を合計時価総額で割ることで保有比率w_Mを計算します。\n\nannual_data &lt;- annual_data |&gt;\n    mutate(\n      .by = year, # 年度ごとに\n      # ウェイト\n      w_M = lagged_ME / sum(lagged_ME, na.rm = TRUE)\n    )\n\n2015年のlagged_MEは欠損値なので，w_Mも欠損値になっていますが，2015年のデータはもう使わないので無視します。\n次に，2016年以降の欠損値の行を削除するのではなく，保有比率w_Mをゼロに置き換えることで投資しないことを表します。 mutate()とreplace()を用いて変数の置き換えをします。\n\nannual_data &lt;- annual_data |&gt;\n    mutate( # w_Mの欠損値を0に置き換える\n        w_M = replace(\n          w_M,\n          year &gt;= 2016 & is.na(w_M),\n          0\n        )\n    )\n\nこの処理は、\n\n\nannual_dataにannual_dataを代入し直す\n\nmutate()関数で変数を変換する\n\nreplace()関数でw_Mの値を置き換える\n\n\nw_Mに対して、replace()関数を適用し、\n\nyear &gt;= 2016 かつ\n欠損値かどうかを判定する関数is.na()を使って判別したw_Mが欠損値の場合に、\n\nw_Mの値を0に置き換える\n\n\n\nreplace()関数は，第1引数のデータに対して，第2引数の条件を満たす要素を，第3引数の値に置き換えます。 ここでは，w_Mに対して，yearが2016以上で，かつw_Mが欠損値の場合のw_Mを0に置き換えています。\n作成した保有比率を表すウェイトw_Mの合計が1になっているかどうかを確認します。\n\nannual_data |&gt;\n    summarise(\n        weight_sum = round(sum(w_M), digits = 2),\n        .by = year\n    )\n\n# A tibble: 6 × 2\n   year weight_sum\n  &lt;dbl&gt;      &lt;dbl&gt;\n1  2015         NA\n2  2016          1\n3  2017          1\n4  2018          1\n5  2019          1\n6  2020          1\n\n\n確認できました。 これまでの操作で変数を追加したannual_dataにmonthly_dataに結合します。 完全外部結合(full outer join)を行います。 完全外部結合とは，データベースを連結する操作の1つで、2つのデータフレームからそれぞれ特定のキーとなる列を指定して，キーの値が一致する行同士は連結し、一致しない残りの行もそのまますべて抽出するものです。\nではfull_join()関数を使って，annual_dataとmonthly_dataをyearとfirm_IDの2つのキーで結合し，その結果をmonthly_dataに代入します。\n\n\n\n月次データに保有比率のデータを追加\n\nmonthly_data &lt;- annual_data |&gt;\n  select(year, firm_ID, w_M) |&gt; # 必要な変数のみ\n  full_join(monthly_data, by = c(\"year\", \"firm_ID\")) |&gt; # 完全外部結合\n  select(-w_M, w_M) # w_Mを最終列に移動\n\n\nできあがった拡大データセットmonthly_dataを確認します。\n\nglimpse(monthly_data)\n\nRows: 95,040\nColumns: 25\n$ year        &lt;dbl&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015…\n$ firm_ID     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ month       &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7…\n$ month_ID    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ stock_price &lt;dbl&gt; 954, 960, 1113, 1081, 1317, 1366, 1353, 1209, 1291, 1407, …\n$ DPS         &lt;dbl&gt; 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 40, 0…\n$ n_shares    &lt;dbl&gt; 2422000, 2422000, 2422000, 2422000, 2422000, 2422000, 2422…\n$ adj_coef    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ R_F         &lt;dbl&gt; 6.506826e-04, 5.834099e-04, 6.114423e-04, 6.848180e-04, 7.…\n$ ME          &lt;dbl&gt; 2310588000, 2325120000, 2695686000, 2618182000, 3189774000…\n$ R           &lt;dbl&gt; NA, 0.006289308, 0.159375000, -0.028751123, 0.218316374, 0…\n$ Re          &lt;dbl&gt; NA, 0.005705898, 0.158763558, -0.029435941, 0.217579602, 0…\n$ industry_ID &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, 1, 1, 1…\n$ sales       &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 5948.96, 5…\n$ OX          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 564.14, 56…\n$ NFE         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 50.66750, …\n$ X           &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 513.48, 51…\n$ OA          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 13865.58, …\n$ FA          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4642.16, 4…\n$ OL          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4534.22, 4…\n$ FO          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3959.70, 3…\n$ BE          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10013.82, …\n$ lagged_BE   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ROE         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ w_M         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2.233661e-…\n\n\n準備が整ったので，市場ポートフォリオの月次リターンを計算します。 t時点における市場ポートフォリオのリターンR_{M,t}は、個別銘柄のリターンR_{i,t}とウェイトw_{i,t}^Mの積の合計で表されます。\n\nR_{M,t} = \\sum_{i=1}^{N} w_{i,t}^M R_{i,t}\n\nこれをRで実装します。 monthly_dataをmonth_IDでグループ化し，summarise()関数を用いて，R_Mを計算し，その後でmutate()関数を用いて，R_Meを計算し，その結果をfactor_dataに代入します。\n\n\n\n市場ポートフォリオの月次リターンを計算\n\nfactor_data &lt;- monthly_data |&gt;\n  filter(month_ID &gt;= 13) |&gt; # 2016以降のデータを抽出\n  summarise(\n    R_F = R_F[1], # 無リスク金利を抽出\n    R_M = sum(w_M * R, na.rm = TRUE), # 月次リターンの加重平均\n    .by = month_ID\n  ) |&gt;\n  mutate(R_Me = R_M - R_F) # 月次超過リターン変数を作成\n\n\nfactor_dataの中身をsummary()で確認します。\n\nsummary(factor_data)\n\n    month_ID          R_F                  R_M                 R_Me          \n Min.   :13.00   Min.   :-2.329e-04   Min.   :-0.102438   Min.   :-0.102438  \n 1st Qu.:27.75   1st Qu.:-4.107e-05   1st Qu.:-0.011056   1st Qu.:-0.010890  \n Median :42.50   Median : 3.870e-05   Median : 0.006081   Median : 0.006186  \n Mean   :42.50   Mean   : 9.991e-05   Mean   : 0.004100   Mean   : 0.004000  \n 3rd Qu.:57.25   3rd Qu.: 1.323e-04   3rd Qu.: 0.031698   3rd Qu.: 0.031649  \n Max.   :72.00   Max.   : 6.326e-04   Max.   : 0.111043   Max.   : 0.110819  \n\n\n作成した市場ポートフォリオの超過リターンをヒストグラムにして分布を確認します。\n\n# 市場ポートフォリオの月次超過リターンをヒストグラムで可視化\nggplot(factor_data) + aes(x = R_Me) + geom_histogram() +\n  labs(x = \"市場ポートフォリオの月次超過リターン\", y = \"度数\") + mystyle\n\n\n\n\n\n\n\n次に、市場ポートフォリオの累積リターンを計算します。 計算の仮定は以下の通りです。\n\n\nmonth_IDが13の月初から運用スタートし、バイアンドホールドで運用すると仮定する。\n毎年1月にコストなしでリバランスし、リバランス前後で元本の変動はないと仮定する。\n\n市場ポートフォリオの累積グロス・リターンを計算します。\n\n\n\n市場ポートフォリオの累積リターンの可視化 (1)\n\ndf_g &lt;- factor_data |&gt;\n  mutate(\n    gross_R_M = 1 + R_M, # rに1足してグロスリターン\n    cumulative_gross_R_M = cumprod(gross_R_M) # 累積グロスリターン\n    )\n\n\n作成した累積グロス・リターンを折れ線グラフで可視化します。\n\ng &lt;- ggplot(df_g) + aes(x = month_ID, y = cumulative_gross_R_M) + geom_line()\ng &lt;- g + labs(x = \"Month ID\", y = \"累積グロスリターン\") + mystyle\nprint(g)\n\n\n\n\n\n\n\n累積リターンであることが一発で分かるように、始点を1として、折れ線グラフを描き直します。 rbind()で始点となるデータを追加し、geom_hline()で始点の水準を点線で図示します。\n\n\n\n市場ポートフォリオの累積リターンの可視化 (2)\n\ndf_g &lt;- factor_data |&gt;\n  mutate(\n    gross_R_M = 1 + R_M,\n    cumulative_gross_R_M = cumprod(gross_R_M)\n  ) |&gt;\n  select(month_ID, cumulative_gross_R_M) |&gt;\n  add_row(month_ID = 12, cumulative_gross_R_M = 1, .before = 1)\n\n# 折れ線グラフを作成\ng &lt;- ggplot(df_g) +\n  geom_line(aes(x = month_ID, y = cumulative_gross_R_M)) +\n  geom_hline(yintercept = 1, linetype = \"dotted\", color = \"red\") + # 元本の水準を点線で図示\n  labs(x = \"Month ID\", y = \"Cumulative Gross Return\") +\n  scale_x_continuous(expand = c(0, 0)) + ylim(0.5,1.5) +  mystyle\nprint(g)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ファクターモデルの導入</span>"
    ]
  },
  {
    "objectID": "chapter06.html#ポートフォリオソート",
    "href": "chapter06.html#ポートフォリオソート",
    "title": "\n6  ファクターモデルの導入\n",
    "section": "\n6.3 ポートフォリオ・ソート",
    "text": "6.3 ポートフォリオ・ソート\nある特性に基づいて株式銘柄をランキングにし、そのランキングに基づいてポートフォリオを構築することをポートフォリオ・ソートと呼びます。 ポートフォリオ・ソートは、ファクター・モデルの検証において重要な手法です。 ここでは前年度末の時価総額に基づいて、企業を10個のグループに分類して、実現リターンの比較をしてみましょう。\n\n\n図6.2 前年度末の時価総額に基づくポートフォリオ・ソート\n\nRで時価総額ランキングを作成するには、ntile()関数を用います。 ntile()関数は、データを指定した数のグループに分類します。 以下のコードでは、mutate()関数でME_rank10を新たに作成しています。 ME_rank10は、lagged_ME変数をntile()関数で10個に分類し、as.factor()関数で因子型に変換したものです。\n\n# ch06_11: 前年度末の時価総額に基づくポートフォリオ・ソート (1)\nannual_data &lt;- annual_data |&gt;\n  mutate(\n    ME_rank10 = as.factor(ntile(lagged_ME, 10)),\n    .by = year\n  ) # ntile()関数を用いて十個のグループに分類\nhead(annual_data)\n\n# A tibble: 6 × 23\n   year firm_ID     ME annual_R annual_R_F annual_Re industry_ID sales    OX\n  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  2015       1  3577.   NA      0.00743      NA              NA   NA    NA \n2  2016       1  6883.    0.997  0.000565      0.997           1 5949.  564.\n3  2017       1 11377.    0.688  0.0000488     0.688           1 6505.  691.\n4  2018       1  8695.   -0.214  0.00579      -0.219           1 6846.  751.\n5  2019       1 13958.    0.647 -0.000770      0.648           1 7572.  959.\n6  2020       1  9709.   -0.284  0.000380     -0.285           1 7538.  778.\n# ℹ 14 more variables: NFE &lt;dbl&gt;, X &lt;dbl&gt;, OA &lt;dbl&gt;, FA &lt;dbl&gt;, OL &lt;dbl&gt;,\n#   FO &lt;dbl&gt;, BE &lt;dbl&gt;, lagged_BE &lt;dbl&gt;, ROE &lt;dbl&gt;, lag_ME &lt;dbl&gt;,\n#   lagged_BEME &lt;dbl&gt;, lagged_ME &lt;dbl&gt;, w_M &lt;dbl&gt;, ME_rank10 &lt;fct&gt;\n\n\nME_rank10の値と、年・ランキングごとの会社数を確認してみましょう。\n\nsummary(annual_data$ME_rank10)\n\n   1    2    3    4    5    6    7    8    9   10 NA's \n 643  642  641  641  640  640  640  640  639  639 1515 \n\ntable(annual_data$year,  annual_data$ME_rank10)\n\n      \n         1   2   3   4   5   6   7   8   9  10\n  2015   0   0   0   0   0   0   0   0   0   0\n  2016 125 124 124 124 124 124 124 124 124 124\n  2017 127 127 127 127 127 127 127 127 127 127\n  2018 127 127 127 127 127 127 127 127 126 126\n  2019 131 131 131 131 130 130 130 130 130 130\n  2020 133 133 132 132 132 132 132 132 132 132\n\n\nここでは、ME_rank10の値が10の企業が時価総額ランキングの上位10%に、1の企業が時価総額ランキングの下位10%に属することを意味します。\n前回と同様に、full_join()関数でmonthly_dataとannual_dataを結合します。 drop_na()関数で欠損行を削除し、.by =month_IDとME_rank10に関してグループ化した上で、summarize()関数で月次超過リターンReの平均値を計算して、Re変数としています。\n\n\n\n前年度末の時価総額に基づくポートフォリオ・ソート\n\nME_sorted_portfolio &lt;- annual_data |&gt;\n  select(year, firm_ID, ME_rank10) |&gt; # 年次データから追加したい情報を抽出\n  full_join(monthly_data, by = c(\"year\", \"firm_ID\")) |&gt; # yearとfirm_IDをキーに月次データと結合\n  drop_na() |&gt; # 欠損行を削除\n  summarize(\n    # 各グループで月次超過リターンの平均値を計算\n    Re = mean(Re),\n    .by = c(month_ID, ME_rank10)\n    )\nME_sorted_portfolio\n\n\n# A tibble: 600 × 3\n   month_ID ME_rank10       Re\n      &lt;dbl&gt; &lt;fct&gt;        &lt;dbl&gt;\n 1       25 2          0.0976 \n 2       26 2          0.00392\n 3       27 2          0.0172 \n 4       28 2          0.0773 \n 5       29 2          0.00948\n 6       30 2          0.0473 \n 7       31 2          0.0313 \n 8       32 2          0.0136 \n 9       33 2          0.00911\n10       34 2         -0.0962 \n# ℹ 590 more rows\n\n\n準備が出来たので、各ポートフォリオの平均超過リターンを可視化してみましょう。 これにより、時価総額の大きい企業のポートフォリオが、時価総額の小さい企業のポートフォリオよりも高い、あるいは低いリターンを上げているかどうかを確認することができます。\n\n\n\n各ポートフォリオの平均超過リターンを可視化\n\nME_cross_sectional_return &lt;- ME_sorted_portfolio |&gt;\n  summarize(\n    mean_Re = mean(Re),\n    .by = ME_rank10\n  ) # 月次超過リターンの平均値を計算\n\ng &lt;- ggplot(ME_cross_sectional_return) +\n  aes(x = ME_rank10, y = mean_Re) +\n  geom_col() + # 棒グラフ\n  xlab(\"時価総額ランク\") + ylab(\"平均月次超過リターン\") +\n  scale_y_continuous(expand = c(0, 0)) +\n  ylim(0,0.02) + mystyle\nprint(g)\n\n\n\n\n\n\n\n\n小型株ほど月次超過リターンの平均が高いことが分かりました。 このように、時価総額の大きい企業のポートフォリオと小さい企業のポートフォリオのリターンの差をサイズ・プレミアムと呼びます。\n先ほどは各ポートフォリオの区分を同じウェイトで保有した場合のリターンを計算しましたが，コラムでは，時価総額の大きさに応じてウェイトを変えた時価総額加重ポートフォリオを作成して，先ほどの結果を再現してみる。\nまずは等加重の場合のコードを確認する。\n\n\n\nBPRに基づくポートフォリオ・ソート（等加重の場合）\n\nannual_data &lt;- annual_data |&gt;\n  mutate(\n    lagged_BEME = lagged_BE / lagged_ME\n    ) |&gt;\n  mutate(\n    # 簿価時価比率に基づいて十個のグループに分類\n    BEME_rank10 = as.factor(ntile(lagged_BEME, 10)),\n    .by = year\n    )\n\nBEME_sorted_portfolio &lt;- annual_data |&gt;\n  select(year, firm_ID, BEME_rank10, lagged_ME) |&gt;\n  full_join(monthly_data, by = c(\"year\", \"firm_ID\")) |&gt;\n  drop_na() |&gt;\n  summarize(\n    # 月次超過リターンの平均値を計算\n    Re = mean(Re),\n    .by = c(month_ID, BEME_rank10)\n  )\n\n# 作図\nBEME_sorted_portfolio |&gt;\n  summarize(\n    mean_Re = mean(Re),\n    .by = BEME_rank10\n  ) |&gt;\n  ggplot() +\n  geom_col(aes(x = BEME_rank10, y = mean_Re)) +\n  geom_hline(yintercept = 0) + # y = 0の直線を追加\n  labs(x = \"BE/ME Rank\", y = \"Mean Monthly Excess Return\") +\n  scale_y_continuous(limits = c(-0.005, 0.02)) + mystyle\n\n\n\n\n\n\n\n\n次に時価総額加重の場合のコードを確認します。\n\n\n\nBPRに基づくポートフォリオ・ソート（時価総額加重の場合）\n\n# 中盤で保有比率wと月次超過リターンReを計算している箇所を除けば,ch06_15aと全く同じ\nannual_data &lt;- annual_data |&gt;\n  mutate(\n    lagged_BEME = lagged_BE / lagged_ME\n    ) |&gt;\n  mutate(\n    BEME_rank10 = as.factor(ntile(lagged_BEME, 10)),\n    .by = year\n    )\n\nBEME_sorted_portfolio &lt;- annual_data |&gt;\n  select(year, firm_ID, BEME_rank10, lagged_ME) |&gt;\n  full_join(monthly_data, by = c(\"year\", \"firm_ID\")) |&gt;\n  drop_na() |&gt;\n  mutate(\n    # 各ポートフォリオで保有比率を計算\n    w = lagged_ME / sum(lagged_ME),\n    .by = c(month_ID, BEME_rank10)\n  ) |&gt;\n  summarize(\n    # 時価総額加重の月次超過リターンを計算\n    Re = sum(w * Re),\n    .by = c(month_ID, BEME_rank10)\n  )\n\nBEME_sorted_portfolio |&gt;\n  summarize(\n    mean_Re = mean(Re),\n    .by = BEME_rank10\n  ) |&gt;\n  ggplot() +\n  geom_col(aes(x = BEME_rank10, y = mean_Re)) +\n  geom_hline(yintercept = 0) +\n  labs(x = \"BE/ME Rank\", y = \"Mean Monthly Excess Return\") +\n  scale_y_continuous(limits = c(-0.005, 0.02)) + mystyle\n\n\n\n\n\n\n\n\n結果が異なっていることに注意しましょう。\n次節では，この現象を，資産価格モデルの1つであるCAPM(Capital Asset Pricing Model)が説明できるかどうかを検証します。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ファクターモデルの導入</span>"
    ]
  },
  {
    "objectID": "chapter06.html#capmの実証的な検証",
    "href": "chapter06.html#capmの実証的な検証",
    "title": "\n6  ファクターモデルの導入\n",
    "section": "\n6.4 CAPMの実証的な検証",
    "text": "6.4 CAPMの実証的な検証\n\n6.4.1 CAPMを検証する意義\nまずはCAPMの復習から始めましょう。 CAPMは，資産の期待リターンを，市場ポートフォリオの期待リターンと市場ポートフォリオとの共分散で説明するモデルです。\n\n\n\n\n\n\nNoteCAPM\n\n\n\n\n\n第1命題: 市場ポートフォリオは接点ポートフォリオと一致し，効率的フ ロンティア(資本市場線)上に位置する.\n\n第2命題: 各証券のリスクプレミアムは，その証券のマーケット・ベータ に比例する.\n\n\n\\mathbb{E}[R_i] - R_F = \\beta_i \\left ( \\mathbb{E}[R_M] - R_F \\right )\n ただし， \n\\beta_i = \\frac{\\mathrm{COV}_{R_i,  R_M}}{\\mathrm{Var}_M}\n\n\n\nこのCAPMを回帰式で表現すると次のようになります。\n\nR_{i,t}^e = \\beta_i \\times R_{M,t}^e + \\varepsilon_{i,t}\n ここで、R^e_{i,t} = R_{i,t} - R_{F,t}である。 つまり、t時点における証券iの実現超過リターンR_{i,t}^eは、t時点における市場ポートフォリオの実現超過リターンR_{M,t}^eと、証券iの市場ポートフォリオに対するベータ係数\\beta_iの積に、誤差項\\varepsilon_{i,t}を加えたものとして表現されます。\nまた、誤差項\\varepsilon_{i,t}に関して次の仮定を置きます。\n\n\nvarepsilon _{i,t}は独立同一分布(i.i.d.)に従う\nE[\\varepsilon_{i,t}] = 0\nE[R_{M,t}^e , \\ \\varepsilon_{i,t} ] = 0\n\nこうすることで、CAPM式を線形回帰モデルで表現できるので、\\beta_iの推定が可能となります。\n\n6.4.1.1 時系列回帰\nCAPM式は任意のi証券で成立するモデルのため、ポートフォリオにも応用できます。 つまりあるポートフォリオの超過リターンを、市場ポートフォリオの超過リターンと、そのポートフォリオに対するベータ係数の積で説明することができます。\n\nR_{P,t}^e = \\alpha _P + \\beta_P R_{M,t}^e + \\varepsilon_{P,t}\n\nCAPMの式と比較すると、切片である\\alpha _Pが追加されていることが分かります。 もし証券市場にCAPMの関係が成立しているなら、\\alpha _Pはゼロとなっているはずです。 この$$を調べることで、CAPMの検証が可能となります。\nここでは、時系列回帰を使って、市場ポートフォリオの超過リターンを説明変数として、各ポートフォリオの超過リターンを説明するモデルを推定します。\n\n# ch06_16: 市場ポートフォリオの超過リターンを追加\n\nME_sorted_portfolio &lt;- factor_data |&gt;\n  select(-R_F) |&gt; # 無リスク金利は重複するので結合前に削除\n  full_join(ME_sorted_portfolio, by = \"month_ID\") |&gt; # month_IDをキーに\n  select(-R_Me, R_Me) # R_Meを最終列へ移動\n\n\n# ch06_17: 時系列回帰 (1)\n\nME_sorted_portfolio |&gt;\n  filter(ME_rank10 == 1) |&gt; # 時価総額が最小のポートフォリオを抽出\n  lm(Re ~ R_Me, data = _) |&gt; # .を使ってlm()関数の第二引数にデータを代入\n  tidy() # 線形回帰の結果をtidy()関数でデータフレームに変換\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic       p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n1 (Intercept)   0.0121   0.00404      3.00 0.00395      \n2 R_Me          0.654    0.0976       6.70 0.00000000937\n\n\n\n# ch06_18: 時系列回帰 (2)\n\nME_sorted_portfolio |&gt;\n  filter(ME_rank10 == 1) |&gt;\n  ggplot(aes(x = R_Me, y = Re)) + # aes()関数はggplot()関数の中にも代入可能\n  geom_point() +  # geom_point()関数と次のgeom_smooth()関数で共通のaes()関数を受け取る\n  geom_smooth(method = \"lm\", color = \"black\") +\n  labs(x = \"Excess Return of Market Portfolio\", y = \"Excess Return of Small Size Portfolio\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n6.4.1.2 ポートフォリオごとの回帰\n\n\n\nCAPMの実証的な検証 (1)\n\n# 推定結果を保存するために空のリストを準備\nCAPM_results &lt;- vector(\"list\", 10)\n\nfor(i in 1:10){\n\n  CAPM_results[[i]] &lt;- ME_sorted_portfolio |&gt;\n    filter(ME_rank10 == i) |&gt;\n    lm(Re ~ R_Me, data = _) |&gt;\n    tidy() |&gt;\n    mutate(ME_rank10 = i) |&gt; # 推定対象のポートフォリオ名を保存\n    select(ME_rank10, everything()) # ME_rank10を第一列に移動\n}\n\n\n\n\n\nCAPMの実証的な検証 (2)\n\n# リストを一つのデータフレームにまとめる\nCAPM_results &lt;- do.call(rbind, CAPM_results)\n\n\n\n\n\nグループごとの線形回帰 (1) lapply()関数を使う場合\n\nME_sorted_portfolio_splitted &lt;- split(ME_sorted_portfolio, ME_sorted_portfolio$ME_rank10) # 元データをME_rank10の値に応じて十個のデータフレームに分割\n\nestimate_CAPM &lt;- function(return_data) { # リターン・データを受け取り, CAPMの推定結果をデータフレームで返す関数を準備\n  lm_results &lt;- lm(Re ~ R_Me, data = return_data)\n  tidied_lm_results &lt;- tidy(lm_results)\n}\n\nCAPM_results_by_lapply &lt;- lapply(ME_sorted_portfolio_splitted, estimate_CAPM)\n# lapply()関数は第一引数にリスト, 第二引数に関数を取る\n# lapplyの返り値はリストなので，一つのデータフレームにまとめたい場合はdo.call()関数を用いる\n\n\n\n\n\nグループごとの線形回帰 (2) map()関数を使う場合\n\nME_sorted_portfolio |&gt;\n  nest(.by = ME_rank10) |&gt; # 【修正1】ここでグループ化を指定して畳み込む\n  mutate(\n    # map()関数を用いて各グループを線形回帰\n    CAPM_regression = map(data, ~lm(Re ~ R_Me, data = .x)),\n    CAPM_summary = map(CAPM_regression, tidy)\n    # 【修正2】ここは既にランクごとの行になっているので .by は不要\n    ) |&gt;\n  select(-c(data, CAPM_regression)) |&gt;\n  unnest(cols = CAPM_summary)\n\n\n# A tibble: 20 × 6\n   ME_rank10 term         estimate std.error statistic  p.value\n   &lt;fct&gt;     &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 2         (Intercept)  0.0106     0.00375     2.83  6.44e- 3\n 2 2         R_Me         0.711      0.0908      7.83  1.19e-10\n 3 8         (Intercept)  0.00122    0.00168     0.723 4.73e- 1\n 4 8         R_Me         0.956      0.0407     23.5   2.59e-31\n 5 4         (Intercept)  0.00957    0.00289     3.31  1.62e- 3\n 6 4         R_Me         0.848      0.0699     12.1   1.54e-17\n 7 7         (Intercept)  0.00284    0.00173     1.64  1.06e- 1\n 8 7         R_Me         0.943      0.0418     22.6   2.16e-30\n 9 1         (Intercept)  0.0121     0.00404     3.00  3.95e- 3\n10 1         R_Me         0.654      0.0976      6.70  9.37e- 9\n11 9         (Intercept)  0.000406   0.00144     0.282 7.79e- 1\n12 9         R_Me         1.03       0.0349     29.5   1.33e-36\n13 3         (Intercept)  0.0120     0.00312     3.86  2.90e- 4\n14 3         R_Me         0.770      0.0754     10.2   1.42e-14\n15 6         (Intercept)  0.00653    0.00195     3.34  1.45e- 3\n16 6         R_Me         0.904      0.0472     19.2   9.39e-27\n17 5         (Intercept)  0.00728    0.00234     3.11  2.86e- 3\n18 5         R_Me         0.896      0.0565     15.9   9.35e-23\n19 10        (Intercept) -0.000659   0.00113    -0.582 5.63e- 1\n20 10        R_Me         1.06       0.0273     38.9   2.93e-43\n\n\n\n6.4.1.3 CAPMアルファ\n\n\n\nCAPMアルファの可視化\n\nCAPM_results |&gt;\n  filter(term == \"(Intercept)\") |&gt; # 定数項に関する推定結果のみを抽出\n  mutate(\n    # ME_rank10を整数型からファクター型に\n    ME_rank10 = as.factor(ME_rank10)\n  ) |&gt;\n  # 横軸をME_rank10, 縦軸をCAPM_alphaとする棒グラフ\n  ggplot() + aes(x = ME_rank10, y = estimate) +\n  geom_col() + # 棒グラフ\n  geom_hline(yintercept = 0) + # y = 0の直線を追加\n  labs(x = \"ME Rank\", y = \"CAPM alpha\") +\n  scale_y_continuous(limits = c(-0.003, 0.013)) +\n  mystyle\n\n\n\n\n\n\n\n\n\n\n\nCAPMアルファの統計的な有意性を評価\n\nCAPM_results |&gt;\n  filter(term == \"(Intercept)\") |&gt; # 定数項を抽出\n  rename(\n    # 列名を変更\n    CAPM_alpha = estimate,\n    p_value = p.value\n  ) |&gt;\n  mutate(\n    # 統計的に有意な結果を*で強調\n    significance = cut(p_value,\n                        breaks = c(0, 0.01, 0.05, 0.1, 1),\n                        labels = c(\"***\", \"**\", \"*\", \"\"),\n                        include.lowest = TRUE)\n  ) |&gt;\n  select(# 出力したい列を指定\n    ME_rank10, CAPM_alpha, p_value, significance\n  )\n\n\n# A tibble: 10 × 4\n   ME_rank10 CAPM_alpha  p_value significance\n       &lt;int&gt;      &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;       \n 1         1   0.0121   0.00395  \"***\"       \n 2         2   0.0106   0.00644  \"***\"       \n 3         3   0.0120   0.000290 \"***\"       \n 4         4   0.00957  0.00162  \"***\"       \n 5         5   0.00728  0.00286  \"***\"       \n 6         6   0.00653  0.00145  \"***\"       \n 7         7   0.00284  0.106    \"\"          \n 8         8   0.00122  0.473    \"\"          \n 9         9   0.000406 0.779    \"\"          \n10        10  -0.000659 0.563    \"\"          \n\n\n\n\n\n証券市場線の推定\n\nME_cross_sectional_return &lt;- CAPM_results |&gt;\n  filter(term == \"R_Me\") |&gt; # R_Meの係数を抽出\n  rename(CAPM_beta = estimate) |&gt; # 名称変更\n  select(ME_rank10, CAPM_beta) |&gt; # 変数を選択\n  mutate( # ファクター型に変換\n    ME_rank10 = as.factor(ME_rank10)\n  ) |&gt;\n  # 超過リターンのデータと結合\n  full_join(\n    ME_cross_sectional_return, ., by = \"ME_rank10\"\n  )\n\n# 平均超過リターンと平均市場ポートフォリオ超過リターンを計算\nmean_R_Me &lt;- mean(factor_data$R_Me)\n\nggplot(ME_cross_sectional_return) +\n  aes(x = CAPM_beta, y = mean_Re) +\n  geom_point() + # 散布図\n  geom_abline(intercept = 0, slope = mean_R_Me) + # 証券市場線\n  labs(x = \"市場beta\", y = \"平均超過リターン\") + #\n  scale_x_continuous(limits = c(0, 1.2), expand = c(0, 0)) +\n  scale_y_continuous(limits = c(0, 0.02)) + mystyle\n\n\n\n\n\n\n\n\n\n6.4.2 Fama-Frenchの3ファクター・モデル\n\n6.4.2.1 銘柄のランク付け\n\n\n\n前年度の時価総額に基づくランク付け\n\nannual_data &lt;- annual_data |&gt;\n  mutate(\n    # lagged_BEMEが欠損している場合は欠損扱いに\n    lagged_ME = replace(lagged_ME, is.na(lagged_BEME), NA)\n  ) |&gt;\n  mutate(\n    .by = year,\n    ME_rank2 = as.factor(ntile(lagged_ME, 2))\n  )\n\n\n\n\n\n簿価時価比率に基づくランク付け (1)\n\nannual_data |&gt;\n  mutate(\n    # 年度ごとに簿価時価比率のパーセンタイル順位を計算\n    BEME_percent_rank = percent_rank(lagged_BEME),\n    .by = year\n  )\n\n\n# A tibble: 7,920 × 26\n    year firm_ID     ME annual_R annual_R_F annual_Re industry_ID sales    OX\n   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  2015       1  3577.   NA      0.00743      NA              NA   NA   NA  \n 2  2016       1  6883.    0.997  0.000565      0.997           1 5949. 564. \n 3  2017       1 11377.    0.688  0.0000488     0.688           1 6505. 691. \n 4  2018       1  8695.   -0.214  0.00579      -0.219           1 6846. 751. \n 5  2019       1 13958.    0.647 -0.000770      0.648           1 7572. 959. \n 6  2020       1  9709.   -0.284  0.000380     -0.285           1 7538. 778. \n 7  2015       2  4087.   NA      0.00579      NA               1 3506.  45.8\n 8  2016       2  5593.    0.375 -0.000770      0.376           1 3491.  51.2\n 9  2017       2  9153.    0.641  0.000380      0.640           1 3946.  83.4\n10  2018       2  7104.   -0.220  0.00371      -0.223           1 4139.  93.4\n# ℹ 7,910 more rows\n# ℹ 17 more variables: NFE &lt;dbl&gt;, X &lt;dbl&gt;, OA &lt;dbl&gt;, FA &lt;dbl&gt;, OL &lt;dbl&gt;,\n#   FO &lt;dbl&gt;, BE &lt;dbl&gt;, lagged_BE &lt;dbl&gt;, ROE &lt;dbl&gt;, lag_ME &lt;dbl&gt;,\n#   lagged_BEME &lt;dbl&gt;, lagged_ME &lt;dbl&gt;, w_M &lt;dbl&gt;, ME_rank10 &lt;fct&gt;,\n#   BEME_rank10 &lt;fct&gt;, ME_rank2 &lt;fct&gt;, BEME_percent_rank &lt;dbl&gt;\n\n\n\n\n\n簿価時価比率に基づくランク付け (2)\n\nannual_data &lt;- annual_data |&gt;\n  mutate(\n    # 年度ごとに簿価時価比率のパーセンタイル順位を計算\n    BEME_percent_rank = percent_rank(lagged_BEME),\n    .by = year\n  ) |&gt;\n  mutate(\n    # BEME_percent_rankの値に応じて1から3までBEME_rank3の値を定義\n    BEME_rank3 = cut(BEME_percent_rank,\n                      breaks = c(0, 0.3, 0.7, 1),\n                      labels = c(1, 2, 3),\n                      include.lowest = TRUE)\n  )\n\n\n\n6.4.2.2 時価総額とBE/MEに基づくポートフォリオ・ソート\n\n\n\nSize-BE/MEポートフォリオへの分類 (1)\n\nannual_data &lt;- annual_data |&gt;\n  mutate(\n    # ME_rank2とBEME_rank3の組合せで, ファクター型の変数FF_portfolio_typeを定義\n    FF_portfolio_type = interaction(ME_rank2, BEME_rank3)\n    )\n\n\n\n\n\nSize-BE/MEポートフォリオへの分類 (2)\n\nannual_data &lt;- annual_data |&gt;\n  mutate(\n    # ファクター型の変数\n    FF_portfolio_type = fct_recode(FF_portfolio_type,\n                                        SL = \"1.1\",\n                                        BL = \"2.1\",\n                                        SN = \"1.2\",\n                                        BN = \"2.2\",\n                                        SH = \"1.3\",\n                                        BH = \"2.3\")\n  )\n\n\n\n\n\nSize-BE/MEポートフォリオへの分類 (3)\n\nannual_data |&gt;\n  summarize(FF_portfolio_type = FF_portfolio_type[1],\n            mean_BEME = mean(lagged_BEME),\n            mean_ME = mean(lagged_ME),\n            mean_N_stocks = n() / length(unique(year)),\n            .by = c(ME_rank2, BEME_rank3)\n   ) |&gt;\n  drop_na() # 欠損データを削除\n\n\n# A tibble: 6 × 6\n  ME_rank2 BEME_rank3 FF_portfolio_type mean_BEME mean_ME mean_N_stocks\n  &lt;fct&gt;    &lt;fct&gt;      &lt;fct&gt;                 &lt;dbl&gt;   &lt;dbl&gt;         &lt;dbl&gt;\n1 1        3          SH                    1.97   11023.          260.\n2 1        2          SN                    0.973  11868.          226 \n3 1        1          SL                    0.416  11601.          155.\n4 2        2          BN                    0.960 211793.          286 \n5 2        3          BH                    1.72  151135.          125.\n6 2        1          BL                    0.468 414941.          230.\n\n\n\n\n\nSize-BE/MEポートフォリオの構築 (1)\n\nannual_data &lt;- annual_data |&gt;\n  # yearとFF_portfolio_typeのペアでグループ化\n  mutate(\n    # 各ポートフォリオ内で時価総額加重の保有比率を計算\n    w = lagged_ME  / sum(lagged_ME, na.rm = TRUE),\n    .by = c(year, FF_portfolio_type)\n  )\n\n\n\n\n\nSize-BE/MEポートフォリオの構築 (2)\n\nFF_portfolio &lt;- annual_data |&gt;\n  select(\n    year, firm_ID, FF_portfolio_type, ME_rank2, BEME_rank3, w\n  ) |&gt;\n  full_join(\n    monthly_data,\n    by = c(\"year\", \"firm_ID\")\n  ) |&gt; # 今までに準備したデータと月次データを結合\n  summarize(\n    ME_rank2 = ME_rank2[1],\n    BEME_rank3 = BEME_rank3[1],\n    R = sum(w * R, na.rm = TRUE), # 各ポートフォリオの月次リターンを計算\n    R_F = R_F[1],\n    .by = c(month_ID, FF_portfolio_type)\n  ) |&gt;\n  drop_na() # 欠損データを削除\n\n\n\n\n\nSize-BE/MEポートフォリオのリターンの可視化 (1)\n\nFF_portfolio_mean_return &lt;- FF_portfolio |&gt;\n  mutate(Re = R - R_F) |&gt;\n  summarize(\n    ME_rank2 = ME_rank2[1],\n    BEME_rank3 = BEME_rank3[1],\n    mean_Re = mean(Re),\n    .by = FF_portfolio_type\n    ) # 各ポートフォリオの超過リターンの平均値を計算\n\nggplot(FF_portfolio_mean_return) +\n  geom_col(aes(x = BEME_rank3, y = mean_Re, fill = ME_rank2), position = \"dodge\") + # x軸をBEME_rank3, y軸をmean_Reに, ME_rank2のサブグループで色分け\n  scale_fill_grey() + # 棒グラフの色をモノトーンに\n  labs(x = \"BE/ME Rank\", y = \"Mean Monthly Excess Return\", fill = \"ME Rank\") +\n  scale_y_continuous(expand = c(0, 0)) + mystyle\n\n\n\n\n\n\n\n\n\n\n\nSize-BE/MEポートフォリオのリターンの可視化 (2)\n\nggplot(FF_portfolio_mean_return) +\n  geom_col(aes(x = BEME_rank3, y = mean_Re, fill = ME_rank2), position = \"dodge\") +\n  scale_fill_grey() +\n  geom_text(aes(x = BEME_rank3, y = mean_Re, group = ME_rank2, label = FF_portfolio_type), # (x, y)座標を指定して各ポートフォリオの名前をグラフに挿入\n            vjust = -0.5, # 棒グラフが重ならないよう文字ラベルを上にずらす\n            position = position_dodge(width = 0.9)) + # ME_rank2のサブグループで文字ラベルが左右にずれるよう調整\n  labs(x = \"BE/ME Rank\", y = \"Mean Monthly Excess Return\", fill = \"ME Rank\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.015)) + # 文字ラベルがはみ出ないようy軸の範囲を指定\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\nSize-BE/MEポートフォリオのリターンの可視化 (3)\n\ninitial_point &lt;- tibble(\n  month_ID = c(12, 12), # 累積リターンの起点を定義\n  cumulative_gross_R = c(1, 1),\n  FF_portfolio_type = c(\"BL\", \"SH\")\n  )\n\nFF_portfolio_cumulative_return &lt;- FF_portfolio |&gt;\n  mutate(# グロス・リターンを累積\n    cumulative_gross_R = cumprod(1 + R),\n    .by = FF_portfolio_type\n  ) |&gt;\n  filter(FF_portfolio_type %in% c(\"BL\", \"SH\")) |&gt;\n  select(month_ID, cumulative_gross_R, FF_portfolio_type) |&gt;\n  bind_rows(initial_point)\n\nggplot(FF_portfolio_cumulative_return) +\n  geom_line(aes(x = month_ID, y = cumulative_gross_R, linetype = FF_portfolio_type)) +\n  scale_linetype_manual(values = c(\"longdash\", \"solid\")) +\n  geom_hline(yintercept = 1, linetype = \"dotted\") +\n  labs(x = \"Month ID\", y = \"Cumulative Gross Return\", linetype = \"\") +\n  scale_x_continuous(expand = c(0, 0)) + mystyle\n\n\n\n\n\n\n\n\n\n6.4.2.3 ファクター・リターンの計算\n\n\n\nSMBとHMLの構築 (1)\n\n# FF_portfolio_typeの値に基づく列を作成し, 縦長から横長のデータに変換\nFF_portfolio &lt;- FF_portfolio |&gt;\n  pivot_wider(\n    id_cols = month_ID,\n    names_from = FF_portfolio_type,\n    values_from = R\n    )\n\n\n\n\n\nSMBとHMLの構築 (2)\n\nfactor_data &lt;- FF_portfolio |&gt;\n  mutate(\n    SMB = (SH + SN + SL) / 3 - (BH + BN + BL) / 3, # SMBとHMLを計算\n    HML = (SH + BH) / 2 - (SL + BL) / 2\n    ) |&gt;\n  select(month_ID, SMB, HML) |&gt;\n  full_join(factor_data, by = \"month_ID\") |&gt; # 3ファクターの実現値をfactor_dataに集約\n  select(-c(\"SMB\", \"HML\"), c(\"SMB\", \"HML\")) # SMBとHMLを最後列に移動\n\n\n\n6.4.2.4 FF3アルファ\n\n\n\nFF3モデルの推定\n\nME_sorted_portfolio &lt;- ME_sorted_portfolio |&gt;\n  select(-c(R_Me, R_M)) |&gt;\n  # 3ファクターの実現値をME_sorted_portfolioに追加\n  full_join(factor_data, by = \"month_ID\")\n\nFF3_results &lt;- list(NA)  # 推定結果を保存するために空のリストを準備\n\nfor(i in 1:10) {\n  FF3_results[[i]] &lt;- ME_sorted_portfolio |&gt;\n    filter(ME_rank10 == i) |&gt;\n    lm(Re ~ R_Me + SMB + HML, data = _) |&gt; # 3ファクターの実現値を独立変数として重回帰\n    tidy() |&gt;\n    mutate(ME_rank10 = i) |&gt; # 推定対象のポートフォリオ名を保存\n    select(ME_rank10, everything()) # ME_rank10を第一列に移動\n}\n\nFF3_results &lt;- do.call(rbind, FF3_results) # do.call()関数を用いて複数のデータフレームから構成されるリストを一つのデータフレームに統合\n\n\n\n\n\nFF3アルファの可視化\n\nFF3_results |&gt;\n  filter(term == \"(Intercept)\") |&gt; # 定数項に関する推定結果のみを抽出\n  mutate(\n    ME_rank10 = as.factor(ME_rank10)\n  ) |&gt; # ME_rank10を整数型からファクター型に\n  ggplot() +\n  # 横軸をME_rank10, 縦軸をFF3_alphaとする棒グラフ\n  geom_col(aes(x = ME_rank10, y = estimate)) +\n  geom_hline(yintercept = 0) +\n  labs(x = \"ME Rank\", y = \"FF3 alpha\") +\n  scale_y_continuous(limits = c(-0.003, 0.013)) + mystyle\n\n\n\n\n\n\n\n\n\n\n\nFF3アルファの統計的な有意性を評価\n\nFF3_results |&gt;\n  filter(term == \"(Intercept)\") |&gt; # 定数項に関する推定結果のみを抽出\n  rename(\n    FF3_alpha = estimate,\n    p_value = p.value\n  ) |&gt; # 列名を変更\n  mutate(\n    significance = cut(p_value,\n      breaks = c(0, 0.01, 0.05, 0.1, 1),\n      labels = c(\"***\", \"**\", \"*\", \"\"),\n      include.lowest = TRUE)\n  ) |&gt; # 統計的に有意な結果を*で強調\n  select(ME_rank10, FF3_alpha, p_value, significance)\n\n\n# A tibble: 10 × 4\n   ME_rank10 FF3_alpha p_value significance\n       &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;       \n 1         1  0.00244   0.181  \"\"          \n 2         2  0.00134   0.412  \"\"          \n 3         3  0.00246   0.0893 \"*\"         \n 4         4 -0.000843  0.335  \"\"          \n 5         5 -0.000924  0.336  \"\"          \n 6         6  0.000957  0.456  \"\"          \n 7         7 -0.00183   0.119  \"\"          \n 8         8  0.000842  0.555  \"\"          \n 9         9 -0.00100   0.522  \"\"          \n10        10 -0.00228   0.0492 \"**\"        \n\n\n\n\n\nデータの保存\n\nwrite_csv(factor_data, \"data/ch06_output.csv\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ファクターモデルの導入</span>"
    ]
  }
]